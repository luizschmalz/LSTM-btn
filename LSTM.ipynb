{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lmPi0F4acbDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8ae66d-016b-4e94-e60c-1ff9b34de00c"
      },
      "cell_type": "code",
      "source": [
        "#install all the required dependancy libraries\n",
        "!pip install tensorflow #for prediction\n",
        "!pip install numpy  #for matrix multiplication\n",
        "!pip install pandas #define the data structures\n",
        "!pip install matplotlib #for visualization\n",
        "!pip install scikit-learn #for normalizing our data(scaling)\n",
        "\n",
        "#importing the libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import io\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5SA-Zrn2cqr4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "23ac3f75-9c54-49f8-b13a-08692db7f2a3"
      },
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f0747c2b-189c-4a50-b901-31884cf194c1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f0747c2b-189c-4a50-b901-31884cf194c1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving btc.csv to btc.csv\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "y0PrtbsMde8D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b6f2b1f7-e800-418b-8c27-aacbd37aff4a"
      },
      "cell_type": "code",
      "source": [
        "#decoding the files as uploaded will be a dictionary of keys (the file names) and values (the encoded file objects)\n",
        "btc = pd.read_csv(io.StringIO(uploaded['btc.csv'].decode('utf-8')))\n",
        "btc.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date  Symbol     Open     High      Low    Close  Volume From  \\\n",
              "0  5/26/2018  BTCUSD  7459.11  7640.46  7380.00  7520.00      2722.80   \n",
              "1  5/25/2018  BTCUSD  7584.15  7661.85  7326.94  7459.11      8491.93   \n",
              "2  5/24/2018  BTCUSD  7505.00  7734.99  7269.00  7584.15     11033.72   \n",
              "3  5/23/2018  BTCUSD  7987.70  8030.00  7433.19  7505.00     14905.99   \n",
              "4  5/22/2018  BTCUSD  8393.44  8400.00  7950.00  7987.70      6589.43   \n",
              "\n",
              "      Volume To  \n",
              "0  2.042265e+07  \n",
              "1  6.342069e+07  \n",
              "2  8.293137e+07  \n",
              "3  1.148104e+08  \n",
              "4  5.389753e+07  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f916332-3b39-4cdb-ada7-64e95ce85e1a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume From</th>\n",
              "      <th>Volume To</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5/26/2018</td>\n",
              "      <td>BTCUSD</td>\n",
              "      <td>7459.11</td>\n",
              "      <td>7640.46</td>\n",
              "      <td>7380.00</td>\n",
              "      <td>7520.00</td>\n",
              "      <td>2722.80</td>\n",
              "      <td>2.042265e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5/25/2018</td>\n",
              "      <td>BTCUSD</td>\n",
              "      <td>7584.15</td>\n",
              "      <td>7661.85</td>\n",
              "      <td>7326.94</td>\n",
              "      <td>7459.11</td>\n",
              "      <td>8491.93</td>\n",
              "      <td>6.342069e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5/24/2018</td>\n",
              "      <td>BTCUSD</td>\n",
              "      <td>7505.00</td>\n",
              "      <td>7734.99</td>\n",
              "      <td>7269.00</td>\n",
              "      <td>7584.15</td>\n",
              "      <td>11033.72</td>\n",
              "      <td>8.293137e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5/23/2018</td>\n",
              "      <td>BTCUSD</td>\n",
              "      <td>7987.70</td>\n",
              "      <td>8030.00</td>\n",
              "      <td>7433.19</td>\n",
              "      <td>7505.00</td>\n",
              "      <td>14905.99</td>\n",
              "      <td>1.148104e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5/22/2018</td>\n",
              "      <td>BTCUSD</td>\n",
              "      <td>8393.44</td>\n",
              "      <td>8400.00</td>\n",
              "      <td>7950.00</td>\n",
              "      <td>7987.70</td>\n",
              "      <td>6589.43</td>\n",
              "      <td>5.389753e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f916332-3b39-4cdb-ada7-64e95ce85e1a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f916332-3b39-4cdb-ada7-64e95ce85e1a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f916332-3b39-4cdb-ada7-64e95ce85e1a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ee18950-81a5-4727-afce-4a09e7db8668\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ee18950-81a5-4727-afce-4a09e7db8668')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ee18950-81a5-4727-afce-4a09e7db8668 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "btc",
              "summary": "{\n  \"name\": \"btc\",\n  \"rows\": 1273,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1273,\n        \"samples\": [\n          \"4/13/2018\",\n          \"3/23/2015\",\n          \"1/18/2018\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Symbol\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"BTCUSD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3786.4465827307645,\n        \"min\": 120.0,\n        \"max\": 19650.0,\n        \"num_unique_values\": 1226,\n        \"samples\": [\n          609.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3959.1666701712543,\n        \"min\": 184.0,\n        \"max\": 19891.99,\n        \"num_unique_values\": 1196,\n        \"samples\": [\n          586.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3560.4305754659094,\n        \"min\": 0.06,\n        \"max\": 19010.0,\n        \"num_unique_values\": 1196,\n        \"samples\": [\n          569.67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3788.559183999996,\n        \"min\": 120.0,\n        \"max\": 19650.0,\n        \"num_unique_values\": 1224,\n        \"samples\": [\n          515.38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume From\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9940.038575810231,\n        \"min\": 0.0,\n        \"max\": 160540.99,\n        \"num_unique_values\": 1237,\n        \"samples\": [\n          3011.09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume To\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105580653.00178878,\n        \"min\": 0.0,\n        \"max\": 1237770941.0,\n        \"num_unique_values\": 1238,\n        \"samples\": [\n          1835075.42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "kUSRbjfxmE_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dccb2af-f487-492b-9f90-fb82ddffeaf1"
      },
      "cell_type": "code",
      "source": [
        "#selecting only the column that we are going to use in the prediction process\n",
        "data_to_use=btc['Close'].values\n",
        "data_to_use"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7520.  , 7459.11, 7584.15, ...,  378.  ,  378.  ,  370.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "RU7Z978_w1lP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "81e426e0-4a3d-4fec-adff-24d3fcf4c107"
      },
      "cell_type": "code",
      "source": [
        "#data preprocessing(scaling)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data_to_use.reshape(-1, 1))\n",
        "#plotting the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,7), frameon=False, facecolor='brown', edgecolor='blue')\n",
        "plt.title('Bitcoin prices from December 2014 to May 2018')\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('Scaled price of Bitcoin')\n",
        "plt.plot(scaled_data, label='Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "PM3y5iPb1HOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc2119bd-772c-4768-f717-f004f44d4b50"
      },
      "cell_type": "code",
      "source": [
        "# This function is used to create Features and Labels datasets. By windowing the data.\n",
        "#Input: data - dataset used in the project\n",
        "#window_size - how many data points we are going to use to predict the next datapoint in the sequence\n",
        "#[Example: if window_size = 1 we are going to use only the previous day to predict todays stock prices]\n",
        "#Outputs: X - features splitted into windows of datapoints (if window_size = 1, X = [len(data)-1, 1])\n",
        "#y - 'labels', actually this is the next number in the sequence, this number we are trying to predict\n",
        "\n",
        "def window_data(data, window_size):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    i = 0\n",
        "    while (i + window_size) <= len(data) - 1:\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size])\n",
        "\n",
        "        i += 1\n",
        "    assert len(X) ==  len(y)\n",
        "    return X, y\n",
        "#windowing the data with window_data function\n",
        "X, y = window_data(scaled_data, 7)\n",
        "\n",
        "\n",
        "#we now split the data into training and test set\n",
        "import numpy as np\n",
        "X_train  = np.array(X[:1018])\n",
        "y_train = np.array(y[:1018])\n",
        "\n",
        "X_test = np.array(X[1018:])\n",
        "y_test = np.array(y[1018:])\n",
        "\n",
        "print(\"X_train size: {}\".format(X_train.shape))\n",
        "print(\"y_train size: {}\".format(y_train.shape))\n",
        "print(\"X_test size: {}\".format(X_test.shape))\n",
        "print(\"y_test size: {}\".format(y_test.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (1018, 7, 1)\n",
            "y_train size: (1018, 1)\n",
            "X_test size: (248, 7, 1)\n",
            "y_test size: (248, 1)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0h75jdrjToBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d266df-e64d-4b5a-c5a5-f278a2d8aa29"
      },
      "cell_type": "code",
      "source": [
        "#ate agora tudo foi copiado do link fornecido para rodar o projeto, agora vamos rodar esses primeiros hiperparametros e depois fazer nossos proprios testes\n",
        "batch_size = 7\n",
        "window_size = 7\n",
        "hidden_layer = 256\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_63:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_127:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_191:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_255:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_319:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_383:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_447:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "TRI3eUQzW6_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d330156-5c4b-40de-8f3f-d98e077658fb"
      },
      "cell_type": "code",
      "source": [
        "#we define the loss\n",
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 30) == 0:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200  Current loss: 0.28875723481178284\n",
            "Epoch 30/200  Current loss: 0.05913089960813522\n",
            "Epoch 60/200  Current loss: 0.01159659493714571\n",
            "Epoch 90/200  Current loss: 0.010467746295034885\n",
            "Epoch 120/200  Current loss: 0.007723554968833923\n",
            "Epoch 150/200  Current loss: 0.006841229274868965\n",
            "Epoch 180/200  Current loss: 0.00605869572609663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sup =[]\n",
        "for i in range(len(traind_scores)):\n",
        "    for j in range(len(traind_scores[i])):\n",
        "        sup.append(traind_scores[i][j][0])\n",
        "\n",
        "\n",
        "tests = []\n",
        "i = 0\n",
        "while i+batch_size <= len(X_test):\n",
        "\n",
        "    o = session.run([outputs],feed_dict={inputs:X_test[i:i+batch_size]})\n",
        "    i += batch_size\n",
        "    tests.append(o)\n",
        "\n"
      ],
      "metadata": {
        "id": "JfaNuySYBDRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests_new = []\n",
        "for i in range(len(tests)):\n",
        "  for j in range(len(tests[i][0])):\n",
        "    tests_new.append(tests[i][0][j])"
      ],
      "metadata": {
        "id": "NRqpS3gsBKsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_results = []\n",
        "for i in range(1264):\n",
        "    if i >= 1019:\n",
        "      test_results.append(tests_new[i-1019])\n",
        "    else:\n",
        "      test_results.append(None)"
      ],
      "metadata": {
        "id": "7Ts9xIXhBc5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qnQJYH-HqsX4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "918496e6-939a-42d4-a116-e329cb0d436c"
      },
      "cell_type": "code",
      "source": [
        "#we now plot predictions from the network\n",
        "plt.figure(figsize=(16, 7))\n",
        "plt.title('Bitcoin prices from December 2014 to May 2018')\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('Scaled Price of Bitcoin')\n",
        "plt.plot(scaled_data, label='Original data')\n",
        "plt.plot(sup, label='Training data')\n",
        "plt.plot(test_results, label='Testing data')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input could not be cast to an at-least-1D NumPy array",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-26262efa06e2>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Original data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Testing data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input could not be cast to an at-least-1D NumPy array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input could not be cast to an at-least-1D NumPy array"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x700 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABRIAAAJwCAYAAAD1Op1tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADiZUlEQVR4nOzdd5hcdb3H8c/02V7SewVSSEBDaIFECFIEQkdATQCpF0SKYpCrVAHFSxMBQaSDFCmiQggQ6YQeCDWd9LbZvjv13D/OmTNnyu7OJFuT9+t59pmZ35yZ+W12l/vcj9/v7+syDMMQAAAAAAAAALTC3dUbAAAAAAAAAND9ESQCAAAAAAAAaBNBIgAAAAAAAIA2ESQCAAAAAAAAaBNBIgAAAAAAAIA2ESQCAAAAAAAAaBNBIgAAAAAAAIA2ESQCAAAAAAAAaBNBIgAAAAAAAIA2ESQCANDJXC6Xrrzyyk7/3FNPPVXDhw/v9M9ty/Dhw3Xqqad29TYyRKNRXXrppRoyZIjcbreOPvrort4SJP33v/+Vy+XSU0891dVbAQAA2OEQJAIAsI3uv/9+uVyulK++ffvqgAMO0AsvvNDm699++21deeWVqq6u7vjNImd/+9vfdOONN+r444/XAw88oIsuuqirt9Sq4cOH279/brdb5eXlmjBhgs466yzNnz+/q7e3Xfnqq6906aWXavfdd1dJSYkGDBigww8/XB988EHW61evXq0TTzxR5eXlKi0t1VFHHaWlS5dmXHfnnXfqhBNO0NChQ+VyuXIO2M8880y5XC4dccQROV1/xx136P7778/p2nwkfgcPOuigrM/fc8899u9oS/9WHaU7/Mw+/PBDHXHEEerfv7+Ki4s1ceJE3XbbbYrFYu31bQIA0OG8Xb0BAAC2F1dffbVGjBghwzC0fv163X///frBD36g559/PuX/wW9qapLXm/w/wW+//bauuuoqnXrqqSovL++w/d1zzz2Kx+Md9v5b6+uvv5bb3f3+t81XX31VgwYN0s0339zVW8nZ7rvvrksuuUSSVFdXpy+//FJPPvmk7rnnHl100UW66aabuniH24e//vWvuvfee3Xcccfpf/7nf1RTU6O//OUv2nvvvfXiiy+mBGn19fU64IADVFNTo1//+tfy+Xy6+eabNW3aNH3yySfq1auXfe3vf/971dXVac8999TatWtz2ssHH3yg+++/X8FgMOf933HHHerdu3eHVAIHg0HNmzdP69atU//+/VOee+SRRxQMBtXc3Nzun9uWrv6Zffjhh9p3332100476Ve/+pUKCwv1wgsv6Oc//7mWLFmiW2+9tUO/fwAA2o0BAAC2yX333WdIMt5///2U9aqqKsPn8xmnnHJKq6+/8cYbDUnGsmXLOnCX3Us8HjcaGxu7ehutOuCAA4zx48e3eV0kEjFCoVAn7Kh1w4YNMw4//PCM9cbGRuPoo482JBl33HFHF+ysfc2bN8+QZDz55JMd+jn19fUtPvfBBx8YdXV1KWubNm0y+vTpY0yZMiVl/fe//70hyXjvvffstS+//NLweDzGZZddlnLt8uXLjXg8bhiGYRQVFRmzZs1qdY/xeNzYZ599jNNPP73Fn38248ePN6ZNm5bTtfkYNmyYMX36dKO0tNS45ZZbUp5buXKl4Xa7jeOOOy7rfy87Wlf/zM4880zD7/cbmzdvTlmfOnWqUVpaurXfFgAAna77/c//AABsJ8rLy1VQUJBSfSilnpF45ZVX6pe//KUkacSIEXbb3/Lly+3rH374Ye25554qLCxURUWFpk6dqpdeeinlPe+44w6NHz9egUBAAwcO1HnnnZfRKp1+RuLy5cvlcrn0xz/+UXfffbdGjRqlQCCgyZMn6/3332/z+0u0dL/++us6++yz1atXL5WWlmrmzJnasmVLyrXDhw/XEUccoTlz5miPPfZQQUGB/vKXv9jPpVdGVVdX66KLLtLw4cMVCAQ0ePBgzZw5U5s2bbKvCYVCuuKKKzR69GgFAgENGTJEl156qUKhUMp7zZ07V/vtt5/Ky8tVXFysXXbZRb/+9a9b/L4S/y7z5s3T559/bv9M/vvf/6b8m91yyy32v9kXX3whyaxi3H///VVUVKTy8nIdddRR+vLLL1Pe/8orr5TL5dI333yjH//4xyorK1OfPn30m9/8RoZhaOXKlTrqqKNUWlqq/v376//+7//a/Fm0pqCgQA899JAqKyv1u9/9ToZh2M/F43HdcsstGj9+vILBoPr166ezzz474+cnSS+88IKmTZumkpISlZaWavLkyXr00UdTrpk/f74OPfRQlZWVqbCwUNOmTdNbb73VId9/LBbTr3/9a/Xv319FRUWaMWOGVq5cmXFdPnv64osvdMopp6iiokL77bdfi/+mkyZNUnFxccpar169tP/++2f8vJ966ilNnjxZkydPttfGjBmj6dOn64knnki5dtiwYXK5XC1+brqHHnpICxcu1O9+97ucXzN8+HB9/vnneu211+zf7e9973v280uXLtUJJ5ygyspKFRYWau+999a///3vnN8/GAzq2GOPzfjdeOyxx1RRUaFDDjkk4zWffvqpTj31VI0cOVLBYFD9+/fX6aefrs2bN9vXzJs3Ty6XS88880zG6x999FG5XC698847Le6rq39mtbW1CgaDGVXnAwYMUEFBQZuvBwCgu6C1GQCAdlJTU6NNmzbJMAxt2LBBf/rTn1RfX68f//jHLb7m2GOP1TfffKPHHntMN998s3r37i1J6tOnjyTpqquu0pVXXql9991XV199tfx+v+bPn69XX31VBx98sCQzBLnqqqt00EEH6dxzz9XXX3+tO++8U++//77eeust+Xy+Vvf96KOPqq6uTmeffbZcLpf+8Ic/6Nhjj9XSpUvbfK0knX/++SovL9eVV15pf/aKFSvsoRgJX3/9tU4++WSdffbZOvPMM7XLLrtkfb/6+nr7/7k//fTT9d3vflebNm3SP//5T61atUq9e/dWPB7XjBkz9Oabb+qss87S2LFj9dlnn+nmm2/WN998o2effVaS9Pnnn+uII47QxIkTdfXVVysQCGjx4sUZQZJTnz599NBDD+l3v/ud6uvrdf3110uSxo4dq6amJknSfffdp+bmZp111lkKBAKqrKzUyy+/rMMOO0wjR47UlVdeqaamJv3pT3/SlClT9NFHH2UMuvnhD3+osWPH6oYbbtC///1vXXvttaqsrNRf/vIXHXjggfr973+vRx55RL/4xS80efJkTZ06tc2fRUuKi4t1zDHH6N5779UXX3yh8ePHS5LOPvts3X///TrttNN0wQUXaNmyZbr99tv18ccfp/zu3H///Tr99NM1fvx4XXbZZSovL9fHH3+sF198UaeccookM0Q97LDDNGnSJF1xxRVyu9267777dOCBB+qNN97Qnnvu2a7f/+9+9zu5XC796le/0oYNG3TLLbfooIMO0ieffGIHM/nu6YQTTtBOO+2k6667LiVwzdW6devsv2HJDGo//fRTnX766RnX7rnnnnrppZdUV1enkpKSvD+rrq5Ov/rVr+wwNVe33HKLfvazn6m4uFiXX365JKlfv36SpPXr12vfffdVY2OjLrjgAvXq1UsPPPCAZsyYoaeeekrHHHNMTp9xyimn6OCDD9aSJUs0atQoSeZ/Z44//vis/02ZO3euli5dqtNOO039+/fX559/rrvvvluff/653n33XTvsHDJkiB555JGMfTzyyCMaNWqU9tlnn5z/HRI662f2ve99T48//rjOPvtsXXzxxXZr89NPP60bb7wx730DANBlurQeEgCA7UCitTn9KxAIGPfff3/G9ZKMK664wn7cUmvzokWLDLfbbRxzzDFGLBZLeS7RSrdhwwbD7/cbBx98cMo1t99+uyHJ+Nvf/mavzZo1yxg2bJj9eNmyZYYko1evXkZVVZW9/txzzxmSjOeffz6n73vSpElGOBy21//whz8YkoznnnvOXhs2bJghyXjxxRcz3mfYsGEp7YC//e1vDUnG008/nXFt4vt+6KGHDLfbbbzxxhspz991112GJOOtt94yDMMwbr75ZkOSsXHjxla/l2ymTZuW0dqc+DcrLS01NmzYkPLc7rvvbvTt2zeldXHBggWG2+02Zs6caa9dccUVhiTjrLPOstei0agxePBgw+VyGTfccIO9vmXLFqOgoKDNFlfDaLm1OSHxb5H4ubzxxhuGJOORRx5Jue7FF19MWa+urjZKSkqMvfbay2hqakq5NvHziMfjxk477WQccsgh9pphmG3VI0aMML7//e+32/efaG0eNGiQUVtba68/8cQThiTj1ltv3eo9nXzyyS3++7Xl9ddfN1wul/Gb3/zGXtu4caMhybj66qszrv/zn/9sSDK++uqrrO/XVmvzL37xC2PEiBFGc3OzYRht//ydWmptvvDCCw1JKX9XdXV1xogRI4zhw4dn/HcoXWIP0WjU6N+/v3HNNdcYhmEYX3zxhSHJeO2117IeBZHtmIPHHnvMkGS8/vrr9tpll11mBAIBo7q62l7bsGGD4fV6U/6bmqvO/JlFo1Hj/PPPN3w+n/1/Izwej3HnnXfmvW8AALoSrc0AALSTP//5z5o7d67mzp2rhx9+WAcccIDOOOMMPf3001v1fs8++6zi8bh++9vfZgwjSVT6vfzyywqHw7rwwgtTrjnzzDNVWlqaU0viD3/4Q1VUVNiP999/f0nKOqE0m7POOiulyujcc8+V1+vVf/7zn5TrRowYkbWtMd0//vEP7bbbblmrnxLf95NPPqmxY8dqzJgx2rRpk/114IEHSjLbICXZbYTPPfdcuw6aOe644+yqUUlau3atPvnkE5166qmqrKy01ydOnKjvf//7Gf8WknTGGWfY9z0ej/bYYw8ZhqGf/vSn9np5ebl22WWXnH8WrUm0ddbV1Uky/w3Lysr0/e9/P+XfMNECmvg3nDt3rurq6jR79uyMgR6Jn8cnn3yiRYsW6ZRTTtHmzZvt92poaND06dP1+uuvZ/z7b+v3P3PmzJSqsOOPP14DBgyw/623Zk/nnHNOfv+olg0bNuiUU07RiBEjdOmll9rriQrWQCCQ8ZrEv2Ximnx88803uvXWW3XjjTdmfe+t9Z///Ed77rlnSlt3cXGxzjrrLC1fvtxu4W+Lx+PRiSeeqMcee0ySWTE4ZMgQ+78t6Zytvc3Nzdq0aZP23ntvSdJHH31kPzdz5kyFQiE99dRT9trjjz+uaDTaauV3Np39M/N4PBo1apQOOeQQPfDAA3r88cd15JFH6mc/+5ldQQ0AQE9AazMAAO1kzz331B577GE/Pvnkk/Wd73xH559/vo444gj5/f683m/JkiVyu90aN25ci9esWLFCkjLahP1+v0aOHGk/35qhQ4emPE6EitnOyctmp512SnlcXFysAQMGpJzzKJlBYi6WLFmi4447rtVrFi1apC+//DIlzHPasGGDJDMk/etf/6ozzjhDs2fP1vTp03Xsscfq+OOP36ZJ0enfS0s/B8lsiZ4zZ44aGhpUVFRkr6f/u5eVlSkYDKa0WSbWnWfFba36+npJssO3RYsWqaamRn379s16feLfcMmSJZKkXXfdtcX3XrRokSRp1qxZLV5TU1OTElhv6/ef/nvncrk0evRo+/dua/aU6++oU0NDg4444gjV1dXpzTffTDmHLxGQpZ/bKcmeXLw15+P9/Oc/17777tvm30m+VqxYob322itjfezYsfbzrf0eOJ1yyim67bbbtGDBAj366KM66aSTWjxLsKqqSldddZX+/ve/2793CTU1Nfb9MWPGaPLkyXrkkUfswPmRRx7R3nvvrdGjR+e0L6lrfmY33HCDbr31Vi1atMj+vBNPPFEHHHCAzjvvPB1xxBEZ5+kCANAd8X+tAADoIG63WwcccID9/zwmzqXrbjweT9Z1YyvOiGtNew4UiMfjmjBhgm666aaszw8ZMsT+zNdff13z5s3Tv//9b7344ot6/PHHdeCBB+qll15q8XtvS3t8L9k+uyN/FgsXLpQkO3CJx+Pq27evHnnkkazXtxTSZpOo7Lvxxhu1++67Z70mfdBFR3//W7OnfH+u4XBYxx57rD799FPNmTMnI2SrrKxUIBDQ2rVrM16bWBs4cGBen/nqq6/qxRdf1NNPP50S1kejUTU1NWn58uWqrKxUaWlpXu/b3vbaay+NGjVKF154oZYtW2afpZnNiSeeqLffflu//OUvtfvuu6u4uFjxeFyHHnpoRtXozJkz9fOf/1yrVq1SKBTSu+++q9tvvz3nfXXFz0wyB2IdeOCBGb9zM2bM0MUXX6zly5fnFYYCANBVCBIBAOhA0WhUUrIaLJuWqnRGjRqleDyuL774osUgZNiwYZLMQSYjR46018PhsJYtW6aDDjpoK3eeu0WLFumAAw6wH9fX12vt2rX6wQ9+sFXvN2rUKDv0au2aBQsWaPr06W1OTHW73Zo+fbqmT5+um266Sdddd50uv/xyzZs3r93+fZw/h3RfffWVevfunVKN2Nnq6+v1zDPPaMiQIXZ12ahRo/Tyyy9rypQprQZoiWEZCxcubDHoSFxTWlraKb9zUrLiMMEwDC1evFgTJ07slD3F43HNnDlTr7zyip544glNmzYt4xq3260JEybogw8+yHhu/vz5GjlyZN5DO7799ltJ5qCmdKtXr9aIESN0880368ILL2zxPVr6mxk2bFiLv8OJ5/Nx8skn69prr9XYsWNb/G/Yli1b9Morr+iqq67Sb3/7W3s9/eebcNJJJ+niiy/WY489pqamJvl8Pv3whz/MaT9d9TOTzEE2sVgsYz0SiUhK/t8KAAC6O85IBACgg0QiEb300kvy+/12eJNNImCqrq5OWT/66KPldrt19dVXZ1TlJCq0DjroIPn9ft12220pVVv33nuvampqdPjhh7fTd9Oyu+++2/5/hiXpzjvvVDQa1WGHHbZV73fcccdpwYIFeuaZZzKeS3yPJ554olavXq177rkn45qmpiY1NDRIMlsm0yUCjWyti1trwIAB2n333fXAAw+k/BwXLlyol156aatD1fbQ1NSkn/zkJ6qqqtLll19uh0gnnniiYrGYrrnmmozXRKNR+/s4+OCDVVJSouuvv95u7UxI/DwmTZqkUaNG6Y9//GPW0Hzjxo3t/F1JDz74oH3eoyQ99dRTWrt2rf1719F7+tnPfqbHH39cd9xxR9ZQL+H444/X+++/nxJMff3113r11Vd1wgkn5P25Bx54oJ555pmMrz59+miPPfbQM888oyOPPLLV9ygqKsr4740k/eAHP9B7772nd955x15raGjQ3XffreHDh7d6zEI2Z5xxhq644gr93//9X4vXJKpQ06tOb7nllqzX9+7dW4cddpgefvhhPfLIIzr00EMz2uFb0lU/M0naeeedNXfu3JQ2/VgspieeeEIlJSV28A0AQHdHRSIAAO3khRdesCt3NmzYoEcffVSLFi3S7NmzW20znDRpkiTp8ssv10knnSSfz6cjjzxSo0eP1uWXX65rrrlG+++/v4499lgFAgG9//77GjhwoK6//nr16dNHl112ma666iodeuihmjFjhr7++mvdcccdmjx5ct4DCLZGOBzW9OnTdeKJJ9qfvd9++2nGjBlb9X6//OUv9dRTT+mEE07Q6aefrkmTJqmqqkr//Oc/ddddd2m33XbTT37yEz3xxBM655xzNG/ePE2ZMkWxWExfffWVnnjiCc2ZM0d77LGHrr76ar3++us6/PDDNWzYMG3YsEF33HGHBg8enDJQoj3ceOONOuyww7TPPvvopz/9qZqamvSnP/1JZWVluvLKK9v1s1qyevVqPfzww5LMKsQvvvhCTz75pNatW6dLLrlEZ599tn3ttGnTdPbZZ+v666/XJ598ooMPPlg+n0+LFi3Sk08+qVtvvVXHH3+8SktLdfPNN+uMM87Q5MmTdcopp6iiokILFixQY2OjHnjgAbndbv31r3/VYYcdpvHjx+u0007ToEGDtHr1as2bN0+lpaV6/vnn2/V7rays1H777afTTjtN69ev1y233KLRo0frzDPPlKQO3dMtt9yiO+64Q/vss48KCwvtf/OEY445xv4fCP7nf/5H99xzjw4//HD94he/kM/n00033aR+/frpkksuSXnd888/rwULFkgy/4eITz/9VNdee60kswV24sSJGjp0aMb5kpJ04YUXql+/fjr66KPb3P+kSZN055136tprr9Xo0aPVt29fHXjggZo9e7Yee+wxHXbYYbrgggtUWVmpBx54QMuWLdM//vGPvM8VHTZsWJu/+6WlpZo6dar+8Ic/KBKJaNCgQXrppZe0bNmyFl8zc+ZMHX/88ZKUNQjPpit/ZpI0e/Zs/fjHP9Zee+2ls846SwUFBXrsscf04Ycf6tprr00ZWAUAQLfWRdOiAQDYbtx3332GpJSvYDBo7L777sadd95pxOPxlOslGVdccUXK2jXXXGMMGjTIcLvdhiRj2bJl9nN/+9vfjO985ztGIBAwKioqjGnTphlz585Nef3tt99ujBkzxvD5fEa/fv2Mc88919iyZUvKNbNmzTKGDRtmP162bJkhybjxxhszvqdse2zp+37ttdeMs846y6ioqDCKi4uNH/3oR8bmzZtTrh02bJhx+OGHZ32fYcOGGbNmzUpZ27x5s3H++ecbgwYNMvx+vzF48GBj1qxZxqZNm+xrwuGw8fvf/94YP368/W8zadIk46qrrjJqamoMwzCMV155xTjqqKOMgQMHGn6/3xg4cKBx8sknG998802r35thGMa0adOM8ePHp6y19m9mGIbx8ssvG1OmTDEKCgqM0tJS48gjjzS++OKLlGuuuOIKQ5KxcePGlPVZs2YZRUVFOe0jm2HDhtm/fy6XyygtLTXGjx9vnHnmmcb8+fNbfN3dd99tTJo0ySgoKDBKSkqMCRMmGJdeeqmxZs2alOv++c9/Gvvuu6/9ve25557GY489lnLNxx9/bBx77LFGr169jEAgYAwbNsw48cQTjVdeeaXdvv958+YZkozHHnvMuOyyy4y+ffsaBQUFxuGHH26sWLEi4/XbsqeWzJo1K+Nv3vnl/Ps1DMNYuXKlcfzxxxulpaVGcXGxccQRRxiLFi3K633vu+++VvfU2t9YunXr1hmHH364UVJSYkgypk2bZj+3ZMkS4/jjjzfKy8uNYDBo7Lnnnsa//vWvnN43lz0k/rvx/vvv22urVq0yjjnmGKO8vNwoKyszTjjhBGPNmjUt/ncoFAoZFRUVRllZmdHU1JTT3rrDz+zFF180pk2bZvTu3dvw+/3GhAkTjLvuuiun/QMA0F24DKOdT1IHAAA7hPvvv1+nnXaa3n///ZRp1QDQkaLRqAYOHKgjjzxS9957b1dvBwCAHQpnJAIAAADoMZ599llt3LhRM2fO7OqtAACww+GMRAAAAADd3vz58/Xpp5/qmmuu0Xe+852sU5cBAEDHoiIRAAAAQLd355136txzz1Xfvn314IMPdvV2AADYIXFGIgAAAAAAAIA2UZEIAAAAAAAAoE0EiQAAAAAAAADa1KOHrcTjca1Zs0YlJSVyuVxdvR0AAAAAAACgRzEMQ3V1dRo4cKDc7tZrDnt0kLhmzRoNGTKkq7cBAAAAAAAA9GgrV67U4MGDW72mRweJJSUlksxvtLS0tIt3AwAAAAAAAPQstbW1GjJkiJ2ztaZHB4mJdubS0lKCRAAAAAAAAGAr5XJsIMNWAAAAAAAAALSJIBEAAAAAAABAmwgSAQAAAAAAALSJIBEAAAAAAABAmwgSAQAAAAAAALSJIBEAAAAAAABAmwgSAQAAAAAAALSJIBEAAAAAAABAmwgSAQAAAAAAALSJIBEAAAAAAABAmwgSAQAAAAAAALSJIBEAAAAAAABAmwgSAQAAAAAAALSJIBEAAAAAAABAmwgSAQAAAAAAALSJIBEAAAAAAABAmwgSAQAAAAAAALSJIBEAAAAAAABAmwgSAQAAAAAAALSJIBEAAAAAAABAmwgSgZ7sxcukOZd39S4AAAAAAMAOgCAR6Kkaq6R375Deud28DwAAAAAA0IEIEoGeyjCS98MNXbcPAAAAAACwQyBIBHqqeCR5P9LYdfsAAAAAAAA7BIJEoKeKOYLEUF3X7QMAAAAAAOwQCBKBnspZkRiq7bp9AAAAAACAHQJBItBTUZEIAAAAAAA6EUEi0FM5g8RmKhIBAAAAAEDHIkgEeqo4FYkAAAAAAKDzECQCPVUsmryfFiQ+9O4KnfngB2qOxDp5UwAAAAAAYHtFkAj0VK0MW/nNsws194v1emHh2k7eFAAAAAAA2F4RJAI9VSycvO+oSHRWIfo8/IkDAAAAAID2QcoA9FQttDav2tJo3y8OeDtzRwAAAAAAYDtGkAj0VC0MW/m2KhkkRmNGZ+4IAAAAAABsxwgSgZ4q1kKQuNkRJMbjnbkjAAAAAACwHSNIBHqqFisSm+z70TgViQAAAAAAoH0QJAI9VUsVibQ2AwAAAACADkCQCPRUziAxnAwS19YkKxIjMVqbAQAAAABA+yBIBHoqZ2uzY4Lz+tpm+z6tzQAAAAAAoL0QJAI9lSM8TISK4Whcm+rD9nKUikQAAAAAANBOCBKBniqlItEMDzfUNadcEuGMRAAAAAAA0E4IEoGeKpasPJQRl+LxlLZmSYrR2gwAAAAAANoJQSLQUzlbmyUpHtG6mlDKUiROazMAAAAAAGgfBIlAT+VsbZakWFjr0ioSo7Q2AwAAAACAdkKQCPRUsfQgMZLR2sywFQAAAAAA0F4IEoGeynlGoiTFo6pqSF2LcEYiAAAAAABoJwSJQE8VTzsjMRZWKGpWIPq95p82FYkAAAAAAKC9ECQCPVWW1uZQJCZJKvJ7JElRKhIBAAAAAEA7IUgEeqr0YSvxqMJWBWKh3yuJYSsAAAAAAKD9ECQCPVUss7U5bLU2FwUSFYm0NgMAAAAAgPZBkAj0VOnDVmIRO0hMVCRGqEgEAAAAAADthCAR6KmytDaH0isSGbYCAAAAAADaCUEi0FO10tpsn5HIsBUAAAAAANBOvF29AQBbKb0iMRZR2Gpltqc209oMAAAAAADaCRWJQE8VS29tdpyRGEhUJNLaDAAAAAAA2gdBItBTpQeJsYhC0ZikZEUiw1YAAAAAAEB7IUgEeqosrc3JYStUJAIAAAAAgPZFkAj0VK21NlORCAAAAAAA2hlBItBTpVUkGtGwwrHUqc0xpjYDAAAAAIB2QpAI9FSJikRfofkwGpFh5YZFgcTUZlqbAQAAAABA+yBIBHqieddLG78y71tBYjQatp8usioSaW0GAAAAAADthSAR6IleuyF5P1GRGAnZS4nWZoatAAAAAACA9kKQCPR0/kSQaLY6e90u+b3mn3aUikQAAAAAANBOCBKBns5XIEmKRc2KxIDXLY/bJUmKUJEIAAAAAADaCUEi0NO5zTbmeMQ8I9HvdcvnMYPEGBWJAAAAAACgnRAkAj2Ry5zKrBFTpQG7STKnNktmkOh1m3/akThBIgAAAAAAaB8EiUBPE4tIRsy8f+KDkscvSYrHMisSozFamwEAAAAAQPsgSAR6mkhj8r63QPL4JCVbmwNej7wehq0AAAAAAID2RZAI9DSRZuuOS/IGJLcVJMas1maPW16GrQAAAAAAgHZGkAj0NNEm89YblFwuuyLRiDnOSEwMW+GMRAAAAAAA0E4IEoGusHaB9Nat5nmH+UpUJPqC5q0VJCqaPCPRHrYSM2QYhIkAAAAAAGDbebt6A8AO6S9TzVtPQNr7nPxem6hI9BWat2mtzQHHsBXJrEr0Oh4DAAAAAABsDSoSga60dkH+r4k4WpulZEWiI0hMDFuRpCjtzQAAAAAAoB0QJAI9TSJI9BWYt3aQ6GxtTlYgRmIMXAEAAAAAANuOIBHoaaLWGYmJikSrtVnx5NRmn7MiMUZFIgAAAAAA2HYEiUBP02JFYlSSWZHoKEiktRkAAAAAALSLbhMk3nDDDXK5XLrwwgu7eitA95YRJPolSa642doc8HrkcrnsgSvhWFwPvL1cX62r7fStAgAAAACA7Ue3mNr8/vvv6y9/+YsmTpzY1VsBOtlWVAtmtDabf8aueLIiUZJ8HrcisZgeeXeF7vjvEknS8hsO37btAgAAAACAHVaXVyTW19frRz/6ke655x5VVFS0em0oFFJtbW3KF7DDaaG1OT1IDPo8kqT3l1d17v4AAAAAAMB2qcuDxPPOO0+HH364DjrooDavvf7661VWVmZ/DRkypBN2CLQz6yzDrZZekZjW2uy3Bq0ErUAxFGVqMwAAAAAA2HZdGiT+/e9/10cffaTrr78+p+svu+wy1dTU2F8rV67s4B0CHSAWSt43tqK1OdJo3iYqEq1bX8wMGAM+K0j0mxWJYYJEAAAAAADQDrrsjMSVK1fq5z//uebOnatgMJjTawKBgAKBQAfvDOhg0VDb17QmYlUkJoLEYJl5E6uT5KxIJEgEAAAAAADtp8uCxA8//FAbNmzQd7/7XXstFovp9ddf1+23365QKCSPx9NV2wM6jjNIjG9Fm3PUOiPRawWJgVJJUjDeYD60z0jMbG2Oxw253a78PxMAAAAAAOzwuixInD59uj777LOUtdNOO01jxozRr371K0JEbL8SZxym38+VXZFoVfIGzSDRb4TlV8QetlKQaG2OJYPE5mhMhf5uMawdAAAAAAD0MF2WKJSUlGjXXXdNWSsqKlKvXr0y1oHtirMicWvanFuoSJSkEjUqYLU0J1qbQ5GY/Xxj2AwSY3FDDeGoSoO+/D8fAAAAAADskLp8ajOww3EOW2mPikS3R/KXSJJKXI12RWLQZwaJtc3J9ummsBkqnv3QB9rrd69oU/02ntcIAAAAAAB2GN2qx/G///1vV28B6HjbWpEYC5u3Hn9yLVgqhetUoqbksBVf5vEAjVaQ+NnqGjVFYlqxuVG9ixlgBAAAAAAA2kZFItDZtvWMxFjEvPU42pKtyc2lrgZHRWLmn3dj2KxObI6Y5yYahpH/5wMAAAAAgB0SQSLQ2aJhx/2tqEiMW0Gi2xEkWucklqjJMbU5syKxyTovsdm6jcUJEgEAAAAAQG4IEoHO5qxCjG1Na3O2ikQrSHSckViQLUgMx2QYhkJRsyIxRkUiAAAAAADIEUEi0NlSWpvbK0i0WpvV2EZrc8wOESUpHs+4BAAAAAAAICuCRKCzxZytzVtxRmIrrc2lrsbWW5vDMYUiyfSQikQAAAAAAJArgkSgs7VQkfjRt1s0+Xcv68kPVrb++tZam9WogNcMELNPbY6qORqzH8cJEgEAAAAAQI4IEoHO5mxnjjZLVph368uLtLEupF8+9Wnrr7eDRH9yzWptLklpbc4SJEZi9qAVSYozbAUAAAAAAOSIIBHobM4g0YhL8agkqVdxMhisbY60/Hq7tdmbXPKbFYllrgb5PS2fkdgUjqnZ2dpMkAgAAAAAAHJEkAh0tvQBK1arc2VhMkh8f1lVy6/P0tocKeovSRrg2tzq1ObGcFpFIq3NAAAAAAAgRwSJQGdLH7ASNYevNDkCvgWralp+fZbW5lDJEEnSUNeG1lub06Y2x5jaDAAAAAAAckSQCHQ259RmyQ4WnUFiyDEQJUOW1ubmokGSpDJXo7xblkpqqbU5SkUiAAAAAADYKgSJQGfLqEg0HzsDvmislYAvS2tzyFWgjYZ5TqLr9knSV//OWpHYlD5shSARAAAAAADkiCAR6GwZQaJ5ZmJT2BkkttBzbBiOisRkkBiOxbXK6Ju87oO/ZQ0SozFDzVGGrQAAAAAAgPwRJAKdLZre2twkKbW1OdxSRaI14VlSakViJK5K1Saf6z8ha5AYjsVTKhIJEgEAAAAAQK4IEoHOFmlMfRw2HzdFkpWCLVYkJtqapZQgMRyL67X4bsnn3F4V+71KF40ZCtHaDAAAAAAAtgJBItDZ0oNE63Gzs7W5pUrBuCNIdLY2R+O6MfpDx3VRlRX61K80kPpRsbiaHYElBYkAAAAAACBXBIlAZws3pD2ul5Ta2hzJtyIxGledCvVU4BhzwWqBfvD0vVQaTFYmRmLxlInQtDYDAAAAAIBcESQCnc1qZbYrCu3W5hymNieCRJdbcifPQLTDQbcVGsbNx7v0L9Fbsw/UfadONj8qZqRVJBIkAgAAAACA3GQeogagY0WsisSiPlLdmhZam1uoSMwysVkyKxLN9USQaA1licdV8splGuIdJWmoogxbAQAAAAAAW4kgEehsidbmYitItB6ntja3UZHo8ae+pdUK7fJ4U6/7+t/S+/dotCTpUfOMRFqbAQAAAADAVqC1Gehsidbmoj7mbaRRkVg8ZcBKixWJdpCY+r8BhKyKRCO9IrFmdcp1kbTWZjqbAQAAAABArggSgc5kGPZwFTtIDDemVCNKrVQkttDa3GS1RXsSA1isMxIVrku5Lpze2kySCAAAAAAAckSQCHSmaLMkK7yzg8T6lPMRJSna4tTmsHmb1tpcHzIrEL3eRJBoVSSmTYiOxOIpFYm0NgMAAAAAgFwRJAKdKdHWLKW0NqdXJEZbCvhiVkCY1trcGLaCRF96kNiYcl00ZiQnPEuKEyQCAAAAAIAcESQCnSnR1uwNSoESa23bW5sbQubrvT5/6nVpFYnhWFwhR0UiOSIAAAAAAMgVQSLQmSJWhaCvUPIXWWsN9hmHCdFYXKrfKG38OvX19rCV9CAxvSIxcUZiferHp09t5oxEAAAAAACQI2/blwBoN4kKQX+xGSZKWSsSo3FD+uNo88EFn0iVI8z7LQSJjVYQ6bcrErOfkWgYydBRorUZAAAAAADkjopEoDPZQWKh+SVJkcaUScqSFI46hq2s+iB5v4XW5sSwFV8bQaIk1TUng0QqEgEAAAAAQK4IEoHOlGht9hdJPqu1OVyvprAZHBb5PZKkaNwRJBqOkLHFikQzHPT704etpLY2S6lBIhWJAAAAAAAgVwSJQGdKVAj6HBWJ4UZ7knJx0DxtIOocthJPBn8tBYn11rAVnz9gXddyRaKzjTpORSIAAAAAAMgRQSLQmezW5iLHsJVGhaKJikQzSIzEHBWJziCxhdbmREViwN9ya7PH7crYjvNjAAAAAAAAWkOQCHQmZ5BotzY3KGQFgUUBqyLR2docb7u1OTFApbUg0efJ3A4ViQAAAAAAIFcEiUBnimRpbZahaLhJklQUMNM+V8xRhWg4QsVY2LzNCBLNsDGYESQmz0j0e7JVJBIkAgAAAACA3BAkAp0p7By2UphcD5mBX7FVkWjEw8nnnBWJiYDQ0docixv2uYeBgD/tNcmgMJCttZmKRAAAAAAAkCOCRKAzherMW3+x5PZIBZWSJE/zZknJ1mavkSU8lLK2NifOR5SkQCBovSYiRUMpHx3wZIaGBkEiAAAAAADIEUEi0Jmaa8zbgnLztrifJMnfvFGSVGgNW/GqpSAxs7U50dbscbvk9/mSr2muTflof5YzEmltBgAAAAAAuSJIBDpTIkgMlpm3xX0kSYHmTeZD64xEj7IMWJGytjY3JAa1+D1yeZxBYk3KRweznpG4Vd8FAAAAAADYAREkAp0pI0g0KxKDodTWZp8zSIw2J+9boeK8xVu0qd5sXU5MbC4KeM12ack8IzEtSMxWkcjUZgAAAAAAkCuCRKAztRAkFoatIDHR2uxqIUiMm0Hiks0h/d9LX0tKtjabQaLXui4qNW9J+Whflr92WpsBAAAAAECuCBKBzmQHieXmbXFfSVJRxAwSAz63fB6XfHKci5ilIjEir6oazPMSm6NmkBj0uZMtz7EIFYkAAAAAAKBdESQCnamFisTiSJUkKeB1y+t2pw5byRokelQaNEPDSNQ86NDvcTsqEjNbm4MEiQAAAAAAYBsQJAKdJRaRIg3mfTtINCsSS2KJINEjr8eVFiSG7LuGNbU5anhVWmAFiTEzDPR53I4zEqNSU3XKxzO1GQAAAAAAbAuCRKCzOCsEA6XmrVWRWBZLViT6PO4Wh62Em5vMt5JPJUGz+jBijV72e91pZySmViRmPyNxq78bAAAAAACwgyFIBDpLItjzl0geK/Ar7i9JKovXKKCwAj63vG6XPC1UJIZDjZKkkPxyyWWuWWmgz+OWPNYZiTkGibQ2AwAAAACAXBEkAp2ludq8TbQ1S1JhpeQrlCQNcG2W3+MxKxJbmNocDSUqEv12JWLEDhJdyYpEI5b8PEuAMxIBAAAAAMA2IEgEOkv6oBVJcrmksiGSpEGuTWZFYvoZiRFHkBg2g8SQ4UsGiVFHRaLbkRY2bk75eOcZiQGv+afPGYkAAAAAACBXBIlAZ8kWJEpSuSNI9JqtzV5Fk887KhLjEStIlM8espK4TZnaLEkNaUGiOxkaFgXM66hIBAAAAAAAuSJIBDpLS0GisyLR68kybMUxtdmqTjSDRLMSMeWMRGeQmFaR6DwjsdAqT6QiEQAAAAAA5IogEegsm5eYt6UDUtfLh0qSBrs2mhWJ6a3NjopElxUqZj0j0euS3L7k6+rXpXyMM0gs8lsViUxtBgAAAAAAOSJIBDrLqg/M20F7pK7bQeIm+b1ued0tVyS64+b9kOGzKxETQaLXnXZGYhrnGYkF1gNamwEAAAAAQK4IEoHOEItKaz427w+enPJUvNisUOyrLQp43fJ5XPKkBIlN0pbl0u17qk94tSSztTmafkai120Ob3E5EsNj/iIVVEqSCr0ue3nsgFJzWwSJAAAAAAAgR962LwGwzTZ8bgaCgTKp1+iUpyLugAKS/K6oAj6PvG63vK60isSXfiNt+tpecrY2h+2pzVZQ6PZKMev1Q/eRXOb/XvCDCf200hvQweP6qT4U1WPvfas4ZyQCAAAAAIAcUZEIdIaqZeZt37GSO/XPLmyYeb5fUfuMRF/6GYnWtOYE57CViHPYiiTJEQ4GSuwgsW+RT785Ypz2GtlLbrcZOlKRCAAAAAAAckWQCHSGxDmHvoKMp8IyW5F9isrrdinoNrSTa1Wrbxcy/HZLc0aQGAsnLwyUJM9NNJKTVTwuM0hk2AoAAAAAAMgVrc1AZ0hMXvYGM54KWRWJPkXlcrl0Yc0NGu+dl3rR0tTHqRWJ1hmJniz/u4DHZ1ckpgSJVkUiw1YAAAAAAECuCBKBzpCoEvQGMp5KBIl+V1SSNL56XsY1ikdTHibOSPzZYx/r+QVrJDnOSEyXJUi0ChIV44xEAAAAAACQI1qbgc7QakViorU5ltFrvLrXPlnfLiyv1lQ32yGiJPm8Lfw5J1JDR/VhorWZMxIBAAAAAECuCBKBzmAHif6Mp5qtIFGSFI+kPFcbzzxTUZIMudUUiaWs+bK1NkuttzZTkQgAAAAAAHJEkAh0hsSwlSwVifVhx5+hc1CKpOpYZvCYUNecGjpmnJHo9pm3dpCYDB7d9hmJrW0aAAAAAAAgiSAR6Ax2kJh6RmJtc0TLqh3hYSw1HKyKZJ6pmJAYspKQUZHoKzRvXZlTm92J1maSRAAAAAAAkCOGrQCdIUtFomEY2uPalxWOxnVywC2vK568zrIl7DIrC9NanrPJGLbisz4rW2uzi6nNAAAAAAAgP1QkAp0hcUaiJ1lhGI0bCkfNcC+SyPTTWptrwpLhy35OYrqMYSuJ12UJEt3WEhWJAAAAAAAgVwSJQGfI0tociSWDvWSQmFp5GI57FPe0fE6iU8YZid6Wg0R72AoViQAAAAAAIEcEiUBniGW2NkeiyRAv3EJFYkQexdyZA1qyyTwjMS1IjCeHrSRbm3N6awAAAAAAAIJEoFNkq0iMJysEk0Fi6hmJMXkU97Q8cMUp84zExLAVa91Rfehi2AoAAAAAAMgTQSLQGRJnJLbU2mxkb22OyqNYzkFi2p9zxTDz1p05tdlubSZIBAAAAAAAOSJIBDpDtopER2tzS8NWzNbm3IJEf2LYykmPSjsfJn3/GvNxK1ObY5yRCAAAAAAAcuTt6g0A27WXr5Jq1zgqEpPnHYazDltJDRJj8iiaY5BoVySOOdz8SmBqMwAAAAAAaAcEiUBHMQzpzZusB9Y5hS20NocSf4rR1CDRp2geQaIr+xOtTG2mIBEAAAAAAOSK1mago0QaHQ+sxM7TwhmJiSAx5TVSQJGUIDFsePTb0muzfpw//YzEBDtITE5tdtPaDAAAAAAA8kRFItBRQvWZa47W5qzDVsINKZcHFFHY5bcfHxa+QUs2DJLLlVlNmDFsJSFbazNTmwEAAAAAQJ6oSAQ6SjhbkOioLnQMW9llUC9rMTVI9LsiiriSrwnJp4sO2lk+d+afrncrWpslJjcDAAAAAIDcECQCHSVUl7nmqEiMxs1gb+yAUvUqLTYX08JHv6IpFYmDepXp7Gkjs56H2HZFYjIwTExtlmhvBgAAAAAAuSFIBDpK1orEZCiYaG32e1zJ9bSKxK/iQ5LnJ0oaM7iPgj6PfN7MP928Wpsdl8YJEgEAAAAAQA4IEoGOkhYKSkqpSEy0Nns9bsmTGSQ+N/BiPRvfT46jFO3W6GyhobNdOUUrZyRKUjye/gIAAAAAAIBMBIlAR8na2pw5tdnncWUGicEyfdz/eMXlTmk99visILGl0DCbRJAYT05tdoaOtDYDAAAAAIBcMLUZ6ChZW5uDao7E9M36OoWiiSDRLXl8qa/x+OW32pejRjL0c1vXRfIZkNJGRSKTmwEAAAAAQC4IEoGOEsoSJHr8uuTRj/Xvz9Zqt8FlkiS/xy15rErFREWix2+uSymtzV5rbWNdKOVtK4v8apHbY94ytRkAAAAAAGwDgkSgo6RXJHoCksulf3+2VpK0YFWNpPSKxESQ6EtWJDqCRL81rfmo3Qdqzufr9NeZk7VL/xIVB1r5U85akZh8mmErAAAAAAAgFwSJQEdJDxIdg1acfF7nsBXrNe5kkBhz5HyJisSbT9xddaGoygp8be8j0cbsCBJdLpdcLskwOCMRAAAAAADkhmErQEdJb212DFpxyjpsxdHaHE0JEs1Q0O125RYiSlkrEiXJa5UlckYiAAAAAADIBUEi0FHSKxJ9LVQkultvba5WqX1tIlzMSwtBoocgEQAAAAAA5KFLg8Q777xTEydOVGlpqUpLS7XPPvvohRde6MotAe0nvSKxuL+MLG3EPq8rWa3orEi0gsRXin6gj4qn6ReRs+0qwry4MoetSJLXnRjmQpAIAAAAAADa1qVB4uDBg3XDDTfoww8/1AcffKADDzxQRx11lD7//POu3BbQPtIrEksHqj4UzbjMHLaSdkaix6+AFSQ2xLz6S7/f6qnYNPuMxLy0UJGYyCSjBIkAAAAAACAHXTps5cgjj0x5/Lvf/U533nmn3n33XY0fP76LdgW0kyxBYk1TJOMyv3Nqs6xQz+O125i/WV+vQeXB5LX5aumMROu94gSJAAAAAAAgB91manMsFtOTTz6phoYG7bPPPlmvCYVCCoVC9uPa2trO2h6Qv/TW5tKBqm7MDBJTKhITPH4FfGbQt6k+pE315u99YthKXto4I5GKRAAAAAAAkIsuH7by2Wefqbi4WIFAQOecc46eeeYZjRs3Luu1119/vcrKyuyvIUOGdPJugTw0VaU+Lhmg2iwViWaQmDbR2eOX3+PJuLY9W5uZ2gwAAAAAAPLR5UHiLrvsok8++UTz58/Xueeeq1mzZumLL77Ieu1ll12mmpoa+2vlypWdvFsgR/GY1JgWJJYOytra7PO6pGBZ6qJjarOTf6sqEl3JPTk/gopEAAAAAACQhy5vbfb7/Ro9erQkadKkSXr//fd166236i9/+UvGtYFAQIFAIGMd6Haatsg+7zChdIBq1mcJEt1uqbhv6qJjarNTYtJyXtyJqc2p+0lWJMbTXwEAAAAAAJChyysS08Xj8ZRzEIEeqWFj5lrJAFVnbW12ScX9UhfdvqyDVXxZwsU2tXVGYoyKRAAAAAAA0LYurUi87LLLdNhhh2no0KGqq6vTo48+qv/+97+aM2dOV24L2HYNm8zbXjtJY4+QCiolb0BrqpsyLvV53VJRb0kuJac2Z29t9rnbb9hKorqRMxIBAAAAAEAuujRI3LBhg2bOnKm1a9eqrKxMEydO1Jw5c/T973+/K7cFbLtGK0gs6iMddKUkaUNts578YJUkac8RlXpvmXmGojlsxScV9kq+zuNXIFtrczsOW3FzRiIAAAAAAMhDlwaJ9957b1d+PNBxEhWJRb3spTlfrFdTJKYJg8p0/KTBdpBotzAX93MEiS1UJG7VsBWmNgMAAAAAgG3X7c5IBLYLiSCxsLe91BSOSpJ26lusikK/ve6zg0THwBVPC2ckblNFYvapzQSJAAAAAAAgFwSJQEdIDFsp6mMvJVqIPW6Xygt99rpdZegMEitHZZ/a3AEVibQ2AwAAAACAXBAkAh3BPiMxWZGYmI7s9bhVXuAMEq0/w9o1ydePO0oFPk9GmLhtFYnZpzZTkQgAAAAAAHJBkAh0hEbz/EMVJs9ITFT+ed0ulTkqEhOBnr4707zd6WApWCq326UP/vcg7dKvxL7W596WIDE1MExUN0bj8fRXAAAAAAAAZOjSYSvAdisaMm+9weRSzAzsvB6XyhwViaGoFeTtepxUMkAasqf9XGnQp76lAX29vs5+bd5arEg016lIBAAAAAAAuSBIBDpCLGzeepJDVWKOisSA12OvN1pDWOT2SCP2z3gr57Xt2drMGYkAAAAAACAftDYDHSEWMW89ycrDiOOMRKeRvYtbfSu/N1mF6NuWisQ4U5sBAAAAAMDWoyIR6AhZKhITZxH6rABv7kVT9W1VoyYMLmv1rdyuZHiYHkLmxG1VNKa3NruoSAQAAAAAALkjSAQ6QtYg0QzsEmcT7tSvRDs5Bqm0JNGCLG1jRWJ6kGi9VyzGsBUAAAAAANA2WpuBjpCltdk5bCUfHsek5q2b2mx9XgtnJMYoSAQAAAAAADkgSAQ6QisVic4Kw1w4u5ndeb5WUitTmxNnJFKRCAAAAAAA2rZVrc3V1dV67733tGHDBsXTQoiZM2e2y8aAHs2uSHQEiS0MW2mLZ2uqEJ3sIDG19JCpzQAAAAAAIB95B4nPP/+8fvSjH6m+vl6lpaVyOQZBuFwugkRAclQkJlubY1tZkZjv9RnsIDF9arO5HqO3GQAAAAAA5CDvUqdLLrlEp59+uurr61VdXa0tW7bYX1VVVR2xR6DnydLaHNnqMxK3NUjMPrWZikQAAAAAAJCPvIPE1atX64ILLlBhYWFH7AfomapXSs215v14LFn9l+WMxHwHpmx7kNjWGYkEiQAAAAAAoG15B4mHHHKIPvjgg47YC9AzVa+UbtlV+r8x5uPE+YhS6tRmK7DLNxhsv9ZmKhIBAAAAAMDWy/uMxMMPP1y//OUv9cUXX2jChAny+Xwpz8+YMaPdNgf0CMvfNG8jDeZt3BkkOoetbF1r81ZNanZiajMAAAAAAGgHeQeJZ555piTp6quvznjO5XIpFotlrAPbt7SKvjYqEr15tjYHvZ6t3pkkKTEQqcUgcdveHgAAAAAA7Bjybm2Ox+MtfhEiArIHrRgujzY3Ru3lra1IPHXf4RrZp0g/O3D01u0nUZEYT/379FKRCAAAAAAA8pB3kAigDVaQGDI8mnTty1pZ1Wgu2xWJ+QWJZYU+vXrJ93TJwbts3X7cianNqZWTHqsykjMSAQAAAABALnJqbb7tttt01llnKRgM6rbbbmv12gsuuKBdNgb0GM6ALh6zW5vDhvnnNefzdTpj/5GKxKwg0dPJ+X1Lw1Y8TG0GAAAAAAC5yylIvPnmm/WjH/1IwWBQN998c4vXuVwugkTs2GIRuyIxnPbntbUVidusjWErVCQCAAAAAIBc5BQkLlu2LOt9AFLKsJVY2A4SI2l/XhHrLMLuEiQmz0gkSAQAAAAAAG3bph5LwzBkGIQQ2ME5/wZiEbu1OWKkTluOdnlrc+qwFSoSAQAAAABAPrYq0XjwwQc1YcIEFRQUqKCgQBMnTtRDDz3U3nsDeoZ4cjJzaxWJ3a21manNAAAAAAAgHzm1NjvddNNN+s1vfqPzzz9fU6ZMkSS9+eabOuecc7Rp0yZddNFF7b5JoFuzKhAlSfGWz0iMxKzWZk/3CBLdiYrEGBWJAAAAAACgbXkHiX/605905513aubMmfbajBkzNH78eF155ZUEidjxWMGhed/R2txiRWJXtTanBoaJisQ4xxMAAAAAAIAc5J1orF27Vvvuu2/G+r777qu1a9e2y6aAHiUWctxvZdhKN6tI9FiBJmckAgAAAACAXOQdJI4ePVpPPPFExvrjjz+unXbaqV02BfQoztbmLEFi2AoQu+8ZiQSJAAAAAACgbXm3Nl911VX64Q9/qNdff90+I/Gtt97SK6+8kjVgBLZ7LbQ2hw0rSIyaAV4k3sVTm+MtTG3mjEQAAAAAAJCDvBON4447TvPnz1fv3r317LPP6tlnn1Xv3r313nvv6ZhjjumIPQLdW0qQmFmRGLKCxKhVmejrsorE1CCRikQAAAAAAJCPvCsSJWnSpEl6+OGH23svQM8UTa9ITGttjsYVjxtK5HWezg4SPT7zNh5NXU5UJMbj6a8AAAAAAADIkHdF4n/+8x/NmTMnY33OnDl64YUX2mVTQI/S4tRmjyQzSHQONOn01maP37x1Bp5KDn2hIhEAAAAAAOQi70Rj9uzZisViGeuGYWj27NntsimgR2lh2ErYbm2OpYR1nT5sJREkxlKDRLcrUZFIkAgAAAAAANqWd5C4aNEijRs3LmN9zJgxWrx4cbtsCuhRYiHHfccZiY5hKxFH+3CiErDTeLMHiV63+edPRSIAAAAAAMhF3kFiWVmZli5dmrG+ePFiFRUVtcumgB6lxdZmK0iMxRWLOSsSO7u1OWDeRkOpywxbAQAAAAAAecg70TjqqKN04YUXasmSJfba4sWLdckll2jGjBntujkgRf1G6fbJ0ut/7OqdpGqhtdk5bCVRkehydcGwFa8VJMZSg0TOSAQAAAAAAPnIO0j8wx/+oKKiIo0ZM0YjRozQiBEjNHbsWPXq1Ut//GM3C3iwfXnndmnTN9Kr13T1TlI5K/3ikSxnJMYVtSoSO/18RCk5tdkZeMo5tZkgEQAAAAAAtM2b7wvKysr09ttva+7cuVqwYIEKCgo0ceJETZ06tSP2ByRFGrvus2NR6ZWrpFEHSKMOTHuu9dbmUDRuV/11eluz1GJrs5fWZgAAAAAAkIe8U40HH3xQ4XBYBx98sH75y1/q/PPP19SpUxUOh/Xggw92xB4Bi6OaL9LUuR/90QPS27dJDx2T+VxLrc3OYSsxs7W50wetSMnWZiMmxZMT15MVifFsrwIAAAAAAEiRd5B42mmnqaamJmO9rq5Op512WrtsCsgq2py8X7eucz973WctP5dSkZj9jMRkRWJXtDb7k/cdVYlMbQYAAAAAAPnIO0g0DEMuV2YYsmrVKpWVlbXLpoCsGjYl79ev79zPdoaY4bQW6/TW5mjijESPJCkUjSmSOCPR0xWtzY4g0bFXzkgEAAAAAAD5yPmMxO985ztyuVxyuVyaPn26vN7kS2OxmJYtW6ZDDz20QzYJSJIaNiTvd3aQ6Awx69ZKvUYlH6dXJFpnOTYpKEkKx7q6ItGXvJ8lSIzFCBIBAAAAAEDbcg4Sjz76aEnSJ598okMOOUTFxcX2c36/X8OHD9dxxx3X7hsEbPWOILGuk4PELcscn91akBiRwvWSpEbDPJswHI0rEu/CMxJdLnPgSiyU1tpMRSIAAAAAAMhdzkHiFVdcIUkaPny4fvjDHyoYDHbYpoCsGjYm79d34hmJ8Zi0ZUXycfr5jNH0IDFRkWgGiaFoXNFYF05tlsz25lgoe0WiQZAIAAAAAADalneqMWvWLEJEdL5Qvd0yLKlzKxJrV0txx2Tm2jWpz7fQ2tyoZEViYjJyl7Q2S5LXOifRUZEY9JlnOIajca2rac72KgAAAAAAAFtOQWJlZaU2bTLPiKuoqFBlZWWLX0CHcJ6PKEmNm7Jf1xFCdamP0ysSY46QMRaWwg2SpAbDOiPRWZHYFcNWJLO1WUoJPSuL/Jo8vEKSdPfrS7tiVwAAAAAAoAfJqbX55ptvVklJiSTplltu6cj9ANk1bE59HKrvvM+OplXr1bVWkRixg8REa3M0bigc7SYVic69Sjpn2ii9v/wDvbhwrX575Lgu2BgAAAAAAOgpcgoSZ82alfU+0GmaqlIfh+uyX9cRHO3AkqTNS1IfxxzPZ2ltlqTGSExSFw1bkcwzEqWM72X8wDJJ0vq6kOJxQ+6uCjoBAAAAAEC3t019loZh6NVXX9W///1vbdmypb32BGRqtIJEX6F52xUViYnP3vSNOYBF0oWPfSAZ8eS1jtbmxNRmSapuNCsBg15Px+83G7u1OTVI7F3sl8slxeKGNjeEs7wQAAAAAADAlHOQWF1drVmzZmnChAk688wzVVtbq/33318HHXSQjjzySI0dO1affvppR+4VO7JGq7W5fKh5G04Gics3NWjh6pqO++xEFV+fXSRv0AwWtyxXLG5ozqcrU68N1Ukyz0NsclQkrqwyqxT7lgbUJezW5kjqsset3sXmnjbUMXAFAAAAAAC0LOcg8Re/+IXeeecdnXTSSfrss8906KGHKhaL6Z133tH8+fM1duxYXX755R25V+zIEq3NiSDRqkhsCsd07J1v68jb39Rzn6zumM+2KxKLpN47mfc3fqUtjWH5jNRgTs3V9t1GJaebf/Stud6nuIuCxERFYnqbtqR+Vri5oTbzOQAAAAAAgISczkiUpBdeeEGPPvqopk2bplNPPVVDhgzRq6++qr322kuS9Pvf/14zZszosI1iB5dobS4fZt5GGqR4XP/5bK2qrJbc/31moY6cOLD9z/lLhG/egFQ6Vlr3mbTxK20un6qA0tqBm8wW/5D8isutIr9HDeGYPlxhrndZRaLHZ97GMtuX+5UEtVC1Wl9LRSIAAAAAAGhZzhWJ69ev18477yxJGjRokILBoIYMGWI/P3ToUG3cuLH9dwhIma3NkhSu1z8+WmU/rAtFVd2UViHYHhIVid6g1Nv8G9DGb1S/bqkKXKnBXHOdGXgm2pr3GF6Z8nzfkqC6hLflisS+peae1lORCAAAAAAAWpFzkBiPx+XxJAdFeDweuVzJyi/nfaDdWZV+Kh0oua1C2lCdlm5sSLmsqqEDwrCUisSB5v1P/65Jz07VAe5PUi4NRmslJQetTB5ekfJ835KuqkhMnJGYWZGY2NN6zkgEAAAAAACtyLm1WZL++te/qri4WJIUjUZ1//33q3fv3pKkurq69t8dkJBobS6slPzF5lmE4Xo1hKKSJJdLMgxpc31Yo/tKWv6m9M4d0pQLpKF7b9tnOysSSwekPHWu959ZX9JgBYmThqVVJHbZsJXE1OYsrc1WReIGWpsBAAAAAEArcg4Shw4dqnvuucd+3L9/fz300EMZ1wAdItHaXFApBUqk5moZoTrVh80gcWhloVZsbtRm67xEvf9X6et/m18XfCxVjlQsbujeN5fqgF36aqd+Jbl/tl2R6JdKBqY8FTJ8kktaFu+nQa5N8rtikqQGq7V510Glqizy2+c49umq1uZERWJrw1bqaG0GAAAAAAAtyzlIXL58eQduA2iFYSSnNicqEiU1N9TIMMzlYb2KUoPEhk3J16/+SKocqX9/tlbX/ecrXfefr7Ts+h/k3o7fSkVixPoTqlWRmoygxrlWSJKaDDMwLPJ7NXl4heZ8vl6SVBrMqwi4/bTS2tzPPiORikQAAAAAANCynM9IBLpMuCEZgBVUSgEzSAw11EiS3C5pUHmBJKmq3rouHku+vtm8ztm6+8nK6tw/33lGYqA05akyV70kc7jKl0ayIrdRARX6PXK7XTpz/5GSpDH9S7ruLNFWWpsT7dYb60KKxY3O3BUAAAAAAOhBCBLR/YUdA1X8RXZFYqjBHGxSHPCqV5FZcWcPWwnXJ18TMs/v9LiTId5lT3+mcx/+MLdzAZ0ViWlBYB+XuYcmw68v4sPs9SYFVOg3qw/3GF6pf/1sP91/2p5tf1ZHaaW1uVdRQG6XFDekzfW0NwMAAAAAgOwIEtH9RZvMW2+BGeRZFYmRRkeQWGwGZZsSrc2RxuTrrSCxMZysUvxqXZ1eWLhOV/zz8xw+PxEktjwopUkBzYnvYT8e6Nqk4kByyvmug8rUv6yLzkeUWm1t9rhd6pOY3FxLkAgAAAAAALIjSET3F7GCPJ8VxPnNQSnRJitIDHpVmahITLQ2O6sYrSAxMeHZaeWWxoy1DHZrs/X5JQMyLom4g/JWDlfEMMPDjUa5XZHYLSRC0CwViZJjcnMd5yQCAAAAAIDscgoSL774YjU0mMHM66+/rmg0M5ABOkyiutBXaN4GzCAx1mwGhGZrsxmUJaYjK+ysSKyVDCOlIjHBk8uZhekViTOfkypHpVxy2HdHau7F03RS8A49Gj1Q10VPUZGjIrHL2RWJkaxP9y1JDFyhIhEAAAAAAGSXU5D4pz/9SfX15plzBxxwgKqqqjp0U0AK5xmFkh0kqrlaklQU8GpQhTlsZdmmBtU0hlPPSFzwmHTX/mpqzqy2c7tzCRLTKhL77CIdfUfKJf5gsXwet0LFg/Tr6BlaYfTvXhWJdpDYUkViorWZikQAAAAAAJBdTknH8OHDddttt+nggw+WYRh65513VFFRkfXaqVOntusGAUWsMxITFYllgyRJ/oY1kqSSoFfDexVqp77FWrShXi9/tlLHGWnVh+s/U2HBKqX/yrvzqkh0nHGYNr05sbeyAp+9VBzoRkGiv8i8bdqS9elEReK3VTm0egMAAAAAgB1STknHjTfeqHPOOUfXX3+9XC6XjjnmmKzXuVwuxWKZ7aPANrGDRCvIKx8qSSpsXC1JKvJ75XK5NGO3gfq/ud/otYXLdFyWt2kKx5T+K59ba3OiIjE5bCXmL1ZK47LPrIh0BomF/m7U2txvV/N2zceSYWRMn95juPk/DPzr0zU674DRGt23uLN3CAAAAAAAurmcWpuPPvporVu3TrW1tTIMQ19//bW2bNmS8UXLMzpEekVg+TBJUknTGkmGioNmOLjbkHJJUnVtTda3iYUzq+3cufwFZKlIDHtKUq/JUpFY1J0qEgdMNNubGzdLW5ZnPD1ldG9N27mPIjFDz32yuvP3BwAAAAAAur28pjYXFxdr3rx5GjFihMrKyrJ+Ae0uo7V5iCTJH29ShepUYgV2JVagGGuqz3gLSTKyBImevM5ITFYkhjwFqdf4zb0lhr5I3awi0RuQ+k8w79+2u7Tqw4xLJgwy/37rmhmmBAAAAAAAMuVdMjVt2jTFYjH94x//0JdffilJGjdunI466ih5PN0oOMH2I7212ReUivtL9es02LXJrvwrtaoBY+EWgsTE+zi4tHVnJDZHpTqjQCWu1JDzmO8O0u3zFkuSQtF42+/dmYbsJa22AsRvXpQGT0p5usAKPpuyTLcGAAAAAADIqyJRkhYvXqxx48Zp5syZevrpp/X000/rJz/5icaPH68lS5Z0xB6xo4taYZ3XUQVonZM42LXRbm0uDVptxYnKw6I+KW/jyhIkhmM5hH3RsHmbmHwsKRSNqU6O/VhnJI7qU6zfHDFOpUGvDp84oO337kz7/ix5v3pFxtMBr/mfg+YoQSIAAAAAAMiUd5B4wQUXaOTIkVq5cqU++ugjffTRR/r22281YsQIXXDBBR2xR+zoIlZFoM8ZJJrtzQNdm+zpyInW5kJZ1xf3T32faGaQ2BzJITTLUpEYisa10ShPXpNou5b00/1GaMEVB+u7Q7NPNu8ypQOl4/9m3t+SGSRSkQgAAAAAAFqTd2vza6+9pnfffVeVlZX2Wq9evXTDDTdoypQp7bo5QJIUsSoMnUFisFySVOpqUpHf/DUO+jzye90qjFtnGhaUp7yNO0uQmFNolu2MxEhcH8Z31m7updbeClNe4splGnRXKB9u3mapSAx6zSCxubu1ZAMAAAAAgG4h74rEQCCgurq6jPX6+nr5/f4srwC2UZaKQAXMqcnFalJhIHk2Z2nQp0KXdb2/KOVtAkYo461zauPNWpEY07vxsclrfGnDV7qrCnPiterWJis9LYmKxGYqEgEAAAAAQBZ5B4lHHHGEzjrrLM2fP1+GYcgwDL377rs655xzNGPGjI7YI3Z06VObJSlQLEkqUrIiUZJKg14VygwMVzW4pd1OsZ8LKpzx1k3hNqrvYlHJsII1Z0ViNK734mOS13l6SIhe2EvyWQFrzcqUp4I+zkgEAAAAAAAtyztIvO222zRq1Cjts88+CgaDCgaDmjJlikaPHq1bb721I/aIHV361GZJ8lsVia5mFTkqEksKfPYZiW+uaJSOuVP67ixJUoHC9kCRhDbPSGzcbN1xpQSZzZGYqlWipwpOkMYdJfXeeSu+sS7gciWrEtPOSQz6OCMRAAAAAAC0LO8zEsvLy/Xcc89p8eLF+vLLLyVJY8eO1ejRo9t9c4Akx9TmFlqb0ysSXWZFYpOsCkK/Wb1Y4AqpKOBVKJqsTGwzSFz3mXnba3RKkBmyzhF8ouynOv7EffL+lrpUyQBpwxdS/fqU5USQSEUiAAAAAADIJu8gMWH06NGEh+gc9tTmZEVg1Fckr6QiV5MK/WlnJFqtzQ2ygj/r/MKgwirwJa+VpGjcUCQWl8/TQnHu2k/M2wG7pSyHrLAt4Mu7qLfrFfYyb+1qS1OBXZHIsBUAAAAAAJCpB6Yg2OFkaW0Ouc1z/orVnFKR6Ha7FLSCxCYjYLbpWq8rUEglwczsvKm1qsR1n5q36UFixAzb0lule4REkNhUlbKcqEgMtVWlCQAAAAAAdkg9MAXBDsdubU5ORm5ym/eLXU3yO8K86sawClxm63Kz/Pq2qtGuZCxwhVUS9GrCoLKUt2+1vXltC0FiNBEketJf0f21VZFIkAgAAAAAALIgSET3Z7c2J4PERiWCxOaUS7c0hlVgTWduUkArNjektDaXBH26d9YeuvTQXezXNLfWytuw0bwtH5Ky3LNbmyvM28b0ikTze0m0ewMAAAAAADj1wBQEO5xIo3mbEiSaVYZFakq59Id7DFGB3drs1+rqpmRFokIqDnjVtzSo//neaFUW+c3rWqvAi2RWQ0pSc2R7qEjM3tos5TCEBgAAAAAA7HC2Kkh844039OMf/1j77LOPVq9eLUl66KGH9Oabb7br5gBJUjSzIrHOGqTiV1SKhuz1U/Yapt0HmNOamxRQfXM0WZFotTYnJFp5WwzNYlHJsJ7zBlKesisSe/IZiWmtzQGvWy6XeT8RlAIAAAAAACTknYL84x//0CGHHKKCggJ9/PHHCoXMEKempkbXXXddXu91/fXXa/LkySopKVHfvn119NFH6+uvv853S9jeZakKrI/7k8//9SApbFYtetwulXkikswzEuvDUft15rAVn/2yRCtvixWJUUe1oy+1ItEettIjW5uzB4kul0tBbxvhKgAAAAAA2GHlnYJce+21uuuuu3TPPffI50uGMlOmTNFHH32U13u99tprOu+88/Tuu+9q7ty5ikQiOvjgg9XQ0JDvtrC9MgwpXG/e9xfZy/URl5oN6/dv3afSV/9KvsYKHpsMsyLxP19VS5IKlFaR6DdDs7rmaPbPdlQ6ypNekbgdtDY3bZHiqZWHbYarAAAAAABgh+Vt+5JUX3/9taZOnZqxXlZWpurq6rze68UXX0x5fP/996tv37768MMPs34GdkCRJiluBX3BUnu5MRxV0BVJXhcLp75GUrN8qmmK6C+frdUPApmtzTv3LdHC1bX6+Nst+v64ftk/WzJDRHcyc19Z1aiH3l0hqYe2NhdUmrdGTArVSAUVyad8Hm1RhIpEAAAAAACQIe8UpH///lq8eHHG+ptvvqmRI0du02ZqamokSZWVlVmfD4VCqq2tTfnCdi5k/YxdbslfbC83hNKCroZNyfvWcJYmBbRqS5OaZFYTBtMqEqeM7i1Jemux47VO9tmMwZTlXz/zmX3fOaCkx/D6JX+Jeb+FgStNYYJEAAAAAACQKu8g8cwzz9TPf/5zzZ8/Xy6XS2vWrNEjjzyiX/ziFzr33HO3eiPxeFwXXnihpkyZol133TXrNddff73KysrsryFDhmz156GHaLaCxECJ7EkgMisSU9SvT95PtDbLr1VbGtUk8zzFAoVUEnC041tB4mera1TT6KhuTEgEid7UIPHDFVvs+z6PSz1Skfm9q3ZNynIiSGyOMmwFAAAAAACkyjtInD17tk455RRNnz5d9fX1mjp1qs444wydffbZ+tnPfrbVGznvvPO0cOFC/f3vf2/xmssuu0w1NTX218qVK7f689BDJCoSA2Upyw3pFXN1a81bw7ArEpuNgDbVh1VvmINSilwhlfqSr+tfFlT/0qDihrRsc5ZzOSPZg8Q9RyQrZjfWhdQj9R1n3q5fmLKcODeSikQAAAAAAJAu7yDR5XLp8ssvV1VVlRYuXKh3331XGzdu1DXXXLPVmzj//PP1r3/9S/PmzdPgwYNbvC4QCKi0tDTlC9upRIjXbLa7O89HlKTGUFQzQteoOjDIXKizKhKjIUmGJNmViFtUorBhBmQV8eqU9ykvNCsUa5tyr0g0jOT94ye1/PvarQ2YaN6u/TRlOTFs5ZyHP9Rp973HWYkAAAAAAMCWd5BYU1Ojqqoq+f1+jRs3TnvuuaeKi4tVVVWV95mFhmHo/PPP1zPPPKNXX31VI0aMyHc72B599W/pd/2lDx9wVCSmBokN4Zg+NUZp3tgrzYX6deatVY0oSc1WkCi5tEHmQJHS6OaU9yktsILE5laCxLQzEkNRM1z708nf0bBeRemv6hn6TzBv16UGic2RZEvzvK836p2lqf9eAAAAAABgx5V3kHjSSSdlbT9+4okndNJJJ+X1Xuedd54efvhhPfrooyopKdG6deu0bt06NTU15bstODVtkWLRtq/rrv5+iiRDev6C5BmJaRWJ9c3m9+cq6W8u1K232prN3x3D7VPUMZR8o1EuSSqOpA5WKQ2aQWJNtorExNRmb0HKciJs65GDVhL6WxWJG7+Svn5B2rxEkjRxcGoL+cJVNZ29MwAAAAAA0E3lHSTOnz9fBxxwQMb69773Pc2fPz+v97rzzjtVU1Oj733vexowYID99fjjj+e7LSTUrJb+uIv0+I9SlhtCUW2q74Hn+bVQkVgXMoM/T6kVJEYapFBdMkj0pYZ/G6wgMRjamLJelqhIbMoSvEatfy9vIHVL1iCSgDfvP5/uo2ywVD5Uikelx04yvyT96tAxeva8Kbr8B2MlmYNoAAAAAAAAJDlKtnIUCoUUjWaGLpFIJO9KQsN52Bzax/qFUiwkLXlVikUkjxmU/eTe+Vq0oV4vXTRVA8oK2niTbqSFisQ6qyKxsLjMPMMw2ixVfyv946fmBS0EiR7ndGdJpQXmn0DWisRoU9b3ClnnBvboikSXS5p6qfTP883Hm76RqlcqWD5Euw8pt89GXEiQCAAAAAAALHmXVO255566++67M9bvuusuTZo0qV02hW3QaJ1pFwtLG7+WZIZkH31brbrmqH71j8+0dGN9F24wTy1VJFpBYknQJ/kKzcW3/2S26kpy+QrldiWv323cGPNO4ixFS1mrZyRuxxWJkrTbydJupyQff/uOfXf8QPPfe01Ns2oas/zbAAAAAACAHU7eFYnXXnutDjroIC1YsEDTp0+XJL3yyit6//339dJLL7X7BpGnBscZgOs+k/rvqq/X1dlLr3+zUafe975evzSzPb1bamFqc50V/JUEvWaQ2FQl1a21n3d5/Crye1UXMgNHf9lA64VpFYlbdUbidlCRKEker3TMnVJhpfTO7dKKt6WJJ0oyA9ryQp+qGyNaV9usMmu6NQAAAAAA2HHlXVI1ZcoUvfPOOxoyZIieeOIJPf/88xo9erQ+/fRT7b///h2xR+Sj0RkkmhN5v1qXOk3726pGxePZ28rnfL5On3WnARt2a3PqEJBauyLRm2w9djuCvfp18jsqBoOVA+11p+QZiflMbd5OKhITBk82b9MmOPctMSsx19c2d/aOAAAAAABAN5R3RaIk7b777nrkkUfaey9oD4nWZklaawZDX641KxIDXrcdgjV8+4lKXrpYmv5badQB1nW1OvuhDyVJy284vBM33Yosrc2haExh6/soCfokv9XaXOcICZtrtLk5bD8cPHioeafB8e8jqbSlIDEWSQaJ3tQgcbupSEwoG2zeplVr9i0J6pv19dpQ1wOH9AAAAAAAgHaXU0lVbW1tyv3WvtDFnEHZus8kw7ArEm88YTcVWOFXwdMzpTUfSQ8dbV++dGNDZ+40u3gsed/lcbQ2JysS65uTw36KA97kGYm1q7O+5f479Za3qMJ80JxabZk8I9ExQOiTR6XrBkqfP2s+dgSJ0VhcUauac7upSCzuZ97Wr5ccA5ASFYkb6qhIBAAAAAAAOVYkVlRUaO3aterbt6/Ky8vlcrkyrjEMQy6XS7FYLMs7oNM4W5tDNVL1Ci3bZAaEo/sUq6zAp6ZITO6G9S28gSkai8vr6YKgzBn0uT1S1VJJklEyQDfP/UY79yvWrgPNULE44JXH7Uq2NjtfGyzTHcd9V//8ZI2uO3aC5LIGzEQaUqZZZ53a/Oy55m3VEvPWESSGY/HkR2wvFYmJIDEekRqrpKJekqQ+pVaQWEtFIgAAAAAAyDFIfPXVV1VZWSlJmjdvXoduCNso0drs8khGTPXLP1J1oxkIDe9dqPJCn9bVNstQZhjszIcbQjGVFXZBkNi0JXk/Fja//CV6q6aPbnvlA0nS8+fvJ8mqRpSSFYkJRX2kHz+tHwwYoB9MGGC9l2NYS3ONVNRbUuoZiYkwPIPjjMTmSDJI3G4qEr1+qaDSHFhTv84OEvuWmN/3RlqbAQAAAACAcgwSp02bJkmKRqN67bXXdPrpp2vw4MEdujFspURr8+A9pJXzVbf8I0n7qH9pUIV+r30moJGlqz3iqLZrCEe7ZlJvc3Xm2uBJ+rY6GWalTGyWkhWJCcfeLQ2YmLrm8Ur+EilclxIkJqY2R+OGGsMxFQWy/Ek4pjaHombFrd/jltudJXTsqUr6W5Ov10n9xkuitRkAAAAAAKTKq6TK6/XqxhtvVDQabftidL5o2GxnlqRh+0qSIpvM1uDhvc2qvTI7SMwMwRrDybb0hlAX/YydFYkJg/dUUyS5ty2NbQSJwfLs711grTvCykJ/sj3Z/v5daX8W3oB9N1GRuN1UIyY4z0m09Cs1KxIZtgIAAAAAAKQ8g0RJOvDAA/Xaa691xF6wrey2ZrdUOVKSFGswg7kRvYskJYPEuONlz3y8SlJqeFjfVUFi7drMtX7j7UnJkrSu1qyQK7GqCTNamwsqsr93YmCL4yxFl8tlD6CxP8MxIdp8/8yKxIBvOwsSS/qbt47J14mKRFqbAQAAAACAlGNrs9Nhhx2m2bNn67PPPtOkSZNUVFSU8vyMGTPabXPIU/W35m3JQPPMO0mGVX03vFd6kJgMwi56fIGm7dw3rSKxC4bmNFZJc3+TuV7cT7UrksNQ1ttBYgtnJLYVJDZVpy773GqKxJJVj4HS1BbrrBWJ28mglYQsQWLid6UxHFMkFpevK4bvAAAAAACAbiPvIPF//ud/JEk33XRTxnNMbe5iiSnDvUZqVbNfgyUZjWZF4i79S6TatRrkNh/HjdSXPr9gjVZsbrQfd0lF4pqPzNbm0sFSqNb8kqTivtpUX29ftnSjOYU6a0Wiy51ZUZiQaHl2TneWVODzaIsijorEktTXOc9IjGynFYlFfc3bho32kh3USqprjqqyyN/ZuwIAAAAAAN1I3kFiPB5v+yJ0rg8fkD59Quqzs/m4cqTueHezrpNU6jJDt4n9g9JNQ3SaXLpeDygcl5K1pIau+OfnKW/ZJWckRprM29KBUnUkGSQW9dHmxBAZSS9/aZ7jt/sQq8LQeUZisFxytxDyZWltlqSgdU5iU6Ii05sWmBWUyzAMzf1ivX1eYHB7q0gMWuFrqM5e8nrcKvJ71BCOqa45QpAIAAAAAMAOLq8gcfny5Zo7d64ikYimTZum8ePHd9S+kI/nLzBvV7xp3laOUs0qq5VZDSryu1VZt0iS5JKhCtWZFYnWvJWAIgopNSRqCHdFkGhNB/YFpVCyAlGBEm2qTz2n7ztDy3XCpCHW9Y4gsbBXy+9vB4nVqctWKGi3NkfDqa8bsLv++81GnfXQh8ktbW8ViYHMIFEyqz4bwjHVNjFgCQAAAACAHV3OQeK8efN0xBFHqKnJrBrzer3629/+ph//+McdtjlspV6jVBM3z/Xzu2IKxENm27Cl2NWUcnmRmjOCxA5pbd7wlRQolsoGZ38+au3LWyBFGuzlmCGtq0kNEscPLJXbbSWhztbm0gEtf749tTmttdmfGLZiVdvG0oaL+IL6eMWKlKXtriIx0c6dFiSWFni1rlaqbY5keREAAAAAANiR5FxW9Zvf/Ebf//73tXr1am3evFlnnnmmLr300o7cG3IRzTJRt3KkFldLUcP88f7+8KHSmo+TT6tWQSWr7gpdzRlv0djew1bqN0p37CXd3EoVq12RWJCy/OO/zs+oSKwsdASfzutLBrb8/i20NmdMbXZWJA7dV5JUGEjN3HekikRJqiNIBAAAAABgh5dzGrJw4UJdd911GjBggCoqKnTjjTdqw4YN2rx5c9svRsepX5/6OFiuUNlwra8PqcY6BfH7IwLSqg/sS54KXK0iVzKYK1JmkNjuFYlVS5P3//4j6eHjpFUfpl4TsYa9pAWJ7yzN/B2rcJ7X56xITEwfzqaVqc2So7U5ZgWJHr90zF2SpCJ/agXi9luRWJuyXGoNXKG1GQAAAAAA5NzaXFtbq969e9uPCwsLVVBQoJqaGvXq1cq5dOhYdWlB4qRTtbYuLsOQ6lSkXqqTvn1H2vR1i2+RLUhs92ErkeREaH31L/O2oFIafE9yPWrtwxts8+1SBn/4na3NrVQk+osz9yIpmF6RmGhtPudNqWKYJHMiudP2V5HoaG02DMn6fhMVibQ2AwAAAACAvIatzJkzR2VlZfbjeDyuV155RQsXLrTXZsyY0X67Q9vq1ibvTzhRmnapVq0wzxps8pRI8XXSO3e0+haFrpBkpK61+7CVxiyVq869S8mpzY6KxHjlaGmNef+47w7WPz5aJSktSExpbW6lIjERUEZTg9NEa3PGsBVP8jNC0dRp5dttRaIRM38OVjhbWmBVJDZTkQgAAAAAwI4uryBx1qxZGWtnn322fd/lcikWa+ez9dC6unXm7dgjpePM6r71tVskSRFfmRSSVLXEvMbtk+KZlWXZW5vb+efYWJW5lth7grMi8fQ50mt/UM20a6Q7lkuSehUng72KwpZam1sZtuINWJ+Tet6iXZEYTqtITFwvR7WipTiY159O9+cvkjnG2zCrEq0gkTMSAQAAAABAQs79mfF4vM0vQsQuUG+FcY4ALRH6hH2lqdcO3y/rW/R21WiIK7VFenN9SM9+vLr9AqSsFYnr9OLCdZr9j0/VHInJcFYkDt1b+snTqi8eIck8x7DInwzvUioSHYFf60GiVZEYSZ1abU9tjsaleFyKW9V3rVQkjupT3PLn9EQuV9aBK6WJ1mbOSAQAAAAAYIe3nR30tgNKVPUV90suWW2oEX+yDV0ev9R3XNa3+J3vb3ojcJHGuL611z5fU6sLH/9Ep973vmJxI+vr8tKUpSIxXKeLH35Lf39/pcb85kX98wOrctLRqpyoBEy0HyekViQWJe87/h0y+BKtzdkrEv/79Qat2+KY6OwMEtMqEkf33c6CRCnrwJVEazMViQAAAAAAgCCxp0u0DBcmB94kBmNsKdk5eV3lSKmgvNW3muF5O2PtwxVb9PyCNdu8zYyKRCv86+vaYi/5DTPgi3mcLcVmJWCBz6Owo+K1wDlFuaSfdMQt0nH3Sl5HwJgu2xmJCx7XgStulWTom/X1OvKWVxzXJ/eRXpG4owSJDFsBAAAAAAAJBIk9XaINNZhsY05UJFb1mpS8rnxosnW1BeMGlOgnew/TqD5FKetLNzVs+z4TQWL5UOnHT9tDUfqq2r4kKHPISW002cKcGIAS9HkUiqSGeSn2OE2acHzre8h2RuIzZ2n3VQ9rH/cXkiQjEk4+56hITD8jMaW1ensRzNbanKhIpLUZAAAAAIAdHUFiT5eoHgtkBomRyp2S14UbkxVnLfje6Apdc/SuOmR86uTj2qZ2qEZLVE4efpM0erodJPZzVCQGZX5OVShZbegMEnfqt41VgOkVic3Jyrtimecm+uQ4H9Hlsp9Pr0jcLtkVickgkYpEAAAAAACQsJ2Nnt0BJUIfR0iYCH1KC/zSgN2ktQukiSe2GSSqYZMk6YLpO6nA59G3VY168sNV7RMi2S3YleZtoiLRVW1fEnSZ1YCbQi6NstaarEnKBX6PjvvuYG1uCGufkck27rwkKhKNmBSLSjWrkk/J/By/y/peHe3VUmpF4n2nTd66z+/usgSJZQVUJAIAAAAAABMViT2dFfqsqHfrF08u0B9e/MoOfUqCXuknz0on/1367kwp4Kjo67WTtO/PUt+rbq0ks/rvZ9N30u5Dy83l9giREq3NibMcraEofVzJ4SalXvNzNjQlfy2dw1a8Hrf+53uj9Z2hFVu3h0RFoiQ9cpy0+GX7YbmrXpLktyoSw/IqFE2Gh4mKxD8cN1EH7NJ36z6/u2vtjMSmiAyjHYbuAAAAAACAHiunisSKigq5HG2eramqyjKdFx3HChIvfX6Z5m8xg0K/xwziSoI+swJwl8PMa51B0LlvmeHe239KrtWvT3lrZ4i0TWrXSNEmyeWWiqwQzgoUK1WroM+tG46dqIo5MalZWteY/F1ztjZvM2eV4dL/ml+WcpnnQPrt9mrpH28s03kHjJaUDDQDvu04e0+0xztavkut34G4ITWEYyoOUMQMAAAAAMCOKqdU4JZbbrHvb968Wddee60OOeQQ7bPPPpKkd955R3PmzNFvfvObDtkkWhANSzFzcMiXyaMGFY6Z1XMlwbQfb1Gf5H1vwK4KtFkViQntNmhj5Xzztt+ukr/Q2ktvSVKlq1Y/mDBAR39nkBrmmK3N6xqTL222g8R2CPDcbjNMjIUyniqzKhIDVpAYNrx68oOVmUGitx0Cze4qWG7eNlcnl3xued0uReOG6pojBIkAAAAAAOzAckoFZs2aZd8/7rjjdPXVV+v888+31y644ALdfvvtevnll3XRRRe1/y6RXbjevtuggoynE9VktgETpUOuMycnS5I7LRRrrpEiTZLPfK/SgnYatPGtFSQO2Su5VpgIEuvUp8SsFPTHzYBvVfLbsisSC9qjIlEy25uzBYmJikRXorXZp537Jc+UTLQ2t0ug2V0VlJu3TdX2ksvlUmmBT1UNYdU2RTWgrEt2BgAAAAAAuoG8U5E5c+bo0EMPzVg/9NBD9fLLL2d5BdqTYRh6cs5/FfrDLtJLZgVoxB1UTJlBW2lBlpx4n/OksUe2/AGOqsR2r0gcundyzW5trlOfYjNI9MTMacopFYmOYSvtwhvIupw8I9GqSJRPjeHkGYnN7dli3V0VWGdPNm1JWS6xfw+Y3AwAAAAAwI4s7yCxV69eeu655zLWn3vuOfXqtZXTdJGzfy5Yo7Fv/VyBxnXSJw9LkprcZrvwbkPKU67NqQ316Luk/hMln9VyvGW5/VSiorGueRsHbWxebN72n2Av1XnM0rZKV63G9C+VDENuK0hc2yDF4ubndUhFYhbJMxKTw1aqGsL284mKxIB3x6pIlJK/B+0yvRsAAAAAAPRYeR94dtVVV+mMM87Qf//7X+21l9mqOn/+fL344ou655572n2DSPXqF2t0lHt5ylpNzAzHjp80WAtWVtvrXk8OodfuJ5tfj54kffOCVLVUGnWgpOSwlW0atBFuTE4BLulvLz/7TUg/kVTqatKU4cVSNNlu3GT4taUxrN7FgfYdtiK1WJG4ex9DxZu98kXMIDEkX0qQ2BxJtDbvABWJjjMSpWRla7tM7wYAAAAAAD1W3uVVp556qt566y2Vlpbq6aef1tNPP63S0lK9+eabOvXUUztgi0gwDENFyzPbx6tiQXncLh21+0D1LvZv3ZtXjrTebJl521il4Ad3aICnRtI2TG5u2GDeeguSU4Elfbg+rqhh/vq5aldLf5pkP9ckvzbVm8FiU9gM8NqvtTl7RWJBtE7jBpQmW5sNr6oaw3YlZiiaGLayHVckJoatOFubl76m8TJ/J7Z5ejcAAAAAAOjRtmoE61577aVHHnmkvfeCNmysC+nwpueVfhxivVGg3QaXqTTo050/nqQT//KOvrdzn+xv0pLKEeZt1VLz9p8/k+urf+lO3y46OnaFapsjGmAE9adXF2vsgFJ9f1y/lt8rZXNWkFjcV3K57OU1tWFtUYn6qEaa+1updpX9XFRebaoLS/2lZivAC7ZXgNdCRaKatqig3GMPW4nIq3A0rsZwTEUBr0I7UkViuF6KRcxQ+cEZ+rWke/SwaqlIBAAAAABgh7ZVQeKSJUt03333aenSpbrlllvUt29fvfDCCxo6dKjGjx/f3nuEZcvapZri+Vwxw6WY3PK7zJCtXgXabyczOJw8vFJvzz5QZQW+1t4qU3pF4lf/kiTtrq8lmW2try/apJvmfiNJWn7D4bm9b90687Y4NXhcV9OszUap+rhq7M9ySlQktv+wlewViYo0qMwXU8AxbEWSqhrCKvB5FI7tAGckBh0jmZe/Ib11q/1woDZzRiIAAAAAADu4vFOR1157TRMmTND8+fP1j3/8Q/X15rTbBQsW6Iorrmj3De7QDENqrDK/JBlL5kmSPjZ20sfGTvZl9SrQuAEl9uMBZQUq9OeZESeCxC3LpHg84+napoi+rUqOU47EMq/Jqn69eVvc114yDEPrappVZZSkXttnjOZVHC9JemvxJl329Kd65SuzorHdKgEdVZHpKjyhlGErkhkkJgattOs+uiO3JxkmPnSMtPS/9lOj3GvsMxJD0Zi2OM6PBAAAAAAAO4a8g8TZs2fr2muv1dy5c+X3J8/jO/DAA/Xuu++26+Z2eC9cKv1hhDT/LklS4eo3JUlvxcdrnVFpX1ZnFGhwReG2fVbZYPM22iw1VWU8/W1Vo5rCydbWRMVgm+zW5mRFYlVDWOFYXFVKCxLPfl1vjLxEkvTkh6v02Hsr7afabWpzLEtVncdsdy51N9tnJLqsFuiqxrCarYEv0nZekSglz0lMM9K1Vo+/v1K7XjFHe1/3iva67hUt3VjfuXsDAAAAAABdKu9U5LPPPtMxxxyTsd63b19t2rSpXTYFS2LK8ZYVkqTeG8yg9uuC76rOKLAvW2n00eCKgoyX58XjkwqscDIR/jnM+3qj1tY024/XOe63yq5ITAaJifdp9FYkr/MVSd6AepdkHxYTaK8gMZ4WJHr8UkG5uYVovV2RGCww/z2r6pMViV63K7dJ2D1ZQUXW5VGuNYrFDdWHotrSGFE4FteTH67Kei0AAAAAANg+5Z2KlJeXa+3atRnrH3/8sQYNGtQum4KlfJh5W/2t1FyrwohZKTh8wr4aMGZvSVLUcOs576H5n4mYTaL9OBH+2Qy9u2SzFm9IVqCtr82zIrEkGSQmQshoMFlVqULzfp/i1GEoPo9L5YU+jR9YqnaRXpHoK5D8xZIkV6RBPmvYis9nnqVY1xyxKxK367bmBCtUlWS2ux99pySzIjGds1ITAAAAAABs//IOEk866ST96le/0rp16+RyuRSPx/XWW2/pF7/4hWbOnNkRe9xxVQw3b6tXSHVmkFNrFKisrEJTjjtPv4qcqX1CtyvsCsjVytl/OUsEiYnJzZYxZXGFY3G9sShZcbqhbhsqEmvN1xqFvZLXWQFW/7LUYShPnL2PPrj8IPUubmHacr7iaZOHfUVSwGyx9kTqk63NPvPz6kNRuyLRv723NUtSkWPad9lgqZd5FudId2aQ6AyWAQAAAADA9i/vZOS6667TmDFjNGTIENXX12vcuHGaOnWq9t13X/3v//5vR+xxx1U+1LytXWNWJUpab1Sqd3FAwYIiPR47QBtVrtrmaCtvkociK0hc/3nK8m69Mt9/fW2+QWJy2Mq6miZJkrfYEVpZLbUD0oLE3sWB9m0nTq9IdHuTQWK4wW5t9lhnJNY1RxWO7gATmxMGTUreLxsiVY6QJPXTFgWUOmBlCUEiAAAAAAA7lLyTEb/fr3vuuUdLlizRv/71Lz388MP66quv9NBDD8nj2QFaPztTUR/JVyjJkFa9L0laZ1Sod4kZciVCt4mDy9rn8xJh3/qFKcs7F2e2MefU2hyPZx22kjgjMVCWDBcT5zP2K00NEnsVZz8zcauln5Hokt3aPGmAVwGrItHjt4LEUFThmNnCu0NUJA7ZK3m/dKBU2Evyl8jtMjTYtVGS9L+Hj5UkralpVkOonUJsAAAAAADQ7Xm39oVDhw7V0KFD23MvSOdymVWJG7+Svn1HkrRelRprhWsPnr6n/jxvsc4/cKf2+bzi7BWJw4KNklLPKMxp2EpzdTK4c7TMJl5bXNk/ea1VkVgSTD3rsdC/1b+i2cXTzvVzuaWAGSR+t79Xg3cql5ZJHuuMxPrmqEIRq7V5ex+0Ikn9JybvR5rM38HK4dK6zzTMtV5jdt1DZ+w/Une9tkSb6sNaurFBE9oryAYAAAAAAN1aTinNxRdfnPMb3nTTTVu9GWSRCBKXvS5JWm+Ua78is1pup34luuWk77TfZyVam8OpLauDAo32/YFlQa2padYnK6vVHIm1PIDEMKTlb5j3Cyokb0CGYeifC9bo7SWbJUllvR1BYrCTwqjivlLNSseCy25tdocb1L/IPGvSFzCnNtc1RxSKWa3Nvh0gSPR4pTFHSF/9W/rOj821ihHSus90zS7L1dd/h1T1aw3vVaRN9WGtqCJIBAAAAABgR5FTkPjxxx/n9GbtMvADqYZNkRa9ZD9cZ1SqoqgdJjRn42g/duofWSVppCTptCkjdO+by7SutlljfvOinjtvinYbUp75onfvlOZcZr2vGRh+uGKLfv73T+xLevcZ4HiBse37z8Uxd0vPXyCteMt87HLbrc0K10tRs2Xb57cqEkPJMxJ3iIpESTrur1JTtVRq/XyscxIHLXvKfByu0bBe/6sPVmzR8k0NXbNHAAAAAADQ6XIKEufNm9fR+0BL9jxTeufPUoN51mC1p7cC3g46i9IxEEWSNPr70uK5Klv5iqSpkqTxA0t16K79df/byyVJz32yJnuQmAgRHe+7Nq0dun9FSfKBEd/Gzeeo92jptP9IV1pVdC63XZGoUJ0UMweK+AJmkOgctrJDnJEoSb4C8yuhYkTq89XfaviYQknS8s2NAgAAAAAAO4YdJBnpwfxF0jF32Q83BYd13Gf13knyBJKP9zpHcnvl3rxI83tfqx/v0V97jeyls6eNtC9pirQwbKP3Lsn7VpDodadWrBb4HYGor9C+O3m4eV5i35KAOpzLlaxIdASJgWCitTmqkD21eQcdJjRiaurjylEa1rtIkvTpqmqdfPe7+usbS7tgYwAAAAAAoDNt1SSLDz74QE888YS+/fZbhcPhlOeefvrpdtkYHEZP1ztHvKLbnn5VtZUj2r5+a/kKpH7jpTUfmY8HfVcadaC06CX1q/9C104OSW6XBpQV6PIfjNXv/vOlmiMtVBL23kna9LV5P2xWrTWGY5nXHXSltPAfZmhpufWk7+j2eYt12r7D2+97a1HyjESztdkKEgNZWpt3lIrEdL1GmWdYNteYj6NNGt7LDH6/WV8vqV7vLN2sM/Yf2fJ7AAAAAACAHi/vZOTvf/+79t13X3355Zd65plnFIlE9Pnnn+vVV19VWRlDFzrKWnd/vRMfr8oif8d+UOnA5P3CSumoO5KPw8k21qA1eKQ5kiUclKS4o1LRY+bVTY5rT97Tmvi930XSOW+an2UZWF6g646ZoJ36OVqfO4pjarNC9VLMPCMxaFUk1oeiCkXNfe+wQaIkzXwueb+pWsN6FXXdXgAAAAAAQJfIOxm57rrrdPPNN+v555+X3+/Xrbfeqq+++konnniihg4d2hF7hKQtjRFJUnlhBweJB/6v2d484UTzcXEfache5v1ok31ZwJrW3NRSkBhxnJ13wP+a11oViZOGVeiKI8e17763lssl+RMViXV2RWJBgVlxF4sb+rbK/F4CO8qwlWwGfkc67QXzfnONygp8+t4ufVIuMYxOGpgDAAAAAAC6RN7JyJIlS3T44YdLkvx+vxoaGuRyuXTRRRfp7rvvbvcNwlTdaAZcFYUdNLE5oe9Y6eIvpaNuT655zTZfRZLDUgqsILHFisSIFTqe9KjUZ2dJydbmnfuVKOjrJucNOisS130mrf9MkhQIBpUYQn7fW8vNNd8OHCRKUrDcvG2uliRdceT4lHMvG7K1rgMAAAAAgO1G3slIRUWF6urqJEmDBg3SwoULJUnV1dVqbGSCa0fZYgWJHV6RKElFvSSvY9BJYoJvxNnanKhIbOGMxESQ6Jj+m6heLPR3gxBx2q/M28N+nzwj0cHlDSq9wM6/I1ckSlJBuXnbVC0Zhkb0LtJ7lx9kP13TFOmSbQEAAAAAgM6RdzIydepUzZ07V5J0wgkn6Oc//7nOPPNMnXzyyZo+fXq7bxDShyuq9PC730rqhIrEbBIVidHMisRQWxWJjmnMTWHz3MRuESQe8Gvp12ul4ftJJQMyn/dkBrY79BmJkjlwRZKMmDmYRlJlkV+9i83QuaaRIBEAAAAAgO1Z3snI7bffrpNOOkmSdPnll+viiy/W+vXrddxxx+nee+9t9w3u6D5csUUn3f2u/biiMyoS09kVickzEhPDVlo+IzGzIjHR2txt2pr9VshZWCkd+9fU55wVmZaAt5vsu6v4CiW3FWQ3VdvLZQVejXSt0YB//0Ra+Z65GItIcVqdAQAAAADYnnjzfUFlZXK6rtvt1uzZs9t1Q0i68p+f6/63l6esFQfy/pFtu0QY6KhIDLZ5RqLVBu3tpq3N6YZPSX3s8evJc/bRCXe9Yy/t8BWJLpfZ3tyw0ToncYgkqazAp9/5blPF6m+lv70h/Xaz9OBRUtVS6fz3s7aOAwAAAACAnifvZOQ///mP5syZk7H+0ksv6YUXXmiXTcE0bkBpxtpO/Yo7fyPebBWJ1hmJLQ3YyHZGYrgbB4n+otTHHr8mD6/UtJ2Tk4l3+CBRcgxcqbGXygp8Gus2W+9lxKQ1H0sr3pLq1urPjz2jv725rPP3CQAAAAAA2l3eycjs2bMVi2WGR/F4nOrEdnb8pMEaWmm23542ZbiePW+KhvUqauNVHcCX5YxEKwxsjmYZthKPSbGQJGl5bXJiSbdrbXbypf27Wq3NRYHkXgMEiakDVyxlBWnndn7+tH33m2++1NX/+kKStK6mWf9csKblKlYAAAAAANCt5d0nu2jRIo0bNy5jfcyYMVq8eHG7bAomt9ulp87dR3MWrtOJk4d03Rl93ixTm61QLRyNKxaLy2NEkucKOgLHMx/7QnN/NVSSs7W5C9qz2+LxSi63ZFjBqDVspcCX3CsViUoOXGmutpcygsTFr9p3h7g2SpJe+XK9fvrAB5Kkq48ar5n7DO/IXQIAAAAAgA6QdzJSVlampUuXZqwvXrxYRUVdUC23netbEtRP9hnetYM+EhWJkcyKREkynjpN+r9dpIbN1nXJFujFW5KTfLt1a7OUHCQiZa1I9HsIEu3zDkP19lJZMO3nWbPKvjvYChIffneFvfbl2tqO2x8AAAAAAOgweScjRx11lC688EItWbLEXlu8eLEuueQSzZgxo103h27CHrbiOCPREWx6v3xWatoiffp3c8GqXGw2fDIcv2KNkaj52u7Y2izZVYjmfTNIdFZPUpGo5FmSkQZ7qZ+nPvWaUPL8xERF4heO8HDpxgYBAAAAAICeJ+9k5A9/+IOKioo0ZswYjRgxQiNGjNDYsWPVq1cv/fGPf+yIPaKr2a3NyYpEt9uVGawlWpqtisQmBVKebgqbbcPdtiLR42i5dpvfW5HfeUZiN913Z/Jbw37CyTCwrza2ePkQ1wZJ0vrakL22bBNBIgAAAAAAPVHeh9WVlZXp7bff1ty5c7VgwQIVFBRo4sSJmjp1akfsD91BlmErknlOYjQaTS5ErbDIqkhskj/l+qaweW33DRL9GUuFgeSfCMNWJPnM4T/OILFXtOUgcaBrszyKKabkz3xDXUj1oaiKA93wrEwAAAAAANCirfr/5F0ulw4++GAdfPDB7b0fdEd2RWJTynKB3yOj2REu2hWJ5m2TYVYkhqIx+T1uNVrDVgq6a2uz25ex5Aw9aW1WsrU5nGxnLolnOfOwcqQaq9ao0NWsEa61WmwMTnl6+aYG7TqorCN3CgAAAAAA2lnOycg777yjf/3rXylrDz74oEaMGKG+ffvqrLPOUigUauHV6NHsYSupQWLQ51GRHGuhOus664xEqyJxU31YoWhchmE+XdBtKxJbDxKpSJSjtTk5wbvAaMy4LF7YR1/Gh0iSxrmSg1YGlZuhNANXAAAAAADoeXJORq6++mp9/vnn9uPPPvtMP/3pT3XQQQdp9uzZev7553X99dd3yCbRxRLtrNG0ikSfR0UuR0ViwybzNu2MxI11IXtic+J13VKWILGIYSup/JmtzQXxzDMPI8FKfRkfKkka5/7WXj9kfH9J0luLN3XgJgEAAAAAQEfIORn55JNPNH36dPvx3//+d+2111665557dPHFF+u2227TE0880SGbRBfzJioSU89IDPg8KnZWJDZuNi8LmcFSs2EGcxtqm9VgnY/o97jl9XTTQC5ba3OA1uYUdmtzMjwMxM3fgY/iO9lrzf5KfWEMlySNtSoS3S7p++P6SZLeXLxJ8bjRCRsGAAAAAADtJedkZMuWLerXr5/9+LXXXtNhhx1mP548ebJWrlzZvrtD9+CzzkjMqEh0p1Qkbt6wRoZhKNRonp+XqEhcXxfSqi3maweUBzthw1spa2uzc9hKN62k7EyJ1uZIMkj0R83778XH2GvhuMuuSBxjVSTGDWnSsAoV+T3aVB/W1+vrOmnTAAAAAACgPeQcJPbr10/Lli2TJIXDYX300Ufae++97efr6urk82UGMdgOtFCRGMyoSNykj76tVqjJDBJD1hmJyzY2aMlGc21k76KO3+/WytraTEViiiwVid6o+bNdY1Qmr6tfryXGQElSP1e1CmX+7vi9bo0dUCpJWrwhObAFAAAAAAB0fzknIz/4wQ80e/ZsvfHGG7rssstUWFio/fff337+008/1ahRozpkk+hizorEeFx67x5p/ecKej0qUjJcrFC93lm0XvHq1ZKkjYY5lfe5T1brz68uliSN6lPcuXvPR5bWZudgGH93bcnuTL7MMxLdYbOysN4oUPMQ878JSwcfo1oVqdZt/g4Md63TsF7ma4f1MsPIFZszz1YEAAAAAADdl7ftS0zXXHONjj32WE2bNk3FxcV64IEH5Pf77ef/9re/6eCDD+6QTaKLeR3tyJ88Iv3nF5Kkvt95S3FHa7PbZejDr5fq5OBSSdJywxyssbkhbF8zqm83DhKzVCQ6w0OP29WZu+me7KnNjmpCa1p3vQq07KC/aqxvnRZ/Wy7pc230DVRpqEY//45XOx0wWZI03AoUl2/OnPYMAAAAAAC6r5yDxN69e+v1119XTU2NiouL5fGknhf35JNPqri4G4dE2HqJikRJWvepffeg4T69/V7quYlb1iyRr9dySVJj8TCpJvWtunVF4qE3SH89SJryc3upV3FAFYU+uVwulRXQup9sbXaEgCEzVKxToeoNvzRwd9V+s0SSVB0cIoW+1CED6iXrZz+sNxWJAAAAAAD0RDkHiQllZWVZ1ysrK7OuYzvg8UlurxSP2tVnkrS3d7G+8IRSLh1kbFBBvTVco2JERpA4ujtXJPYbJ83+VvIk/yw8bpfe/fV0GQYViZIkv9XaHI9I0bDk9du/Ew1GUPUhczp3bXNEklRXONT8Hahaar8FFYkAAAAAAPRMHPqG3BRbE7tXvmcv+Ve9rbG9Un+F/uy/Tb54SBHDo1DxYB04pq8kadY+w3T3Tyapssivbs2Tma0HvB4FfUxsliT5HMNyEu3Njtbm+mYrSGwyg8SmkmHmNZuTQeKwSvM9NtaF7OARAAAAAAB0f3lXJGIH1WeMVLtaqlqSXNv0jfYcWCltyby8QUEdMmGw9hvdW6urm7TroOyVrOhhvH7J45diYSnSKBkVUqhWklRnFKjBrkg0b2Olg83X1a6236Ks0KeyAp9qmiJaU92knfuVdO73AAAAAAAAtgoVichN37GZa/UbVGCYZyTWl+2S8tSqgYfqyN0GqqLIT4i4vbHPSWywpjcbkqyKxFBqRaKndIB5bf16yTDstxhQZg7wWVuTHNYDAAAAAAC6N4JE5KbPmMy1+vX2oI3ioRPt5f+NnKa66X/orJ2hsyXam8P1dntzXG41KZBxRqKv3AoSo81Sc7X9Fv2tIHFdTeqwHgAAAAAA0H0RJCI32YLEurXSyvnm/UGT7OU5scmaOKS8c/aFzuesSLTORwx7CiW5kq3NVkVicXGJFLQqUuvW229BRSIAAAAAAD0PQSJyk621WTIr0obsJU0+Q42TztWtxkkav8tOKgpw/OZ2q9gcoKOqZfb5iBGvGS4uXG0+TpyRWBr0ScX9zevr19lv0b+0QJK0jiARAAAAAIAegyARuQkUS7P+JRX2lsYdbd4m7HeR5PGp8MgbdNplt+uuH09q8W2wHRiyl3n77TtSU7UkKVBcIZ/HpXeWbtabizapqiEsSepV7JdKrInfVCQCAAAAANCjESQidyP2ly75WjrhfqmgPLnef4J9tzToU9Dn6fStoRMN28e8XfGWVLNKkuSvGKwfTDDPQ3zsvW8Vixsq8nvUtyQglVjnJNattd8ieUYiQSIAAAAAAD0F/afIj8f6lWnaklwrHdQ1e0HXGLyn5HJL1d9Kq94z18qHaoDHbFf+ZGW1JGlU32K5XC6p2KpIrM9WkciwFQAAAAAAeoourUh8/fXXdeSRR2rgwIFyuVx69tlnu3I7yEfj5uR9l6vr9oHOFyxNVhmufN+8LRuikqAZMq+uNsPBUX2KzedKrDMS6xxnJFpBYm1z1B7QAgAAAAAAurcuDRIbGhq022676c9//nNXbgNbY8IJ5u3I73XpNtBFAqXm7aavzdvyoSpOG7Azqo813TlLRWJJ0Gdfv66W9mYAAAAAAHqCLm1tPuyww3TYYYd15RawtQ77g9niOuH4rt4JukKwNPVx+VAVh1P/czLSrkjMPCNRMqsSF2+o17qa5mT1IgAAAAAA6LZ61BmJoVBIoVDIflxbW9uFu9nBFVZKe53V1btAVwmUpD4uH6qS/2/vvuPsqAr+j39mbt12t7eUTe+NFBICoUgLCCgKiAiIAooICoKCPs8D2IOo/BREEJSioBTpSDEQBIEEQnovJJuym91Ntt1tt875/TGbu1kSWEqyJfm+X699zdwzZ2bOXIaUb0553/+O/XPcORM7hjZXdzpeukeQKCIiIiIiIiK9X59atXnOnDlkZ2enfgYOHNjTTRI5NAX26JHo8UNGEZnBzv8ukZfhd3d2D22Ot0C0KXW8JNS+crOGNouIiIiIiIj0CX0qSPzRj35EY2Nj6mfbtm093SSRQ9OeQ5szi8G2yQr4OlXJ3R0kBjLB3z50uUkrN4uIiIiIiIj0VX1qaHMgECAQCPR0M0Rkz6HNGQUAnXok+j02GX5PR52sEqjd6M6TWDAcgJJsd+jz1ro2jDFYWv1bREREREREpFfrUz0SRaSXCGR37Ke3B4l7rNqcne7rHAxmts+T2Lx3j8TX1+/kJ8+uPnBtFREREREREZH9okd7JDY3N7Nx48bU582bN7N06VLy8vIoKyvrwZaJyIfac2hze4/ErD16JAa87/s3iqz2eRLDFamioYUZqf3X1+/c/20UERERERERkf2qR3skvvvuu0yePJnJkycDcM011zB58mRuvPHGnmyWiHQlsHeQuGd46PO8P0gsdbdzb4TKJQAMys/gZ2eOB6CuNbbP25TvaqEpEt9PjRYRERERERGRT6NHg8TjjjsOY8xeP/fff39PNktEurLnHIntQ5v3HMrs87xvvsOxn+/YX/dCavf0CW7AODayhOSTV8CuDQA4juG6fy7juN/8h9n/73W21rbu5wcQERERERERkY9LcySKyMfXaWhz4V6H9+qROHA6HHOdu99UlSrOTvMxy7OKv/t/iWfZg/D4JeA4LNhcy6PvbgegsjHCz/6lORRFREREREREepqCRBH5+PYxtHlPewWJANn93e0eQaJtW5wVeKejzo5lsOYZnlzszqU4MM9d2XltVfjTt1lEREREREREPhUFiSLy8e3ZIzF97yDRv68gcfc8ic1VnYoPZw0A9V63Z+OuDe/w4iq3zvdPHgXAjoYIiaTzaVstIiIiIiIiIp+CgkQR+fj27JGYnpvaPWVcCQCXHTt073My21dubqqCSBhaaqG5hgHOdhxj8dfILABWrVpGUyQBwOxxJfg8FgnHUN0UTV2qNZagNZbYzw8lIiIiIiIiIh/G29MNEJE+aM8gcXdACPzhK5OpbIhQlp++9zmpHonVcM9noLUOTv4ZAOvMAFY6QwDIiVYC7vyJQZ+H/jlplNe2sr2ulf45acSTDmfc/gaRuMMr1x5L0Oc5MM8oIiIiIiIiIp0oSBSRj8/rhyvfBeOAP6Oj2GPvO0QEdy5Fy3bPqd3ols3/IwBbTTHbTBEAA60aAAqzAtC8k98nfs5f7Blsq59EcFsDv3t5Pe/tbAFgzY4wk8ty976XiIiIiIiIiOx3GtosIp9MwQgoHPXR69ueTr0XAahZ5W5MDtuMO0dintVMFq0UZfjgxeuZFH2X2/x3sL2+lSv/sZhX1+1Mnb56hxZhEREREREREekuChJFpPu8P0hsN3rESJ64ejZNnhwAhlsV/G7XN2Dl46k6a7bWsK2urdN5qysVJIqIiIiIiIh0FwWJItJ9Rp8GlgdKJnQqPnzCGEaVZNGcPgCA0zwLKIpv71SncsOSvS63SkGiiIiIiIiISLdRkCgi3efY6+CGnfCtN6Df5I7y9oVYEvljAPiS57W9Th1jbwHgzMP68cq1xwKwtipM0jEHuNEiIiIiIiIiAgoSRaS72e2rLOcP7yjLKgEgUDYFgJDV6pYf/X2YeSUAYy03SDxyeAGD8zNI93uIxB0272runnaLiIiIiIiIHOIUJIpIz8gd3LGf6QaJeSOmd65TMiE1DHpqoILvHD+cs6cMwGNbjC7JAjS8WURERERERKS7KEgUkZ4RCHXsp+cD4C0Z37lOv8NSQeIE7zauPWkktm0BMK5fNqAFV0RERERERES6i4JEEekZg4/q2LfbfynyBTETvoTxZ8BJP3V7LRaMBI8fomFo2JI6ZWw/N4hUj0QRERERERGR7uHt6QaIyCGq/1T4ymOQU9ap2Drrns71PD4oHA1Vy6FqRWpI9PCiTAC21rV2R2tFREREREREDnnqkSgiPWfkyVA0uut67cObqV6dKgoFfQA0ReIHomUiIiIiIiIi8j4KEkWk98sqdbettR1FQbdDdVMkgTGmJ1olIiIiIiIickhRkCgivV+wfWGWSGOqaHeQmHAM0YTTE60SEREREREROaQoSBSR3m/3Cs/RjoVVMvxeLHcBZ8Ia3iwiIiIiIiJywClIFJHeL9UjsSNItG2LTH/H8GYRERERERERObAUJIpI7xfIdrfRxk7Fu4c3NytIFBERERERETngFCSKSO+3jx6JAFmplZsVJIqIiIiIiIgcaAoSRaT328ccibDnys2aI1FERERERETkQFOQKCK93549Eo1JFWcGNUeiiIiIiIiISHdRkCgivd/uHokmCfHWVHFqaHNUQaKIiIiIiIjIgaYgUUR6P38GWB53f495Envb0OZH393Gj59ZheOYriuLiIiIiIiI9DHenm6AiEiXLAsCWRBpaJ8nsRTYM0jsgR6JsRawfeD1p4qu++dyAI4aXsBJY4u7v00iIiIiIiIiB5B6JIpI37CPlZuzAm6Q2NzdQWJTFfx2NDz2tVRReI9ekeW7Wrq3PSIiIiIiIiLdQEGiiPQNgWx3G21MFXXMkdjNQ5vXPe/2jFz3L4g2A1BR35Y6vLWu9YPOFBEREREREemzFCSKSN+wjx6JOelukLh4SwPvltd139yE8Y7QkIp33c0eQeK6qqbuaYeIiIiIiIhIN1KQKCJ9Q7C9R2JbXaro2JGFhIJeqsIRzr5rPg+9s7V72lK/pWN/2zsAVDR0BIlrq8IYowVXRERERERE5OCiIFFE+oaise52+aNQuQSAnHQ/P5g9KlXl9fU7u6ctDXsEltveBqByjyAxHEmwfY8eiiIiIiIiIiIHAwWJItI3jJztbre9DXcfB1UrALhw5mBu/dIkAJZta+ietjTs0SOxaiUA5bWdF1hZvLW+e9oiIiIiIiIi0k0UJIpI39B/aufPC/+S2j11fCke26KmKUpVY+TA3D/efl1jMHsObW6u4o2la3hpVTUAA3LTAHhnczfO2SgiIiIiIiLSDRQkikjfYHvg9P8HtrvACssfhZi7OnKa38PI4iwAlu7vXomOA89eBb/sB5tfh7pNWHG392GVyQXgxXnzAJhSlsO1J48E4KG3t/L9x5bt37aIiIiIiIiI9CAFiSLSd0y7GG7YCaH+EG9JzU8IMGmAuxjL8u0N+/eeix+ARfeDScLqp+HlHwPwRnIcS53hAPhr1wBw1wVTOXJYQerUZ5ZVatEVEREREREROWgoSBSRvsWyYMgx7v7m11PFkwbmALBsfweJ5W907G+YC2uewWDxs8SFrHHKADjH8xpTS7wUhYIUh4I8951ZACQc02k1ZxEREREREZG+TEGiiPQ9g492t3sEiRNTPRIb9+/chLUbO/bbF1kpD45mnSnjseSx7DIhxthb+V7m3FS18f2zGVmcCcCG6ub91xYRERERERGRHqQgUUT6nqHHutuKRdCwDYCRdgW3+v/Ez5K/o7yiIlU1Ek/S0Br7ZPcxpnOQ2O5NexoAVVYBv0ucBcDh9rpOdUa0z9m4vrrpk91bREREREREpJdRkCgifU/2gPZeiQaWPAjG4Hvm23zRfo0zPW9R88SPAFiytZ5JP/k3h/10Lne8uncg2KWmKog1g+WB4Se1F1o8HZkCwE8+N441nlEABKqXuQuztBtZ5AaJqyrDtMYSbNr5wT0TdzS28c9F27XKs4iIiIiIiPRq3p5ugIjIJzLlIij/Lyy8B/pNhsolqUNH1D/Dfxcu4R/rHaIJN9z7f3PXc9LY4tTqzh8q2gzxNnjtV+7n3EFw9r1Q/gYvbTUsdBdp5szJ/blg+qUw5ycQbXR7L/rTwUly+GB3RednllXyzLJKAH72ubFcmHjcXYF61vdStzv51tdpiiZojsQ5ZXwpJdnB/fAFiYiIiIiIiOxf6pEoIn3TuDOhaCy01sI/znXLDruAijS3h+Dfn3yS51dUAdA/J42EY3h88faurxttgj9Mg98Mh0X3uWX5wyEYYmvhcXzr1fZbDcwhK+jD8vig32Fu4f2nwW2T4fYpHBl+nvOml3W69JPP/wvm/cxd+TnshourKhtpiiYA+PGzqznm169+8qHYIiIiIiIiIgeQgkQR6Zs8Pjj9d53LZnyT0tFHADDOLgdgSlkOVx4/HIBVFeGur7vpP9C0w933Z7lDqI/8LgAPzC/HGJg0IJtHLjtij/t+C7CgpQaSMXAS8PwP+Pnpw/nrxdN56oqjOGxgDmfzSsc5T18BlUt4fFHHfI4AsYTDyo/SThEREREREZFupqHNItJ3lc2AQUfBljehcDSUTsLuNwmWwHirnAAxzp9exqjSEAArKhpZV9VEms9DWX76vq+5/iV3O/4sOPNO8AYAWLCplgfeKgfg6pNGEvB6Os4ZdyZ4HoKNL8Ow492QMNKIp2oZx4x0A8ejh+Vwes2CjnPemwfbF7E49I+9mlDZ2PapvhYRERERERGRA0E9EkWkbzv7Xjj8Ujjnfvdz6SQAjvMsY3Xw65y55eepeREb2+LM/t3rnPr716lv+YDhwxvbew0edn4qRNxW18rlDy4i4RhOm1jKcSML9z5v9Glw+v+DMWe0LwQDbO0IDo9J30bIau18TrSRNdt37XWpLbUtH+3ZRURERERERLqRgkQR6duySuC030LRGPdz8Tjwub0NPRg8Kx7G77UZUZSZOqUllqS8ohIeOgeWPNRxrXgbNLlzF9J/aqr49nkbqG+NM3FANr85exKWZX14m8rahz3vDhLXv8Th89x5HLeYos5VqSIr2Llz+Jba9wWOIiIiIiIiIr2AgkQRObj40uBr/4JRp3WUtdZx9YkjmTW8gKyAG9plLrwNNvwbnv52R70md3GWmBXABEKp4k073R6C3zxmKGn+PYY0f5DBs9pP/A+01cPLP0kd+lPiDJ4o+k7q80hrOxl+L3/4ymRKQu5qzQoSRUREREREpDdSkCgiB5/+U+C8v0Oov/u5diOnTSzlwUtncMIYt0dg2q4Ve53WWucufLIjmc2GnR3Diysb3DkL++ekfbT7lx4GReMg0Qav/RpqVgEQzSrjJedwrtk6k0cSxwEwwt7OpUcP4fSJ/Xjg4ukAlNe2YIz5uE8tIiIiIiIickApSBSRg1f+MHe7a0OqqLQ9DPS31XTUi7mhYcW2cgBqyEnNoZhIOlQ3RYGPESRaFhx+sbu/4A53O/AIAteuYOqYEQCsN27I+a0xMS4+aggAg/LTsS1oiiSoab+niIiIiIiISG+hIFFEDl75bmjHlrdSRf2yg3hJkBut6KgX3gFAbdVWAGpMDjub3SCvpilK0jH4PBYFmYGPfu+J53b+PNodan3ejDIA1hp3G6xdg227cy4GfR6GFbpzOa6qbPzo9xIRERERERHpBgoSReTgVdAeJC59EJY8CEC/nDSmWBvwmXhHvbAbKrbUutsak8vO9h6Bu4c1l2QHU4HfRxLIgmmXuPsZhTD9GwAcN7KQ604ZxQWfb5/DsW4TRJtSp43r587NuKoi/NHvJSIiIiIiItINFCSKyMFrzOc69te9AEBpdhrnel/tXK9pB83RBJF6d8XmnSYnFSRWtAeJ/bI/4rDmPR3/fzDrGrj4JXcRGMCyLL593HBOnTEBsvoBBqpXp04Z3z8bgJXqkSgiIiIiIiK9jIJEETl4ZfeH8//p7tdtAmBAFpxmvw3ARqefeyxcyc0vrCEztgtw50isSfVIjAAfY37EPaXnwYk3dczV+H4lE9xt1fJU0djdPRIr1SNRREREREREehcFiSJycMsb6m7rNoHjEGp6j6AVZ5cJ8ZIzDQATrmTBpjqKrAagfY7E9iBx97YoFNz/bdtHkDimxA0St9e30RJN7P97ioiIiIiIiHxCChJF5OCWMwhsLyQi8NM8WOH2UKz0D6HSFACwdf0ytta2kme5vQBrTSgVIIYj7lyKoTTv/m9bKkhckSrKzfCnFnXZUNO8/+8pIiIiIiIi8gkpSBSRg5vHC2m57R8MzP8DAA2Zw1ngjAGgtGER/mQzObS4x0wmq3eEOfqWefxz0XYAsoK+/d+23UFi9WpIdvQ+HFnsrty8vrppX2eJiIiIiIiI9AgFiSJy8IvsvXBJJG8075n+vOeU4reSnOl5k4Dl9j5ssLIA2FbXlqofCh6AHom5Q8CfBcko1G5IFY8ocoPEDQoSRUREREREpBdRkCgiB79Tbgar8y930bzRADzvzADg57773AO2j5+fM52jRxR0qh86ED0SbRtKxrv7ewxvHlHsBpnrqzW0WURERERERHoPBYkicvA7/BL43yr4n0qY8CUYdgKf+cxJnDC6iDsTn2OD07+jbnoeX5gykJ+fOb7TJbIORI9EgOJx7rZ6ZapoZHuQqB6JIiIiIiIi0pscoL8Zi4j0Mt4AEICz7gEgE/jL1w7n+RUDePqRo/i+/ahbr30+xZw0f6fTD8gciQCFbs9Idq5PFe2eI7GyMUJTJH7g7i0iIiIiIiLyMahHoogc0j47oZRvf+7ojoK0PMDtgWhbHcUHrEdiKkhcmyrKSfdTmKWVm0VERERERKR3UZAoIoe89PyBHR/aeyTatkWaz5MqDqUd4B6J9eUQ71jcZXevxI2aJ1FERERERER6CQWJIiKhfh377UEiuGHibhl+DwdERkH7PQ3MvQl+MxLuPYWRhRkArK9uojmaODD3FhEREREREfkYFCSKiOwZJHo6eh569ggSLcvigLAsKBzj7r/zJ2iuhq3zOSKrBoA/v7GZ8Te9xDWPLiWRdA5MG0REREREREQ+AgWJIiKBrI79RDS167UPUHj4ftO+vlfRLN/6Tp+fWFzB8yuruqc9IiIiIiIiIvugIFFEZE+JjnkKPd0VJE44B8afDZklMPkCADJ2LGBIQUanaku21ndPe0RERERERET2QUGiiAhA/6nudtJ5qSKv3U2/RFoWnP0X+P46OMwNEnnvVX7/+cGM7x/i3GnuYjArtjd2T3tERERERERE9kFBoogIwFefhm/+B0acnCrqrhyxk4HToWgsRBuZWH4fz33naL5xzFAA3t1Sz0+fXY0xpgcaJiIiIiIiIoc6BYkiIuDOk9hvsts7sN1PPzcegCs+M6z72mF74Jjvu/sb5gIwtCCD9PZVo+99czPb69s+6GwRERERERGRA0ZBoojIB/jM6CKW3ngS3z95VPfeePcqzk07ALBtiyuPH546XNMU3ddZIiIiIiIiIgeUgkQRkQ+Rk+7Hsrpp0ZXdskrcbVtdahXpbx83nMllOQDsVJAoIiIiIiIiPUBBoohIb5OWC56Au99UlSouzHTLdjUrSBQREREREZHupyBRRKS3sayOXol7BolZbpCoHokiIiIiIiLSExQkioj0Rlml7rZ9nkSAgvYeiTv7Qo/Ebe/An0+Ct24HxwEg6Rh+8uwqnl1W2cONExERERERkU/C29MNEBGRfejrPRKX/h22v+P+BEIw9SLmv1fLfW+Wc9+b5Uwuy2FAbnpPt1JEREREREQ+BvVIFBHpjfbRI7FPBYmN2zv2VzwGQFU4kiq6/ZWN3d0iERERERER+ZQUJIqI9Ea7eySG24cB/+tajn3pVApoTAWJxhi21bVijIF4BCLhfV7q7U21/Pbf64gnne5ouWvPIHHLm9Cyi+o9gsQXV1WRSDqsrGjkr/PL3WcQERERERGRXk1Dm0VEeqOiMe522wJIxmHhnwkCl3uf4VdNF9EcTfDE4u3c+PQqfv75cVyw5nKoXglXLkyFkK2xBHNXV3PVw0sBKMtL55xpAw98242Bxm3uvj8TYs2w9jl2NUzET5wYPhrb4izaUs+5dy8AIN3v5eypAw5820REREREROQTU49EEZHeaNBRYPugYSuseTZVfJJvObFkkgfeKufGp1cB8OKzD8PWtyAahheuh61uOHfZ3xalQkToxkVaIg1ueAhwxOXuduk/uGrl2TzhvwkvCYBUiAjwzuba7mmbiIiIiIiIfGIKEkVEeqNAJgya6e6//ptUcZmp4Ch7Jb9+aV2q7GueFzvOW/0U3DubWTe/wn837Op0yaxAN3VC3z2sOb0AJp7r7m9bQE6ylvF2Ob8dvWGvU6rCfWDeRxERERERkUOcgkQRkd5qxGx3W7OqU/FD/jn81vdHwFBAI8fZy/Y6taGhbq+ypmji07fJGNgyH9oaUkVJx9ASTVDbHOW02/7L3//9lnsgewAUjIDCMZ0ucVLTkzx4yYxOZcu3N2ieRBERERERkV5OcySKiPRWE86Bf/9vx+dTfw0v3wTxVs7yvMErySmMymjFG3eoN5nkWs2pqvlWmKL8QjbtakmVNUX2Q5D46i/h9Vvc/aOvhRmX881/lvPK2ppUlfLqJeDDDRKBxKjT8e5ckzqeVruKI/t7Ol22oTXOtro2yvLTP30bRURERERE5IBQj0QRkd4qqxhGfdbdH3w0HH4JfHs+8eGnADCn4CW+O3ATAK8VX8QiZ0Tq1HzCXHvyqE6Xa4rEP/Ktw5E4CzbVEt7znF0bOkJEgP/+lshT3+0UIoLhS57XAHi0dijlu1rY0f/kTte2MNgV73L9KaNJ83nweSwAllc0fOT2iYiIiIiISPfrFUHiHXfcweDBgwkGg8yYMYN33nmnp5skItI7nHYrfPY3cN7DYHsgdzC+L94Jlofs8DqsTfMAOPPML/HTot+x1BkGuD0Sx5Rm8ehlM1OX+tAeieEd0OCutLxmR5ijbp7Hl+9ewJFz5rFgU/tCKOX/3eu0wMYXGGRV4ffaFGYFONxax3C7kmYT5KfbJnLVw0t4zxrEg4kTeDx5NGuLT3dP3Dqfy48bxpqfncK5h7srSS/f3vhpvy0RERERERE5gHo8SHzkkUe45ppruOmmm1i8eDGTJk1i9uzZ1NTUdH2yiMjBLlQK07/hLr6yW3oeDDqy47M3DYrHMXNYATtNNgAl3iYG5WcwfUgeN39xAvABQeLKx+GPR8KtYzC3T+Wa3/+VU3//3/a6hiuTf2Pg32YSqd4I2xYC8Fj6lxkceYi1WTOxMLwWuIZnBv6D/37vCH55hHuP/zoTaCadZdsb2Vbfxv8lLuGF4T9m9Ay3NyXrXnDnWwQmDsgB4O7XNzF3dfX+++5ERERERERkv+rxIPHWW2/lG9/4Bl//+tcZO3Ysd911F+np6dx777171Y1Go4TD4U4/IiKHpLGf79jPHQweH0cOy6fOhACYWuDgsd0hw1lBH/C+oc1VK+HOo+CfF7cv5mKwklEurv0tHpIAvDx9Cd/yPkt/U80j995KdPN8AP7VUAZY/KT2+NTlRu94muCyBxhuVQKwwfRPHVvW3tOwLC8dxpwOvgyoWQ2bXgVgUnuQCHD5g4vYWtv6qb8eERERERER2f96NEiMxWIsWrSIE088MVVm2zYnnngi8+fP36v+nDlzyM7OTv0MHDiwO5srItJ7TLkIisa5+6NPA2D6kDzszAIATh3asZZWVtDd79Qj8Z0/QfVKd3/SV6i7YC4NJoPxdjnf9PyLgcE2hq39U6r6SZEXCIQ3AxApngzAfGcsy5yhHdd88zasquUAbHL6pYofX7wdgIF5aZCWC5MvcA88fx201DK8KJNhhRkAJBzDrXPXucOs5/0C2uo/8VckIiIiIiIi+1ePBom7du0imUxSXFzcqby4uJiqqqq96v/oRz+isbEx9bNt27buaqqISO/i9cPFL8IX7oZZVwMQ9Hk459gpAAQitamqu4PEoa3LYfPr7pDi99zegJz0M/jCnSyJD+Kn8QsBuCbwNI+PehUr1gQePwD9rDoA5ian8IMzZ5Lm8wAW34xdw85T74HsgdBcBZWL3WucdxpfnTkISI1gZmBu+4rMR1/rBoq1G+DXQ/FsfYsXrjqGJ759JJYFTy2tJPzwpe7CLk9clnqOcCTO9x5ZyrPLKvfvdykiIiIiIiIfSY8Pbf44AoEAoVCo04+IyCErGIJJ50Igq6Ms3e2RSMvOVFFW0Ecmrfwx9r/wwBmw9jlo3AaeAOvLvswdr25kYXk9TzhHUxUYjM9po2jdg+7J59yPk1GUutaa0VcwdVAuA3LTAKgmj8IZX4LZv+jUtLKRk/j2ccPxezt+mxnbr/3X7KxiOOvPHZXfvhO/12ZKWS5fPrwMD0lCVQvcYxtegog7NPreNzbz5JIKfvn8mk/zrYmIiIiIiMgn1KNBYkFBAR6Ph+rqzpPrV1dXU1JS0kOtEhHpwzL2DhJDQS9T7A0ddR5xhxZH+s3g7L8s4dcvreOu194DLDYP+UpHvf5TYdRnsT//B3aMvIDXjnqA73zlLAB+dfZExpSG+Mc3jnDrjvkcjG5fkTm7DAJZlGQHuemMscwcms/fLplOv5y0jmsPPxEuf8vdX/cCNLvtvfzYYUyx9mhr+/FIPMnf5m8BYEdjhIqGtk/+HYmIiIiIiMgn4u26yoHj9/uZOnUqr7zyCmeeeSYAjuPwyiuvcOWVV/Zk00RE+qaCEe525zqIhCEYIivo43B73V5V58bGEX7fSs6B6RdBYcz9cMS3wbJg5GxKR86mdI96U8pyeeGqozsKLAvOecCde7FkYqr4/BmDOH/GoH23tXgclE6CHctg41w47CuU5adzftYSiO1Rr2oFT0aPpLalo/Dd8jr6H9Z/72uKiIiIiIjIAdPjQ5uvueYa7rnnHh544AHWrFnD5ZdfTktLC1//+td7umkiIn1PThnkDQOThPL/AhD02Uy31+5V9cGdwzt9PmlsMYcNLoYTbnB/MvI/3r09Xph5BQw5uuu6uw39jLstfxN2bYC6zZySdOdvfC45A4DG8iX85Q13oZe8DHfOxnfLtQiLiIiIiIhId+vRHokA5557Ljt37uTGG2+kqqqKww47jBdffHGvBVhEROQjGnY81L0H782D0adhGYdJ9iYAHkqcwPneVwB4u7WErICXed8/jqrGCOP7h7Asq3vbOngWvPk7WPEYLHXnZQwC5U4xf06cxumet4lVrmBjtBm/1+aHp47mun8u590tChJFRERERES6W48HiQBXXnmlhjKLiOwvw46Hhfd0rMy8awNBYkTtdH6cuIid5DD4sOPhXYtZIwoozApQmBXombYOnAGWDclop+IHkiez1gzEMRaFVpgCGhlQOojjRhUCsLYqTDgSJxT09USrRUREREREDkk9PrRZRET2s8GzwPK4vRLry905CAF//0k4to/fJc7i8UZ3LsVxu1dS7inBkDsX48Aj4PBL3TLLJv+YbxAhwFbLnZlxnF3OpAHZFGUFKctLxxhYrF6JIiIiIiIi3apX9EgUEZH9KBiCgdNh63y3V+IudxVkq98kimoC7GiMsGBTLQCDCzJ6sqWu2b9wt8kE5A6G/tO4fOBETps6nIznj4BNTzDFXk//ATkATBucy9a6Vt7YsIvjRhX1WLNFREREREQONeqRKCJyMEotYvIG7Fjq7pdOojQ7CEA8aQAYnN8LgsTdPF448jswaCYe22JIQQa5o2YBMNVaz+SyHABOGVcCwJ/f2MxPn11NNJHsqRaLiIiIiIgcUhQkiogcjPpNdrcVi9wfgP5TKc1O61RtUH56Nzfs4/EOngnAzMBmhjUsgESUk8YWM6U9VLz3zc3c/2Z5zzVQRERERETkEKIgUUTkYFQy3t3Wb4ZEBDIKoWBkqkciQEGmn6zevlhJ4WhIz8eTaIWHzoK7P4PVVs/vvzyZ4UWZAPx1/hYSSaeHGyoiIiIiInLwU5AoInIwyiqFtLyOz4OOBMuiZI8gcVBvGtb8QWwbzn8Mpn4N0nKhZhU88x0G5qXz3HdmkZ/hp6KhjZdWVfd0S0VERERERA56ChJFRA5GlgX5wzo+Dz4aoFOQ+NkJpd3dqk+m/1Q44/dw4VPu5/UvQmsdQZ+H848YBMBf3tjUc+0TERERERE5RChIFBE5WA07wd0OPAIOOx+AKWW5BLw2Rw3P52tHDu65tn0S/Q6D4vHgJGDdCwBccEQZfo/N4q0NLNla36m6MYaWaKIHGioiIiIiInJwUpAoInKwmnU1fPVpuOhZ8LuLqvTLSWPxDSfx14tn4LGtnm3fJzHmc+52+cMAFGX4OXNCAQB/eWMzANvqWmmOJvjfp1Yy+Wdzmbtaw55FRERERET2B8sYY3q6EZ9UOBwmOzubxsZGQqFQTzdHREQOtIat8PvDwCThmOtg6d9JtjXyZmQwCTzMC5zAg81TsSzY83e3N394PP1z0j7wsiIiIiIiIoeqj5OvqUeiiIj0HTllMP4sd//1WyC8HU+8iWM8Kzjes5SfJ37LGfZbvP+fyG5+YS1Jp8/+u5mIiIiIiEivoCBRRET6lpN+AgUj3f2SianipOUD4Pf+O/i8/UanU55dVsk5d71FH+6ELyIiIiIi0uMUJIqISN8S6gffmOfO//iNV+GCJ+CLf8ZzQzWxiedjY7g2/XkA/u+0MXzj6CEA7oIs2xp6sOEiIiIiIiJ9m7enGyAiIvKxBbJg6HHu/vATUsX+U38BKx+hLFHOn0/P4biZg/F6bHY2RXlqaSWPLtzGlLLcnmmziIiIiIhIH6ceiSIicvBIy4UhxwBwYuw/eD3ub3OfP6w/AA8v3MZVDy/hxZVVROLJHmumiIiIiIhIX6QgUUREDi6TL3S3b/w/WHAXbP4vx43M59JZ7hDnp5dW8q0HF3HOXfOpa4n1YENFRERERET6FgWJIiJycBn3BRh8NDhxePF6eOB0rLuP4/8+U8RvzplEut8DwIqKRn7xrzU93FgREREREZG+Q0GiiIgcXCwLzn0Qjv4+DDkW/JlQtRz+8WXOnlzK6p+ewpPfPhKAxxdv57nllT3cYBERERERkb5BQaKIiBx80nLghBvgomfgm/+BQDZsXwjLHwVgclkuF80cBMBVDy9l0Zb6nmuriIiIiIhIH6EgUUREDm4FI+Doa9z9eT+HeBsAN54xjs9OKCHpGL714CIeX7Sdioa2HmyoiIiIiIhI76YgUUREDn4zLoPQAAhvhzd/D4DHtpjzhYmU5aWzsynKtY8t46ib5/E/T67o4cZ+iNY6ePoKuPMoeOAMeOIyqC/v6VaJiIiIiMghwjLGmJ5uxCcVDofJzs6msbGRUCjU080REZHebNnD8ORl7v6A6VA8Do75AeFAEQ+8Wc7TyyrZWNMMwNeOHMy1J48kK+jr3jYmovDKT2HDv902Hv9/ECp1jxkDD50NG1/udIrxBlk++BKWDb2UhGOxoqKRC2cOYkpZbve2XURERERE+qSPk68pSBQRkUODMfDKT+CN/9dRFhoAFz4BhaMAuP2VDfx27noA8jP8TBucSyjooygU4NxpZZTlpx/YNs77Bbx+S8fntFzqv/APvvJCghPMAr7f8HMc24d15FVYFrDpP1DxLgD/SU5iTuI81pkyQlYrP/7CVL44feiBba+IiIiIiPR5ChJFREQ+yM71sG2BGyjWbYK0XDj/cRgwFWMML62q5pfPr2FrXWun0/wem7OnDeCMif2YPiQPj20RSzj89LlV/Gv5DvIy/IwuCXHcqEL656ZRmBlgRHHWx2vbH6bDrnUw9ky3bVXLAXjbGc0Mey0AtyXOpG76dVwyawiLt9Tx5j9/z8+9f8FvJXGwaCSLXMI0mnReHv0zRh59DuP6hWiNJ0kkHXLS/fvjWxQRERERkYOEgkQREZGutNTC38+BikWABXlDIRqGorHEplzCW74ZbK5tI9yW4O3Ntbz1Xi1BohxnL+Nk3zIm2xt42PosyyOFbHZKqCJ/r1vcdcFURhRnEgr6KMwKfHh76svh95PA8sB1m8D2Yh44HatySapKna+EI5vmEKHztc4fHuMX2U/Dqif3uuwzyZn8IH4ZUdwA8YbTx3LJrCEf++sSEREREZGDk4JEERGRjyLaBI9fCutf3PtY8QSYfil4AhgM71XuIn/JH8iNV+9VNWn7WTXu+ywIF1BfvpTXY6NZZQZjWe6I6lDQy8PfnMnYfnv8XrVrg/szcjbYHnj7T/DCdTQVH07GZXOxbYs1KxbS/59n4MHBP+U8fEd8kx+/Dfe/Vd7p/n+7ZDpHjyiEpiqo24STP5IVD17H+Kon8eDwYvJwvhW/GrAA+MqMMq6fPZrs9G6eA/JjiCcdfvzMKiYNyOFLhw/s6eaIiIiIiBy0FCSKiIh8HI3boW4zeHywYa4b6sWa9lnVpBfQnD8Bk4xjtdaS2fQeVjK2V72l9ji+1fqtVE/FgNfm6BGFfOf44Uwq8rq9D1t3Qb8p8Lnb4ZnvQOVifhq/kIxjv8O1J4/ihqdW8tyCFZwwcQi/+coRAOxobGPmnHmp+5x5WD9u/dJh2La1d2M3v4558CysZIyNwy5i3q5c/lI9nGryOGxgDvd97XBy0n1Y1j7O7WHPLa/kyr+7vTGX3XQy2Wm9N/QUEREREenLFCSKiIh8Gq11sOCPsHUBeANut8JEBIYcA0d+F/x7LLriJN26S/8BsWZIz4OqFeAkiGb0Izn688xdV8cLdaXMdaaSlR7kd/1e4bjtd+1124SxmRG9g1qymXftsXzxzrdoaI3z14unc8zIwlS9O17dyH/W1XDXBVPJz+xiyPT7FnBx8PCqmcL98RN4wxlP0Odj1ogCfjB7FCOzDexYBgUjIauYXc1RLvjz27TFk3xlehmnTSxlS20rUwflEvR5PvXXnBIJw/JHwJcG474I/nR+/MyqVM9LDccWERERETlwFCSKiIj0pLpNcO+p0FzVqXitPZw/RU7iV7678VtJfhH/Ct/NX0hWeAMALyQP5/L49zqdUxwK8NYPT8Czrx6HH0UiCq//Bhq3ue3a9nbq0GanmNecSewy2fisJJf4XiLTtBDHy5+CF7Mk9xRe2RzZ65KFWQFOHlvMZccM2z8rWc+9Cd78nbtfOgm+/HdOvvc91lc3p6p87cjBXHfKKNL9XpKOwbbolT0pRURERET6GgWJIiIiPa2pGlY9AeEKdy7GVU9CpDF1+J20ozm3/jKO9q3lfvsXVJPLOc4c/vdLx3L7vI2s3hEG4LJjh/KjU8fsv3bVrIF378Ms+wdWNPyhVZPGooUgFYHh/DpyJvNindvhtS0uO3Yo3z951KcL9XavVr37vumF/LTxsxxlr2RwoIm/tR3J35In0T8nnaJQgFUVYQbmpfHUFUeRFdSQZxERERGRT0NBooiISG/TWAF//TzUboCSCYS/8hwn/2ERVeEI46zN1Jhc7r3ydCYMyKamKcJnf/8GDa0xXrz6aIYXZe3/9rTWuT0VW2owsRZY/xJbBp3N8wOu5rM7/0Jx+VOkRXd1OiU6/UrMiT9hweY67n2znNfX7wTgsxNKyAr4yAh4KctL4wtTBvDE4u0s29aAAU6bUMqJY4pxjKGuJUZRKNhx0Yat8LsJGMtm6SlPM+TNa8kJr9+ruS/ax/BA5GgGW1Xk0sRDyROZPW00v/jCBFpjSd7ZXMdxowrxeez9/12JiIiIiBzEFCSKiIj0Rs01bs/E8WdBRgG7mqM8uGALf5i3kZnD8vnbJTNSVavDEepbY4wu6abf35IJ8Hg7l4V3QHM1LHkQFt7jlo09E8Z9AVp28mJ5ku8uLiFIjJn2KgqtRl5KTmMnuR94G49t8cD5Y5m1bg601ED5G5CMsdAZyTmxH5NOhBu8f+NIexV26UQGDhkJC+4EOv9xZacJ8ZXY/1HhG0RrLAnAudMG8quzJ+7HL0VERERE5OCnIFFERKQPaY4m8HksAt79uIDJ/rbkQXdlaeN0Ko75QtiJVrwmAUAUH3OTU2iz0hkwaDjP5pzP3xdWpuqHaOGRzN8yJrG203UujV3Ly85UxpSGWFcVJi8jwCvXHuuu1rzuRXjjVmja4S7MkohAIkIt2Xw1ej0xvIyxtlJHFl+dfSQnz5wKvva5GzWPooiIiIjIh1KQKCIiIvvf+pfcFarjbZBRCJVL3DkgwV3pGavTXIcADJpFeOLX2R7L4N3Nuzhi7RxG2hU0mTSeSR7JeHszLySn8yfncyy54SRy0v00tsXx2BaZAe9eTQDcYdl//TxULf/AphosjOUl6c/Ck56NFcjCBHMxBSPw5A1xnyG8HXKHwKhT3fYrdJRPI94GHj/YvfgfBERERET2QUGiiIiIHHjJBGxfCOn5UDgSjHHDxWUPw9b5Hxj0NdkhbsiZwxbvENbsCBOJO5w4ppg/XzTto9+7tQ6euhzWvwjeNEzJRHbV7iTYuoMsq+1jP0ptYCDrrcEs9YynwNPK1BIvA/PS8dkW+NJwxp9DayxOrKWeHfEssooGU5ybwVsba/F6LCYNzCHT78X+pKtrS98Va4Unvwlr/wXpBVA2A3P097lnYxZvbKxlSH46W+pamTEkn8uPG9bTrRURERHZi4JEERER6Xl1m+Hdv8Cqp935FxNRiLXAlx+CwbMAaGyNM3dNNcePLiIvw//x79FSC4FM8AYAeGlVFS8sXEdzcxM2ScINtcRaGsmy2ii0GhhuVVJq1RI1PqrJZYK1mZn2KgJW4mPdtsbkcF/iFB5KnkCYDNKIMCbYwFem92PIsDHEfVmsq2qiNZaksqGNwbk+Mu04LVYGI4uzaI4m+L+nVhL02Vx+3DCKsoJsq2vl/CPKevcQ90NcOBInK+DtvEr53Bvhzd93qhfzZPLzyFm8Z/qx1BlOC2lYFvz76mNIGsPIoiyFziIiItJrKEgUERERAYwxVIejWBYEvR7CkThNkQSWBdvr29he38rOnTvJr1vM0fZy8lreo8IUsLrBQziSwAKm2euYYm+k1QSoJ4sCq5EAccCdE7KZTPKp73TfbU4h68wAGsnER4Lj7GWErFbedkbzavIwtphi1psBlJsSknQEh8WhAEcNK+C8GWUcPjivO7+qPs9xDJFEknjSkHQMiaRD3DH4myvIMU2sag1RFUujtjXOzvomWh0Pk/plUGCFyQ5ls718PSMCdZQltxFZPw9/9VLagsVsCY7hrQGX8lq1j9jmBVya+RZjQlGKjv0GgYLBmLs/g2WSvD7u5xw2dhSB1+cQqF6calezN5czWv6PzaY0VXbcqELuPH8qaX6FxiIiItLzFCSKiIiIfArGGMprW6lriRJLGAYEoxQWFuLxePCZBJGlj2K9eRuB+o45IaPeENEkhEz4I9+nzZPFX+PHMy8+kYAVo9mkscIMJY6X3HQf3kQrQ+0dHDdhCP1KSmmKGerranmvLZ1gWgbGQGs8SVssQVEoyMVHDaEoFMDvsQl47U4955KOwYK9e8IlYu4K2vEI+DMgGYNIA7Q1uNuWXdC43a1bNBancDTr6xK0eHNpcNKYMTT/g+ezPBCScVj+CGx6DdJyoXgcFTU7efnd1XijDcTxUGQ1UGbVUGrVkm81pU6NGQ+tBMmxWmgwGWTRisf6aH8UdoyF/QF1n0sewZXx79IvO8joAh/TttzD6WkrGGjXYkXDREOD+ULjNayL5jLU2kEOzRz5mVP53slj98tXIiIiIvJpKEgUEREROdCMgeqV4CQgZxCkt/cgjIRh29sQroTmamjYCmM/D4Wj4e27oG4z0V2b8DdtxYq17HXZmBVgbbIf2bQwwNq5z6ArYnxUm1yi+IjiI4aPqHG3Q6wdFFkNtBCklmxa7UwsJ0m2aSTbasWzR5DoIUmm2bsNH9UiZwQvJKfTbGWRbzeTlZHOmFGjmDU8H080jBMJY8eawZdGW2gIMU86kbRi6iMQba7FVzAMK5jN8MwonoYt1FZtJSsjjaQ/i5W1sDOZQU0iA8vrJ+D10NTUyGlrrmdA7ZsfuY1JY9FAZqdAcU8OFjaGCH7WO/3ZbEpZbQaxIDmGAquRK/zPMQU3MI7ZabxXeCKrq1s4i3kAVJlczoj+gp3kdLru8989mrFZbfDnE6Bxm3svy4vdvsJ5pSkgs2wi0cIJ1I85n1q7gLL8dAoy/RreLiIiIt1KQaKIiIhIb+ck3QU6Ft0P9eXgS4emHdC6q1O1qC+HZCJGumkFIGl58Jjkfm1K3Hhow08GERJ4aCSTRpNBIxnUm0wqTT4eHEbZ2xhhVeAlSaYV2S/3bjUB0q3oh9apN5lsNUXkW2EGWLtoM37uS55CFq0MsqppIJOM3BKOHD8cv5XEyizCzhsCOQNxsvpR76ST6U0QiNa7QW9ajrtgT0YhZBRAWz14g1RHvbTGkgzITWNLbSsbqpuYPa4EO9YEiYi7sJDtYUttCxv++09GxteyfMBXyC4oYURRFufePZ8tta2cMLqIv3ztcLfx4R3wxDeg/L8AGH8myVgbXjr/N9xuCgibDOY5h7ElYyKzzziPaUMLyQh48Xns/fJdi4iIiOyLgkQRERGRvsgY2LUeat+DYDbkD4OsEvdYMg7GAY/fPd5W54ZbiVj7NoITj5BILyKSPZREW5h4Yw3R5loCgQDBzDx2OVnUtcWJJhy8lkXCwI5EJk4gm53NcZra4owozmJIYSZgcIzbJGPa93H/2DiuXzbZiTrMyn8S2/QGJtZGPJBLTUMT4eotRI2HJpNGM2m0mCAFVpgiq54s2iiyGghYcdqsNHJNY+rRd5g8qkweNg4hWsi1WwnRgo3T6Stq9ORyQ+CHvBgeRCzhHpsxJI9HLpvZLf+JPkx1OMLD72zj3MMHUpId7DhgDOxc5y4KlDOIddt28OTTTxDdtZkz7LeYwpq9rvVaciLfi3+bOkKUhIJkBr18/ajBnD9jUDc+kYiIiBwKFCSKiIiISI+IJRwa2+JE4knS/R5iSYfWWJJQ0Edehh/bomPuxrZ6ks27CPuLcTwBsoI+ymtbSPN5GJCbhmWMO09j9Up45jsQGgBfvBuy+1PbHGXGL18h4RjuvnAqJ48r6dHn/lRaaqF2I7EdK2HVk3i3vomNQ5NJY4UzhDheXncm8G+O4ncXzmTKwGysph3QshPyhkDuYPcy0QSOMbTFk7REkyQdQ7rfQ5rPgwFWVrjBrde2CKX5GNfP/fOzZVk0tMawsGiNJyjKCvJueR3rq5soyAwwrCiT4YWZWHv+t5MDKppI0tgWx3HoHErvFm+DyiVge6FwFPgzcTa+Stu6Vwg6LXj86eDPIFEwhvfiuWDZlIQCVKSNoTA7ncKsQPc/lIiI9FoKEkVERETk4GIMvC/EWr69gXVVTZw9dcDBFXBVrYAnLoOaVV1WTWKzxjOKKH5aYg4GC4PFLrJ5NXkYMbzUmhAbTX/CpAMd31Oaz0M86ZDpM5TEtpJvNbLD5LPNFBGn8wI6fo+NYwzDizKZXJZLXoYP2hrJ97SQkZ5OWloGyWSSwkwvxc1ryQhvxDEOTnuHUtuCYNMWMnctxfKlYQdDJH0ZRBIQi8dI84K3vWl2pB6PiWMFQ1iBLPCl09YSxhNvwfb6sH1BPHmD2dXvWIxjyGp6D/+u1VCzCk+8FcqOoMWbQ1UsQEUkyM42Q2FyJ95AGul+L9GSyUQLJvLaFnfl9njScNLYYsb1CzGiKOuArqadSDrYgF2zEqqWQ8ViIsbLlopKdjbHeL1tCKtixYxxNjLA2knIaiUzu4BQTj6O7SUjXk9WrJqBDe/gS7Z1XNcO4HU+fIoAgCaTxhoGU587idX+CSyoTeOkY4/jc5P7U5S1j8BSREQOCQoSRURERET6MicJ29+Fhi3QsIXkO3/Gaq7Gbh9eXmuyiOCnv1X7sS4bx0uLlY7PiWKwqDdZqeHmuyWMTRV5tPnzabCyyY1WpIaZt5kAzaQRw8sYawt+a//O19mdqk0O5aaELU4x5aaYLaaErRTjLRiGCYQYVpjJiWOKGJSXjs9EKMjNxTGGpkiC6nCEjTubOXxwHmW5afisJOHaHVTX1NCYNoCVa9dT1Lyacmsg88MFTCrLZeW2egZteYxLfC8xxGz/1O2vMTnE8aTegQaTwfPJ6eww+QStGDm0MMbeQrHdSIA4ARMly2rb6zrbTQHrnQEk/NlM9Fdi+dMIjDienLJxEOpPpHgytVGL0lBw71XfP6YttS00RRJUNLRRHAqyYFMtS7bWMyg/g6tPHEG6vxtXgBcReZ9wJE5zJEHSMTjGpLaOgaKsADnp/p5u4gGjIFFERERE5GBjDNFYlLqWKLVtsKs5Sqh2KRnN24knkwzIDZLus/FaDva2t6FmNWBhwpVYTZUfemknEIKsEqzGCqz4R1/JO275sU0Szx6LxzQQYqE9kYTtT/V/NEAUHwvMBBpj4E+2kmW1kR30Egz42NWaJOm483DWmyzakjaZtJFhRcggQtyTTgtBkokEQSvGdHstE6zNJC0Pm5wS1jplrDUDsTEMtyrIsVoYmB6jxBchxxujwVdIIh7HxNsYEllNvvPhAWzUeNlJDsZY5Fth0q0om5wStptCqk0uAStOmVVDBhGGWDvwWh1zeTrGwt5jtfWwSSOBBy8OIctdNKnN+FnqDGelGUwSDw0mg2OHpDM+sZK0lgrIG4pn4HR2JoJs2LINb7wZbzJC3Pazy9eP7f4RrAhMAstiZ1UFeVaYhuAgfnveVOqaY8zftAuvbdM/N41jRxYS9HmIxWJ4atezecWbJDe/SWHjCjLaKgiYD+/JGCadN5Ljec83kori48jyJDhhRA5HFCWguQYyi2HUqWB72NUcJZpwyPYlyahcQEtdJYmG7QTzB7GpooqV775OuVPMg8kTCZPR6T7TBuVy79cPJxT0fYQ3T0QOJTXhCOW1rZ/6OrGEw+odjUTje/6aDRt3NrO1rpUV2xtwPiQhG1sa4l/fnXVwjYJopyBRREREREQ6xFrcefXibRANgz8DkglorXVXrs4b6g4dNwaaqqBhqzsHY+N2CPVz52K0bIi1uufHWyFnEJROdK/vOLRPoviRmhOJJ/HY1geuSN0WSxJ3HIwDkUSSwswAtm1h2ueAbI4mCAV9BH0eookkrdEkkUSSdzbX4RjD0SMKKcj8kHkA2+qhbjPUber0k6x9D8/7Vk7/qBLGJmp1rH5eF+hPfqyi0yrrSTvAXwIX8AQnQCALgO31bfy/cw/jpLHFn+i+n0q0Gba/Q3TnZjZsq2RjWyaVO+soblhCCXWMsCsoshq6vMxGewhR/PgTzVSYAsqsaobaVR9YfyvFXBz7Prll45lclss/3t5KUzSRmtNzaGEGZ07uzzEjCt35Ug/Cv7R3h9rmKC3RJOkBT+q77eq7TCQd5q6upqKhjS9M7k/+h/1/JD0mmkjis21s2yIST7K9vg2PbZGf6Scr4D2o/p/ZVtfKabf9l3Ak0S3383ksPLaFx7KwbXfftizqWmJMH5zHo9/q+cXdDgQFiSIiIiIiIp9EJOwu8hOuBMsD6XngzyRWtQrTWEGgtdpdPT1vKPUJH56CYST92dj+dLIz06FlF/jSIJDpBrcNW90V17HcVdjTcnr4AT+cMYal2xrY2RQllkgwtHUFI6KriC56kLSWCprtEOGYOw9n2KQz0161zyHurSbASjOYHRRSYOpJ4CGWO5wTrXewGtuHdmcUgTdAmzfEq3UFLIn1p8bkECFAIxk0mExaPZngDTI4x8uQbC/ZBcUkfCFKc9KIJRxaogkmDcxhWGEGaT4PaX4PQa/nUw/D7nbJhBvQJ2OEm5rZWBOm0WRQE/USc6A1mqCxLU5+ZgBjDFvrWlldGaYtniQciRP0etzFlmJJWmJJ2mJJYsnOq957bYspZbkE/R5iiSTRhEMs4aS2bfEktc3RVI8sy4IpZblMG5TrTq9qIOC1Oawsh6KsINGEG2DlZwQY1y9EsP37/yCOY4gkknhtG7933/+IcLBqiyXZtKuZupYYaT4PBZkBPLZFSXYw9Q8qsYRDJJEkw+/FtqC+Nc6LK6uoa4kyKN/twVvXEuMf72xlbVUTPo9FbrqfhrY4sUTHf+tB+emM75+N4xiMgaQx1LXEmDwwhxPHFhMK+hhamEHQ1/V8sLGEQ3U4wsC89E/03Luao7y0qgrHwGkTSsnL6Hpo8F/nl3Pr3PU0tweHSeM+R266j9yPcP6HsYDhRZnkZXQOyAuzAgwvymRC/2yGFGTs89z6lhh1rTGGFWZ+qjb0VgoSRUREREREZP9qX/RoW10rKysa8Xtt8mMVZFUvJO7LpCQ/j+zGtbRa6azOPZ5RwwaT6ffy4NtbaI0luXTWELxtu+Cpy2Hjy5+4GWGTRq0J4WBTYDXiYONg4WBh2mcSNdgYywJsklhg2di2G9hYgGN5SFpeksYmafuwvH4sx8Fj4vhtB8cOEPcEidsBbJMkkGgimGwCLJKWlwQemhw/u0wOYW8e9Qk/Htsi3e8hw+8l3e/B6/XRYmfQTDoRTxYJbzp2pIFBvkYCTisZfg9ZOxeREX6PjHhtag7UPZ0Z/SlLzfBP/F0FfTaRuNN1xT0EvDZZQS+7mmMf+379soN4PTZJx9AUieNpD3Tb4slUOwJem5nD8snPCJCd5iPgs/HZFh7bxuux8Lb3AvN5bDy2+9kAlQ1tVDVGaI4miMSTJBx3DrvdW3DDplDQh8e2iCcdWmJJIvEksYRDLOkGprv34wmHkuwgI4qyaGiLsbMpim1ZqZCvNDuYWjXdMYbWWJIdDe79bdticH46pdlpeGw3cAtHEuSm+1m+vYHKxgg+2yJpDO/tbKaqMUI8ufd/X5/HIt3vJZZwSBqTCgR9Hmuf9T9IZsCLMYaW2EebtzY/w8/o0iwSSYMBWqIJapqiZPg9FGYFaGiNkxX0srWujV3NUU4YXcTpk0pJ83lT30fCMXjbe+uV17awvroJn20ztl+ILbWt1LVEeX3DLupa3PfI77WZOTSfwfnplOVnMK5fiPqWGCeOLcbnsTHG8N8Nu/jqve/s1d7cdB9PXzGLsvxPFmhK1xQkioiIiIiISO9kjLuQULQZkjF3OH31Kqhe6Q47j7dBpBHTVg9t9VhOHMf2kbS8nVarPlhFjRfLAj8Jri+9l4b0QaT7ve3hXpSkY0g6cOr4EvIy/YSCXiJxJxVkprcHmTnpPtL9XhzHnRJgR2Mbi7c24LEsAj4bv8ftGRjwevB7bYI+m4LMAPkZfrwem6rGCI8v3k5tcwy7feaCXc0x1uwIU98aS83DWdUYYWvdp5+/7mCXm+6jMCtAcyRBOJJIBZsfZmxpiBHFmVQ2uEOXW6JJRpVkcfWJI7Ati9rmGDnpvtQUAOFInJdXV9PQGsfncUPcaMIhJ93PiyurWF/d5A55/4iB4/4wpCCDgNdmbVXTPo9PG5TLkIIM/rViB63t7TrzsH786LNjUnWy03wfqQelfHIKEkVERERERKTvM8YdGm63hwixVnfuztZdkIi6c3higXFwnCTRRIJoLEE0niAWTxBLJLFwaI3EaIsl3RVYHYNx4phEHC9JItEIsWgEy+PFsX3UtTrYTgyf04bfiWAsDxFviIg3EwsL28TxWw6laQnynQa8bdUErURqaHFrLElbPIkTj5JJK+mmhWCiGV+yhYg3m2qTS9ROI9wWo9wzCF/ZdOycgRAMsavN8NmJ/Zk0MMcNVD3+jmfvxVpjCdpiScprWwC3R2GG34NjwLYgrX2OxqDPw4aaZlZXhmlsi9PYPiw36TjEHUMy6fZ0SziO29Ow/bMxhpLsIKXZQUJpPoJej9t70WOnejAaY6hridMcjZNwDH6PTbrfS9DnBqa7g1M3PLXx2DZbalt4b2cL+Rl+ikMBHOMOx40lHN7b2UxLNIltgW1Z+L02pdlpZKd5STiG1TvCNEUSOI7Bsiyy03xUhdsoyAxw5LB8AJIODC3MYGBeOv2yg53mLnQcw45whNZoAp/HJuEYSrODRBMOkXgSn8emINO/3+c7jCUc5q2toS2eSA2rtrAYlJ9OayxJRUMroaCPtrg7/+zw4kyeWlLB2qomEu3D5b22jW1DJO4QjsSZ2D+b0pw0EkmHZdsaGZSfzsjiLIpCAWaPKyHgtVlZEWZlZSNb61pZVF7PO+V1H9jGP104ldnjSvbrc8uHU5AoIiIiIiIiIiK91qtra3hk4TbyMv2s2N7IiopGAJbdeDLZ6VrBvTt9nHzN201tEhERERERERERAeAzo4v4zOgiAFZWNPKFP77JEUPzFSL2cgoSRURERERERESkx4zvn828a4/71Cszy4GnIFFERERERERERHrUwDytytwX2D3dABEREREREREREen9FCSKiIiIiIiIiIhIlxQkioiIiIiIiIiISJcUJIqIiIiIiIiIiEiXFCSKiIiIiIiIiIhIlxQkioiIiIiIiIiISJcUJIqIiIiIiIiIiEiXFCSKiIiIiIiIiIhIlxQkioiIiIiIiIiISJcUJIqIiIiIiIiIiEiXFCSKiIiIiIiIiIhIlxQkioiIiIiIiIiISJcUJIqIiIiIiIiIiEiXFCSKiIiIiIiIiIhIlxQkioiIiIiIiIiISJcUJIqIiIiIiIiIiEiXFCSKiIiIiIiIiIhIlxQkioiIiIiIiIiISJcUJIqIiIiIiIiIiEiXFCSKiIiIiIiIiIhIlxQkioiIiIiIiIiISJe8Pd2AT8MYA0A4HO7hloiIiIiIiIiIiPQ9u3O13Tnbh+nTQWJTUxMAAwcO7OGWiIiIiIiIiIiI9F1NTU1kZ2d/aB3LfJS4sZdyHIfKykqysrKwLKunm3NAhMNhBg4cyLZt2wiFQj3dHJGPTe+w9HV6h6Wv0zssfZ3eYTkY6D2Wvk7v8MHNGENTUxP9+vXDtj98FsQ+3SPRtm0GDBjQ083oFqFQSP+zSp+md1j6Or3D0tfpHZa+Tu+wHAz0Hktfp3f44NVVT8TdtNiKiIiIiIiIiIiIdElBooiIiIiIiIiIiHRJQWIvFwgEuOmmmwgEAj3dFJFPRO+w9HV6h6Wv0zssfZ3eYTkY6D2Wvk7vsOzWpxdbERERERERERERke6hHokiIiIiIiIiIiLSJQWJIiIiIiIiIiIi0iUFiSIiIiIiIiIiItIlBYkiIiIiIiIiIiLSJQWJvdgdd9zB4MGDCQaDzJgxg3feeaenmyQCwJw5czj88MPJysqiqKiIM888k3Xr1nWqE4lEuOKKK8jPzyczM5OzzjqL6urqTnW2bt3KaaedRnp6OkVFRfzgBz8gkUh056OIAHDzzTdjWRZXX311qkzvsPR2FRUVXHDBBeTn55OWlsaECRN49913U8eNMdx4442UlpaSlpbGiSeeyIYNGzpdo66ujvPPP59QKEROTg6XXHIJzc3N3f0ocghKJpPccMMNDBkyhLS0NIYNG8bPfvYz9lwHUu+w9Davv/46Z5xxBv369cOyLJ566qlOx/fXO7t8+XKOPvpogsEgAwcO5JZbbjnQjyaHiA97h+PxONdffz0TJkwgIyODfv368dWvfpXKyspO19A7LAoSe6lHHnmEa665hptuuonFixczadIkZs+eTU1NTU83TYTXXnuNK664ggULFjB37lzi8Tgnn3wyLS0tqTrf+973ePbZZ3nsscd47bXXqKys5Itf/GLqeDKZ5LTTTiMWi/HWW2/xwAMPcP/993PjjTf2xCPJIWzhwoX86U9/YuLEiZ3K9Q5Lb1ZfX89RRx2Fz+fjhRdeYPXq1fz2t78lNzc3VeeWW27htttu46677uLtt98mIyOD2bNnE4lEUnXOP/98Vq1axdy5c3nuued4/fXX+eY3v9kTjySHmF/96lfceeed/OEPf2DNmjX86le/4pZbbuH2229P1dE7LL1NS0sLkyZN4o477tjn8f3xzobDYU4++WQGDRrEokWL+PWvf82Pf/xj7r777gP+fHLw+7B3uLW1lcWLF3PDDTewePFinnjiCdatW8fnPve5TvX0DgtGeqXp06ebK664IvU5mUyafv36mTlz5vRgq0T2raamxgDmtddeM8YY09DQYHw+n3nsscdSddasWWMAM3/+fGOMMc8//7yxbdtUVVWl6tx5550mFAqZaDTavQ8gh6ympiYzYsQIM3fuXHPssceaq666yhijd1h6v+uvv97MmjXrA487jmNKSkrMr3/961RZQ0ODCQQC5h//+IcxxpjVq1cbwCxcuDBV54UXXjCWZZmKiooD13gRY8xpp51mLr744k5lX/ziF835559vjNE7LL0fYJ588snU5/31zv7xj380ubm5nf4scf3115tRo0Yd4CeSQ8373+F9eeeddwxgtmzZYozROywu9UjshWKxGIsWLeLEE09Mldm2zYknnsj8+fN7sGUi+9bY2AhAXl4eAIsWLSIej3d6h0ePHk1ZWVnqHZ4/fz4TJkyguLg4VWf27NmEw2FWrVrVja2XQ9kVV1zBaaed1uldBb3D0vs988wzTJs2jXPOOYeioiImT57MPffckzq+efNmqqqqOr3D2dnZzJgxo9M7nJOTw7Rp01J1TjzxRGzb5u233+6+h5FD0pFHHskrr7zC+vXrAVi2bBlvvPEGp556KqB3WPqe/fXOzp8/n2OOOQa/35+qM3v2bNatW0d9fX03PY2Iq7GxEcuyyMnJAfQOi8vb0w2Qve3atYtkMtnpL6cAxcXFrF27todaJbJvjuNw9dVXc9RRRzF+/HgAqqqq8Pv9qd9wdisuLqaqqipVZ1/v+O5jIgfaww8/zOLFi1m4cOFex/QOS2+3adMm7rzzTq655hr+53/+h4ULF/Ld734Xv9/PRRddlHoH9/WO7vkOFxUVdTru9XrJy8vTOywH3A9/+EPC4TCjR4/G4/GQTCb5xS9+wfnnnw+gd1j6nP31zlZVVTFkyJC9rrH72J5TWIgcSJFIhOuvv57zzjuPUCgE6B0Wl4JEEflUrrjiClauXMkbb7zR000R+ci2bdvGVVddxdy5cwkGgz3dHJGPzXEcpk2bxi9/+UsAJk+ezMqVK7nrrru46KKLerh1Il179NFHeeihh/j73//OuHHjWLp0KVdffTX9+vXTOywi0sPi8Thf+tKXMMZw55139nRzpJfR0OZeqKCgAI/Hs9fqoNXV1ZSUlPRQq0T2duWVV/Lcc8/x6quvMmDAgFR5SUkJsViMhoaGTvX3fIdLSkr2+Y7vPiZyIC1atIiamhqmTJmC1+vF6/Xy2muvcdttt+H1eikuLtY7LL1aaWkpY8eO7VQ2ZswYtm7dCnS8gx/2Z4mSkpK9FnFLJBLU1dXpHZYD7gc/+AE//OEP+fKXv8yECRO48MIL+d73vsecOXMAvcPS9+yvd1Z/vpCetjtE3LJlC3Pnzk31RgS9w+JSkNgL+f1+pk6dyiuvvJIqcxyHV155hZkzZ/Zgy0RcxhiuvPJKnnzySebNm7dX1/WpU6fi8/k6vcPr1q1j69atqXd45syZrFixotNvRLt/o3r/X45F9rcTTjiBFStWsHTp0tTPtGnTOP/881P7eoelNzvqqKNYt25dp7L169czaNAgAIYMGUJJSUmndzgcDvP22293eocbGhpYtGhRqs68efNwHIcZM2Z0w1PIoay1tRXb7vxXEY/Hg+M4gN5h6Xv21zs7c+ZMXn/9deLxeKrO3LlzGTVqlIaEygG3O0TcsGEDL7/8Mvn5+Z2O6x0WQKs291YPP/ywCQQC5v777zerV6823/zmN01OTk6n1UFFesrll19usrOzzX/+8x+zY8eO1E9ra2uqzre+9S1TVlZm5s2bZ959910zc+ZMM3PmzNTxRCJhxo8fb04++WSzdOlS8+KLL5rCwkLzox/9qCceSaTTqs3G6B2W3u2dd94xXq/X/OIXvzAbNmwwDz30kElPTzcPPvhgqs7NN99scnJyzNNPP22WL19uPv/5z5shQ4aYtra2VJ1TTjnFTJ482bz99tvmjTfeMCNGjDDnnXdeTzySHGIuuugi079/f/Pcc8+ZzZs3myeeeMIUFBSY6667LlVH77D0Nk1NTWbJkiVmyZIlBjC33nqrWbJkSWpF2/3xzjY0NJji4mJz4YUXmpUrV5qHH37YpKenmz/96U/d/rxy8PmwdzgWi5nPfe5zZsCAAWbp0qWd/p635wrMeodFQWIvdvvtt5uysjLj9/vN9OnTzYIFC3q6SSLGGGOAff7cd999qTptbW3m29/+tsnNzTXp6enmC1/4gtmxY0en65SXl5tTTz3VpKWlmYKCAnPttdeaeDzezU8j4np/kKh3WHq7Z5991owfP94EAgEzevRoc/fdd3c67jiOueGGG0xxcbEJBALmhBNOMOvWretUp7a21px33nkmMzPThEIh8/Wvf900NTV152PIISocDpurrrrKlJWVmWAwaIYOHWr+93//t9NfVvUOS2/z6quv7vPPwBdddJExZv+9s8uWLTOzZs0ygUDA9O/f39x8883d9YhykPuwd3jz5s0f+Pe8V199NXUNvcNiGWNM9/V/FBERERERERERkb5IcySKiIiIiIiIiIhIlxQkioiIiIiIiIiISJcUJIqIiIiIiIiIiEiXFCSKiIiIiIiIiIhIlxQkioiIiIiIiIiISJcUJIqIiIiIiIiIiEiXFCSKiIiIiIiIiIhIlxQkioiIiIiIiIiISJcUJIqIiIiIiIiIiEiXFCSKiIiIyIf62te+hmVZWJaFz+ejuLiYk046iXvvvRfHcXq6eSIiIiLSTRQkioiIiEiXTjnlFHbs2EF5eTkvvPACn/nMZ7jqqqs4/fTTSSQSPd08EREREekGChJFREREpEuBQICSkhL69+/PlClT+J//+R+efvppXnjhBe6//34Abr31ViZMmEBGRgYDBw7k29/+Ns3NzQC0tLQQCoX45z//2em6Tz31FBkZGTQ1NRGLxbjyyispLS0lGAwyaNAg5syZ092PKiIiIiIfQEGiiIiIiHwixx9/PJMmTeKJJ54AwLZtbrvtNlatWsUDDzzAvHnzuO666wDIyMjgy1/+Mvfdd1+na9x3332cffbZZGVlcdttt/HMM8/w6KOPsm7dOh566CEGDx7c3Y8lIiIiIh/A29MNEBEREZG+a/To0SxfvhyAq6++OlU+ePBgfv7zn/Otb32LP/7xjwBceumlHHnkkezYsYPS0lJqamp4/vnnefnllwHYunUrI0aMYNasWViWxaBBg7r9eURERETkg6lHooiIiIh8YsYYLMsC4OWXX+aEE06gf//+ZGVlceGFF1JbW0traysA06dPZ9y4cTzwwAMAPPjggwwaNIhjjjkGcBd1Wbp0KaNGjeK73/0u//73v3vmoURERERknxQkioiIiMgntmbNGoYMGUJ5eTmnn346EydO5PHHH2fRokXccccdAMRisVT9Sy+9NDWn4n333cfXv/71VBA5ZcoUNm/ezM9+9jPa2tr40pe+xNlnn93tzyQiIiIi+6YgUUREREQ+kXnz5rFixQrOOussFi1ahOM4/Pa3v+WII45g5MiRVFZW7nXOBRdcwJYtW7jttttYvXo1F110UafjoVCIc889l3vuuYdHHnmExx9/nLq6uu56JBERERH5EJojUURERES6FI1GqaqqIplMUl1dzYsvvsicOXM4/fTT+epXv8rKlSuJx+PcfvvtnHHGGbz55pvcdddde10nNzeXL37xi/zgBz/g5JNPZsCAAaljt956K6WlpUyePBnbtnnssccoKSkhJyenG59URERERD6IeiSKiIiISJdefPFFSktLGTx4MKeccgqvvvoqt912G08//TQej4dJkyZx66238qtf/Yrx48fz0EMPMWfOnH1e65JLLiEWi3HxxRd3Ks/KyuKWW25h2rRpHH744ZSXl/P8889j2/ojq4iIiEhvYBljTE83QkREREQOHX/729/43ve+R2VlJX6/v6ebIyIiIiIfkYY2i4iIiEi3aG1tZceOHdx8881cdtllChFFRERE+hiNExERERGRbnHLLbcwevRoSkpK+NGPftTTzRERERGRj0lDm0VERERERERERKRL6pEoIiIiIiIiIiIiXVKQKCIiIiIiIiIiIl1SkCgiIiIiIiIiIiJdUpAoIiIiIiIiIiIiXVKQKCIiIiIiIiIiIl1SkCgiIiIiIiIiIiJdUpAoIiIiIiIiIiIiXVKQKCIiIiIiIiIiIl36/4AM4nOuZGjHAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iniciando sessao de testes, para retestar o modelo  necessrio rodar novamente essa clula e a prxima com os novos parametros; teste 1\n",
        "\n",
        "#diminuindo pela metade o nmero de hidden layers\n",
        "batch_size = 7\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a205xz0CEcSU",
        "outputId": "0aecc65f-8c0c-465c-dee4-ae1556965926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_511:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_575:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_639:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_703:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_767:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_831:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_895:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 30) == 0:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB8iXq1TEkqK",
        "outputId": "6c217d3c-0ab5-4888-eb5b-ff9f6850c30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200  Current loss: 0.37595316767692566\n",
            "Epoch 30/200  Current loss: 0.04107404500246048\n",
            "Epoch 60/200  Current loss: 0.011039414443075657\n",
            "Epoch 90/200  Current loss: 0.009560907259583473\n",
            "Epoch 120/200  Current loss: 0.008033348247408867\n",
            "Epoch 150/200  Current loss: 0.006691853981465101\n",
            "Epoch 180/200  Current loss: 0.005934994202107191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por reduzir apenas a quantidade de hidden layers, conseguimos chegar num resultado ainda melhor do que anteriormente, ou seja, poupamos processamento e ainda chegamos em um resultado melhor.\n"
      ],
      "metadata": {
        "id": "R0iJfT7SHTTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sup =[]\n",
        "for i in range(len(traind_scores)):\n",
        "    for j in range(len(traind_scores[i])):\n",
        "        sup.append(traind_scores[i][j][0])\n",
        "\n",
        "\n",
        "tests = []\n",
        "i = 0\n",
        "while i+batch_size <= len(X_test):\n",
        "\n",
        "    o = session.run([outputs],feed_dict={inputs:X_test[i:i+batch_size]})\n",
        "    i += batch_size\n",
        "    tests.append(o)"
      ],
      "metadata": {
        "id": "rSOZr0rwHemt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests_new = []\n",
        "for i in range(len(tests)):\n",
        "  for j in range(len(tests[i][0])):\n",
        "    tests_new.append(tests[i][0][j])"
      ],
      "metadata": {
        "id": "p9b56gxyHhQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_results = []\n",
        "for i in range(1264):\n",
        "    if i >= 1019:\n",
        "      test_results.append(tests_new[i-1019])\n",
        "    else:\n",
        "      test_results.append(None)"
      ],
      "metadata": {
        "id": "ucgku0PsHjio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we now plot predictions from the network\n",
        "plt.figure(figsize=(16, 7))\n",
        "plt.title('Bitcoin prices from December 2014 to May 2018')\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('Scaled Price of Bitcoin')\n",
        "plt.plot(scaled_data, label='Original data')\n",
        "plt.plot(sup, label='Training data')\n",
        "plt.plot(test_results, label='Testing data')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9mMRaujKHl1m",
        "outputId": "f2f157c1-7133-425c-92d8-94d5a9548bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input could not be cast to an at-least-1D NumPy array",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-26262efa06e2>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Original data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Testing data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input could not be cast to an at-least-1D NumPy array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input could not be cast to an at-least-1D NumPy array"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x700 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABRIAAAJwCAYAAAD1Op1tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADgRElEQVR4nOzdd5hU9b3H8c+Zvr2wNOlFpSjRoKgYRURRg2I3arxYEls0aowxGJNYYqKJubYYNRKjxt71GmNBRbEiNiyIdKR3tu/Uc/84M2fO7MzuzsB23q/n4ZmZ35yZ+W3zPveT7/f3NUzTNAUAAAAAAAAAzXB19AYAAAAAAAAAdH4EiQAAAAAAAABaRJAIAAAAAAAAoEUEiQAAAAAAAABaRJAIAAAAAAAAoEUEiQAAAAAAAABaRJAIAAAAAAAAoEUEiQAAAAAAAABaRJAIAAAAAAAAoEUEiQAAtDPDMHTttde2++eeddZZGjx4cLt/bksGDx6ss846q6O3kSYSiejKK6/UgAED5HK5dNxxx3X0liDprbfekmEYevrppzt6KwAAADsdgkQAAHbQAw88IMMwUv716tVLEydO1Msvv9zi699//31de+212rZtW9tvFln717/+pZtvvlknnXSSHnzwQf3iF7/o6C01a/Dgwfbvn8vlUmlpqfbcc0+dd955mjNnTkdvr1tZsGCBrrzySu21114qKipS3759NWXKFH388ccZr1+9erVOOeUUlZaWqri4WMcee6yWLl2adt3dd9+tk08+WQMHDpRhGFkH7Oeee64Mw9DRRx+d1fV33XWXHnjggayuzUXid/Cwww7L+PyMGTPs39GmvldtpTP8zD755BMdffTR6tOnjwoLCzVmzBjdcccdikajrfVlAgDQ5jwdvQEAALqL66+/XkOGDJFpmlq/fr0eeOAB/fCHP9SLL76Y8v/g19fXy+NJ/p/g999/X9ddd53OOusslZaWttn+ZsyYoVgs1mbvv72+/fZbuVyd73/bfPPNN9WvXz/deuutHb2VrO2111765S9/KUmqrq7WN998o6eeekozZszQL37xC91yyy0dvMPu4Z///Kfuu+8+nXjiifrZz36myspK/eMf/9D++++vV155JSVIq6mp0cSJE1VZWanf/OY38nq9uvXWWzVhwgR9/vnn6tGjh33tn//8Z1VXV2vcuHFau3ZtVnv5+OOP9cADDygQCGS9/7vuuksVFRVtUgkcCAQ0a9YsrVu3Tn369El57pFHHlEgEFBDQ0Orf25LOvpn9sknn2j8+PHadddd9etf/1r5+fl6+eWXdemll2rJkiW6/fbb2/TrBwCg1ZgAAGCH3H///aYkc+7cuSnrW7ZsMb1er3n66ac3+/qbb77ZlGQuW7asDXfZucRiMbOurq6jt9GsiRMnmqNHj27xunA4bAaDwXbYUfMGDRpkTpkyJW29rq7OPO6440xJ5l133dUBO2tds2bNMiWZTz31VJt+Tk1NTZPPffzxx2Z1dXXK2qZNm8yePXuaBx54YMr6n//8Z1OS+dFHH9lr33zzjel2u82rrroq5drly5ebsVjMNE3TLCgoMM8888xm9xiLxcwDDjjAPOecc5r8+WcyevRoc8KECVldm4tBgwaZkyZNMouLi83bbrst5bmVK1eaLpfLPPHEEzP+97KtdfTP7NxzzzV9Pp+5efPmlPWDDz7YLC4u3t4vCwCAdtf5/ud/AAC6idLSUuXl5aVUH0qpZyRee+21+tWvfiVJGjJkiN32t3z5cvv6hx9+WOPGjVN+fr7Kysp08MEH67XXXkt5z7vuukujR4+W3+/XLrvsoosuuiitVbrxGYnLly+XYRj661//qnvvvVfDhg2T3+/Xvvvuq7lz57b49SVaumfPnq3zzz9fPXr0UHFxsaZNm6atW7emXDt48GAdffTRevXVV7XPPvsoLy9P//jHP+znGldGbdu2Tb/4xS80ePBg+f1+9e/fX9OmTdOmTZvsa4LBoK655hoNHz5cfr9fAwYM0JVXXqlgMJjyXjNnztQPfvADlZaWqrCwULvvvrt+85vfNPl1Jb4vs2bN0tdff23/TN56662U79ltt91mf8/mz58vyapiPOigg1RQUKDS0lIde+yx+uabb1Le/9prr5VhGFq4cKHOOOMMlZSUqGfPnvrd734n0zS1cuVKHXvssSouLlafPn30v//7vy3+LJqTl5enhx56SOXl5frjH/8o0zTt52KxmG677TaNHj1agUBAvXv31vnnn5/285Okl19+WRMmTFBRUZGKi4u177776tFHH025Zs6cOTryyCNVUlKi/Px8TZgwQe+9916bfP3RaFS/+c1v1KdPHxUUFGjq1KlauXJl2nW57Gn+/Pk6/fTTVVZWph/84AdNfk/Hjh2rwsLClLUePXrooIMOSvt5P/3009p3332177772msjRozQpEmT9OSTT6ZcO2jQIBmG0eTnNvbQQw/pq6++0h//+MesXzN48GB9/fXXevvtt+3f7UMOOcR+funSpTr55JNVXl6u/Px87b///nrppZeyfv9AIKATTjgh7XfjscceU1lZmY444oi013zxxRc666yzNHToUAUCAfXp00fnnHOONm/ebF8za9YsGYah5557Lu31jz76qAzD0AcffNDkvjr6Z1ZVVaVAIJBWdd63b1/l5eW1+HoAADoLWpsBAGgllZWV2rRpk0zT1IYNG/S3v/1NNTU1OuOMM5p8zQknnKCFCxfqscce06233qqKigpJUs+ePSVJ1113na699lqNHz9e119/vXw+n+bMmaM333xTkydPlmSFINddd50OO+wwXXjhhfr222919913a+7cuXrvvffk9Xqb3fejjz6q6upqnX/++TIMQ3/5y190wgknaOnSpS2+VpIuvvhilZaW6tprr7U/e8WKFfZQjIRvv/1Wp512ms4//3yde+652n333TO+X01Njf3/3J9zzjn6/ve/r02bNun//u//tGrVKlVUVCgWi2nq1Kl69913dd5552nkyJH68ssvdeutt2rhwoV6/vnnJUlff/21jj76aI0ZM0bXX3+9/H6/Fi9enBYkOfXs2VMPPfSQ/vjHP6qmpkY33nijJGnkyJGqr6+XJN1///1qaGjQeeedJ7/fr/Lycr3++us66qijNHToUF177bWqr6/X3/72Nx144IH69NNP0wbd/OhHP9LIkSN100036aWXXtINN9yg8vJy/eMf/9Chhx6qP//5z3rkkUd0xRVXaN9999XBBx/c4s+iKYWFhTr++ON13333af78+Ro9erQk6fzzz9cDDzygs88+W5dccomWLVumO++8U5999lnK784DDzygc845R6NHj9ZVV12l0tJSffbZZ3rllVd0+umnS7JC1KOOOkpjx47VNddcI5fLpfvvv1+HHnqo3nnnHY0bN65Vv/4//vGPMgxDv/71r7VhwwbddtttOuyww/T555/bwUyuezr55JO166676k9/+lNK4JqtdevW2X/DkhXUfvHFFzrnnHPSrh03bpxee+01VVdXq6ioKOfPqq6u1q9//Ws7TM3Wbbfdpp///OcqLCzU1VdfLUnq3bu3JGn9+vUaP3686urqdMkll6hHjx568MEHNXXqVD399NM6/vjjs/qM008/XZMnT9aSJUs0bNgwSdZ/Z0466aSM/02ZOXOmli5dqrPPPlt9+vTR119/rXvvvVdff/21PvzwQzvsHDBggB555JG0fTzyyCMaNmyYDjjggKy/Dwnt9TM75JBD9MQTT+j888/X5Zdfbrc2P/vss7r55ptz3jcAAB2mQ+shAQDoBhKtzY3/+f1+84EHHki7XpJ5zTXX2I+bam1etGiR6XK5zOOPP96MRqMpzyVa6TZs2GD6fD5z8uTJKdfceeedpiTzX//6l7125plnmoMGDbIfL1u2zJRk9ujRw9yyZYu9/sILL5iSzBdffDGrr3vs2LFmKBSy1//yl7+YkswXXnjBXhs0aJApyXzllVfS3mfQoEEp7YC///3vTUnms88+m3Zt4ut+6KGHTJfLZb7zzjspz99zzz2mJPO9994zTdM0b731VlOSuXHjxma/lkwmTJiQ1tqc+J4VFxebGzZsSHlur732Mnv16pXSujhv3jzT5XKZ06ZNs9euueYaU5J53nnn2WuRSMTs37+/aRiGedNNN9nrW7duNfPy8lpscTXNplubExLfi8TP5Z133jElmY888kjKda+88krK+rZt28yioiJzv/32M+vr61OuTfw8YrGYueuuu5pHHHGEvWaaVlv1kCFDzMMPP7zVvv5Ea3O/fv3Mqqoqe/3JJ580JZm33377du/ptNNOa/L715LZs2ebhmGYv/vd7+y1jRs3mpLM66+/Pu36v//976Ykc8GCBRnfr6XW5iuuuMIcMmSI2dDQYJpmyz9/p6Zamy+77DJTUsrfVXV1tTlkyBBz8ODBaf8daiyxh0gkYvbp08f8wx/+YJqmac6fP9+UZL799tsZj4LIdMzBY489ZkoyZ8+eba9dddVVpt/vN7dt22avbdiwwfR4PCn/Tc1We/7MIpGIefHFF5ter9f+vxFut9u8++67c943AAAdidZmAABayd///nfNnDlTM2fO1MMPP6yJEyfqpz/9qZ599tnter/nn39esVhMv//979OGkSQq/V5//XWFQiFddtllKdece+65Ki4uzqol8Uc/+pHKysrsxwcddJAkZZxQmsl5552XUmV04YUXyuPx6L///W/KdUOGDMnY1tjYM888o+9973sZq58SX/dTTz2lkSNHasSIEdq0aZP979BDD5VktUFKstsIX3jhhVYdNHPiiSfaVaOStHbtWn3++ec666yzVF5ebq+PGTNGhx9+eNr3QpJ++tOf2vfdbrf22Wcfmaapn/zkJ/Z6aWmpdt9996x/Fs1JtHVWV1dLsr6HJSUlOvzww1O+h4kW0MT3cObMmaqurtb06dPTBnokfh6ff/65Fi1apNNPP12bN2+236u2tlaTJk3S7Nmz077/O/r1T5s2LaUq7KSTTlLfvn3t7/X27OmCCy7I7Zsat2HDBp1++ukaMmSIrrzySns9UcHq9/vTXpP4XiauycXChQt1++236+abb8743tvrv//9r8aNG5fS1l1YWKjzzjtPy5cvt1v4W+J2u3XKKafosccek2RVDA4YMMD+b0tjztbehoYGbdq0Sfvvv78k6dNPP7WfmzZtmoLBoJ5++ml77YknnlAkEmm28juT9v6Zud1uDRs2TEcccYQefPBBPfHEEzrmmGP085//3K6gBgCgK6C1GQCAVjJu3Djts88+9uPTTjtNe++9ty6++GIdffTR8vl8Ob3fkiVL5HK5NGrUqCavWbFihSSltQn7fD4NHTrUfr45AwcOTHmcCBUznZOXya677pryuLCwUH379k0551GygsRsLFmyRCeeeGKz1yxatEjffPNNSpjntGHDBklWSPrPf/5TP/3pTzV9+nRNmjRJJ5xwgk466aQdmhTd+Gtp6ucgWS3Rr776qmpra1VQUGCvN/6+l5SUKBAIpLRZJtadZ8Vtr5qaGkmyw7dFixapsrJSvXr1ynh94nu4ZMkSSdIee+zR5HsvWrRIknTmmWc2eU1lZWVKYL2jX3/j3zvDMDR8+HD792579pTt76hTbW2tjj76aFVXV+vdd99NOYcvEZA1PrdTkj25eHvOx7v00ks1fvz4Fv9OcrVixQrtt99+aesjR460n2/u98Dp9NNP1x133KF58+bp0Ucf1amnntrkWYJbtmzRddddp8cff9z+vUuorKy0748YMUL77ruvHnnkETtwfuSRR7T//vtr+PDhWe1L6pif2U033aTbb79dixYtsj/vlFNO0cSJE3XRRRfp6KOPTjtPFwCAzoj/awUAQBtxuVyaOHGi/f88Js6l62zcbnfGdXM7zohrTmsOFIjFYtpzzz11yy23ZHx+wIAB9mfOnj1bs2bN0ksvvaRXXnlFTzzxhA499FC99tprTX7tLWmNryXTZ7flz+Krr76SJDtwicVi6tWrlx555JGM1zcV0maSqOy7+eabtddee2W8pvGgi7b++rdnT7n+XEOhkE444QR98cUXevXVV9NCtvLycvn9fq1duzbttYm1XXbZJafPfPPNN/XKK6/o2WefTQnrI5GI6uvrtXz5cpWXl6u4uDin921t++23n4YNG6bLLrtMy5Yts8/SzOSUU07R+++/r1/96lfaa6+9VFhYqFgspiOPPDKtanTatGm69NJLtWrVKgWDQX344Ye68847s95XR/zMJGsg1qGHHpr2Ozd16lRdfvnlWr58eU5hKAAAHYUgEQCANhSJRCQlq8EyaapKZ9iwYYrFYpo/f36TQcigQYMkWYNMhg4daq+HQiEtW7ZMhx122HbuPHuLFi3SxIkT7cc1NTVau3atfvjDH27X+w0bNswOvZq7Zt68eZo0aVKLE1NdLpcmTZqkSZMm6ZZbbtGf/vQnXX311Zo1a1arfX+cP4fGFixYoIqKipRqxPZWU1Oj5557TgMGDLCry4YNG6bXX39dBx54YLMBWmJYxldffdVk0JG4pri4uF1+56RkxWGCaZpavHixxowZ0y57isVimjZtmt544w09+eSTmjBhQto1LpdLe+65pz7++OO05+bMmaOhQ4fmPLTju+++k2QNamps9erVGjJkiG699VZddtllTb5HU38zgwYNavJ3OPF8Lk477TTdcMMNGjlyZJP/Ddu6daveeOMNXXfddfr9739vrzf++Saceuqpuvzyy/XYY4+pvr5eXq9XP/rRj7LaT0f9zCRrkE00Gk1bD4fDkpL/twIAgM6OMxIBAGgj4XBYr732mnw+nx3eZJIImLZt25ayftxxx8nlcun6669Pq8pJVGgddthh8vl8uuOOO1Kqtu677z5VVlZqypQprfTVNO3ee++1/59hSbr77rsViUR01FFHbdf7nXjiiZo3b56ee+65tOcSX+Mpp5yi1atXa8aMGWnX1NfXq7a2VpLVMtlYItDI1Lq4vfr27au99tpLDz74YMrP8auvvtJrr7223aFqa6ivr9f//M//aMuWLbr66qvtEOmUU05RNBrVH/7wh7TXRCIR++uYPHmyioqKdOONN9qtnQmJn8fYsWM1bNgw/fWvf80Ymm/cuLGVvyrp3//+t33eoyQ9/fTTWrt2rf1719Z7+vnPf64nnnhCd911V8ZQL+Gkk07S3LlzU4Kpb7/9Vm+++aZOPvnknD/30EMP1XPPPZf2r2fPntpnn3303HPP6Zhjjmn2PQoKCtL+eyNJP/zhD/XRRx/pgw8+sNdqa2t17733avDgwc0es5DJT3/6U11zzTX63//93yavSVShNq46ve222zJeX1FRoaOOOkoPP/ywHnnkER155JFp7fBN6aifmSTttttumjlzZkqbfjQa1ZNPPqmioiI7+AYAoLOjIhEAgFby8ssv25U7GzZs0KOPPqpFixZp+vTpzbYZjh07VpJ09dVX69RTT5XX69Uxxxyj4cOH6+qrr9Yf/vAHHXTQQTrhhBPk9/s1d+5c7bLLLrrxxhvVs2dPXXXVVbruuut05JFHaurUqfr222911113ad999815AMH2CIVCmjRpkk455RT7s3/wgx9o6tSp2/V+v/rVr/T000/r5JNP1jnnnKOxY8dqy5Yt+r//+z/dc889+t73vqf/+Z//0ZNPPqkLLrhAs2bN0oEHHqhoNKoFCxboySef1Kuvvqp99tlH119/vWbPnq0pU6Zo0KBB2rBhg+666y71798/ZaBEa7j55pt11FFH6YADDtBPfvIT1dfX629/+5tKSkp07bXXtupnNWX16tV6+OGHJVlViPPnz9dTTz2ldevW6Ze//KXOP/98+9oJEybo/PPP14033qjPP/9ckydPltfr1aJFi/TUU0/p9ttv10knnaTi4mLdeuut+ulPf6p9991Xp59+usrKyjRv3jzV1dXpwQcflMvl0j//+U8dddRRGj16tM4++2z169dPq1ev1qxZs1RcXKwXX3yxVb/W8vJy/eAHP9DZZ5+t9evX67bbbtPw4cN17rnnSlKb7um2227TXXfdpQMOOED5+fn29zzh+OOPt/8Hgp/97GeaMWOGpkyZoiuuuEJer1e33HKLevfurV/+8pcpr3vxxRc1b948Sdb/EPHFF1/ohhtukGS1wI4ZM0YDBw5MO19Ski677DL17t1bxx13XIv7Hzt2rO6++27dcMMNGj58uHr16qVDDz1U06dP12OPPaajjjpKl1xyicrLy/Xggw9q2bJleuaZZ3I+V3TQoEEt/u4XFxfr4IMP1l/+8heFw2H169dPr732mpYtW9bka6ZNm6aTTjpJkjIG4Zl05M9MkqZPn64zzjhD++23n8477zzl5eXpscce0yeffKIbbrghZWAVAACdWgdNiwYAoNu4//77TUkp/wKBgLnXXnuZd999txmLxVKul2Rec801KWt/+MMfzH79+pkul8uUZC5btsx+7l//+pe59957m36/3ywrKzMnTJhgzpw5M+X1d955pzlixAjT6/WavXv3Ni+88EJz69atKdeceeaZ5qBBg+zHy5YtMyWZN998c9rXlGmPTX3db7/9tnneeeeZZWVlZmFhofnjH//Y3Lx5c8q1gwYNMqdMmZLxfQYNGmSeeeaZKWubN282L774YrNfv36mz+cz+/fvb5555pnmpk2b7GtCoZD55z//2Rw9erT9vRk7dqx53XXXmZWVlaZpmuYbb7xhHnvsseYuu+xi+nw+c5dddjFPO+00c+HChc1+baZpmhMmTDBHjx6dstbc98w0TfP11183DzzwQDMvL88sLi42jznmGHP+/Pkp11xzzTWmJHPjxo0p62eeeaZZUFCQ1T4yGTRokP37ZxiGWVxcbI4ePdo899xzzTlz5jT5unvvvdccO3asmZeXZxYVFZl77rmneeWVV5pr1qxJue7//u//zPHjx9tf27hx48zHHnss5ZrPPvvMPOGEE8wePXqYfr/fHDRokHnKKaeYb7zxRqt9/bNmzTIlmY899ph51VVXmb169TLz8vLMKVOmmCtWrEh7/Y7sqSlnnnlm2t+885/z79c0TXPlypXmSSedZBYXF5uFhYXm0UcfbS5atCin973//vub3VNzf2ONrVu3zpwyZYpZVFRkSjInTJhgP7dkyRLzpJNOMktLS81AIGCOGzfO/M9//pPV+2azh8R/N+bOnWuvrVq1yjz++OPN0tJSs6SkxDz55JPNNWvWNPnfoWAwaJaVlZklJSVmfX19VnvrDD+zV155xZwwYYJZUVFh+nw+c8899zTvueeerPYPAEBnYZhmK5+kDgAAdgoPPPCAzj77bM2dOzdlWjUAtKVIJKJddtlFxxxzjO67776O3g4AADsVzkgEAAAA0GU8//zz2rhxo6ZNm9bRWwEAYKfDGYkAAAAAOr05c+boiy++0B/+8AftvffeGacuAwCAtkVFIgAAAIBO7+6779aFF16oXr166d///ndHbwcAgJ0SZyQCAAAAAAAAaBEViQAAAAAAAABaRJAIAAAAAAAAoEVdethKLBbTmjVrVFRUJMMwOno7AAAAAAAAQJdimqaqq6u1yy67yOVqvuawSweJa9as0YABAzp6GwAAAAAAAECXtnLlSvXv37/Za7p0kFhUVCTJ+kKLi4s7eDcAAAAAAABA11JVVaUBAwbYOVtzunSQmGhnLi4uJkgEAAAAAAAAtlM2xwYybAUAAAAAAABAiwgSAQAAAAAAALSIIBEAAAAAAABAiwgSAQAAAAAAALSIIBEAAAAAAABAiwgSAQAAAAAAALSIIBEAAAAAAABAiwgSAQAAAAAAALSIIBEAAAAAAABAiwgSAQAAAAAAALSIIBEAAAAAAABAiwgSAQAAAAAAALSIIBEAAAAAAABAiwgSAQAAAAAAALSIIBEAAAAAAABAiwgSAQAAAAAAALSIIBEAAAAAAABAiwgSAQAAAAAAALSIIBEAAAAAAABAiwgSAQAAAAAAALSIIBHohh6Zs0LnP/SxGsLRjt4KAAAAAADoJggSgW7o6ue+0qtfr9fLX63t6K0AAAAAAIBugiAR6GacVYgeF3/iAAAAAACgdZAyAN3M6m319v2igKcDdwIAAAAAALoTgkSgm/luS519PxozO3AnAAAAAACgOyFIBLqZVY4gMRwlSAQAAAAAAK2DIBHoZlZuTbY2R2KxDtwJAAAAAADoTggSgW5mpaMiMUJFIgAAAAAAaCUEiUA3s2absyKRIBEAAAAAALQOgkSgm1lfFbTvR6K0NgMAAAAAgNZBkAh0I9GYqY01ySAxTEUiAAAAAABoJQSJQDeyuSaoqCM8pCIRAAAAAAC0FoJEoBtZV9WQ8jhKRSIAAAAAAGglBIlAN+I8H1GSwkxtBgAAAAAArYQgEehGGlck0toMAAAAAABaC0Ei0I2sr0wNEhm2AgAAAAAAWgtBItCNbKxObW2OxqhIBAAAAAAArYMgEehGGiJRSZLbZUiSIpyRCAAAAAAAWglBItCNhCJWBWK+zy2JYSsAAAAAAKD1ECQC3UgiSCzweSTR2gwAAAAAAFoPQSLQlYUbpEjyXMRgoiLRH69IZNgKAAAAAABoJQSJQFcVi0p37Sfd/j0pGpGUXpEYiVKRCAAAAAAAWgdBItBV1W+Vti6XqtdKlSslScF4cJgXPyORYSsAAAAAAKC1ECQCXVWkIXm/ao0kZ0ViPEiktRkAAAAAALQSgkSgqwrXJ+/HKxJDkagkKd8fb21m2AoAAAAAAGglBIlAVxWuS97f9p0kKRRNrUgM09oMAAAAAABaCUEi0FU5KxK3rZCUbG3OZ9gKAAAAAABoZQSJQFeVUpGYaG1OBImckQgAAAAAAFoXQSLQVYUdw1YaVSQWJM5IpLUZAAAAAAC0EoJEoKtyViTWb5MkBdMqEmltBgAAAAAArYMgEeiqnGckxqKKxUy7lbkgfkYiw1YAAAAAAEBrIUgEuqqUIDFsT2yWpHy/VZEY5YxEAAAAAADQSggSga7K2docDdttzZKzIpHWZgAAAAAA0DoIEoGuylmRaEYVCkfthwEvU5sBAAAAAEDrIkgEuipnRaKkUDgkSfJ5XPK6DUlShIpEAAAAAADQSggSga7KWZEoKRwPEv1ul9yueJBIRSIAAAAAAGglBIlAV9U4SAw5KxKtP+0IU5sBAAAAAEArIUgEuqpGrc3hUFiSFSR6Eq3NMVqbAQAAAABA6yBIBLqqRhWJoXCDJMnvcclDazMAAAAAAGhlBIlAV9WoIjHiaG32uGhtBgAAAAAArYsgEeiqGp+RGElvbQ4ztRkAAAAAALQSgkSgq4qkBomR+NRmn9sxbIXWZgAAAAAA0EoIEoGuKtw4SExWJLrjZyRGY6ZMkzARAAAAAADsOIJEoKtqHCRGEmckuuV1Jf+0qUoEAAAAAACtgSAR6IpiMamhMmUpmjgj0Z08I1Fi4AoAAAAAAGgdBIlAV7TmUylUI/mLpaJdJEnR+BmJfk9qkBiOMXAFAAAAAADsOIJEoCta9Jp1O2yi5M2T5GxtdsnjaG2OUpEIAAAAAABaQacJEm+66SYZhqHLLruso7cCdH5L37Jud50suTySpJijtdntMmTEixKpSAQAAAAAAK2hUwSJc+fO1T/+8Q+NGTOmo7cCdA21m6zb8mGS2yspeUai32v9WScGrtSHovrzKws0Z+nm9t8nAAAAAADoNjo8SKypqdGPf/xjzZgxQ2VlZR29HaBriDRYt96A5HJLkqLRZEWiJHnj5yTe9+4y3f3WEv3o3g/bf58AAAAAAKDb6PAg8aKLLtKUKVN02GGHtXhtMBhUVVVVyj9gpxSus249eZLLqki0W5s91p91wGsFjN+s5e8EAAAAAADsOE9Hfvjjjz+uTz/9VHPnzs3q+htvvFHXXXddG+8K6ALCjopEdyJIjEhKDxKDEc5IBAAAAAAAO67DKhJXrlypSy+9VI888ogCgUBWr7nqqqtUWVlp/1u5cmUb7xLohExTitRb9z159rAVM5qc2iwlz0oMESQCAAAAAIBW0GEViZ988ok2bNig73//+/ZaNBrV7NmzdeeddyoYDMrtdqe8xu/3y+/3t/dWgc4lEkze9wYcQWLqGYkBj/X3Q5AIAAAAAABaQ4cFiZMmTdKXX36Zsnb22WdrxIgR+vWvf50WIgKIS1QjSikVibFoRMOM1Rq/+L/S3tcoz5fe2hyLmXK5jHbdLgAAAAAA6B46LEgsKirSHnvskbJWUFCgHj16pK0DcEicj2i4rfMR42ckmtGwXvL9RoEVYen59Qp4r5AkhaLJILEhElW+r0OPRgUAAAAAAF1Uh09tBpCjREWiN08yDEdrc0QBw2pv1ppP7dbmYDhqv7Q+ZN03TVMNjnUAAAAAAICWdKrSpLfeequjtwB0fuHEoJX4kKJ4kKj4GYmSJMNtT22uaojYy3WhqHpIuvixz/TOwo16+1cTVVbga4dNAwAAAACAro6KRKCrSbQ2e/Os20RrcywZGMrlsac2O9XHqxA/Wb5VVQ0RLdtc26ZbBQAAAAAA3QdBItDVRJqoSEwJEpMViU518dbmhoh1G4uZbbZNAAAAAADQvRAkAl2NXZHYXGuzyz4j0SlxRmLifMQoQSIAAAAAAMgSQSLQ1djDVvKt2yYqEvN8LkmmLnI/ryNccyVJ9eGITNNUMGJNco6aBIkAAAAAACA7BIlAR3j/b9LfxkrV63J/baIiMdHaHD8j0Yg1Grbicesk92z9yvuk/uG7VZLV2hyKxpTID8kRAQAAAABAtggSgY7w2m+lzYult27K/bV2RWJ82IpdkRhNXhM/I/Fk99spL60PRdUQjtmPaW0GAAAAAADZIkgEOpLjXMPlm2o17V8f6f3Fm5p/TTjzsBXDdLQ2G24FPIb2cy1IeWl9OKpgJBk40toMAAAAAACyRZAIdCQjefevr32r2Qs36vR/zmn+NeFGFYnx1maXs7XZ5VKRqu2HtaZfktXaHHRUJDK1GQAAAAAAZIsgEehIRvJP0Nlm7KwaTBNpdEZivCLRZTpeY7iV70pWKIZlXVMXitoTmyWJHBEAAAAAAGSLIBHoUMmSxP5lefb9z7/b1vRLGlckxoNEj5xnJHqUZySDRJesxLAhHLUnNkuckQgAAAAAALJHkAh0JCMZJDqHoHy8YmvTr0lUJDYKEn2O4FAut/JdyVZnIx4k1oUijSoSCRIBAAAAAEB2CBKBDpUMEusdAV91QyTTxRZ72ErqGYn5Cjre1q2AK/l+LlkhZR1TmwEAAAAAwHYiSATam7MK0MgcJEaiMTXJrkhMnJGYCBIbkte43Aooc2szFYkAAAAAAGB7ECQC7S0acjxIBolBZ5DYXKVguM66tYetuCVJBUZDymV+I9nanAgSQxEz5YxEgkQAAAAAAJAtgkSgvUUcgZ9jarOzIjHcbEVivIXZm9raXOCsSIxF5HecmWjEW5vD0VhKRWJzHwMAAAAAAOBEkAi0t4izIjFZEVgfcrY2N1MpmAgi7YpEa9hK4yDRq+TnJCoSI7GYGiKO1mbOSAQAAAAAAFkiSATam7Mi0dHmXO8YghKONVeRGH+N22fdJs5IdLY2R8Mq9iRDQo8Rr0iMmAqGaW0GAAAAAAC5I0gE2lvEMV05mjzHMOWMxJwqEuNnJKZUJEblioUavdBUKJpakRglSAQAAAAAAFkiSATaW9QRJDpCxZSpzc1VJCaqGD3xisT4GYkBx3AVxcKpgaWs9uZILKYGZ0Uirc0AAAAAACBLBIlAe2uytdk5bKW5isR4QOj2W7fx1uYUsUij6dCSSzGrtdlZkUiQCAAAAAAAskSQCLS3lNZmR5CYMmwli6nNHn/qrVMskhpYyqpIDEdjjc5IzH7bAAAAAABg50aQCLS3DBWJsZipYCQZ8EWaS/iijYLEgQdoW/Fuja6JpLU2GzIVjsXU4Kh8ZNgKAAAAAADIFkEi0N4iobT7zhBRksLNViQmpjbHg0RvQG/sc2/qNc20NjuDRFqbAQAAAABAtggSgfaWoSLReT6ilO3U5mRL81YVp17TxLCVcDSWEloytRkAAAAAAGSLIBFobylnJFr3GweJ4aYqBU0zvbVZUk0o9fWZKxKtINFZkUiOCAAAAAAAskWQCLS3lIrEsKTUQStSM8NWnOGg22ffrUsLEqMZzkiMKRw11eAYtkJrMwAAAAAAyBZBItDenGFgPOxryLa12RkOegL23dpgpNFnNNfazBmJAAAAAAAgdwSJQHvLUJHYOEgMx3KvSLwnckzyuVgk2QId55KpSMxUvaMikanNAAAAAAAgWwSJQHtLCRIzn5HYdEVi/LVun+RK/vnWBCP6a+Rkzd77NmvBjKZ+jqwg0bo2bK8RJAIAAAAAgGwRJALtLeKoKkxMbY6fceh2GdYlTZ2RmGhXdvtTlutCEUXkUU3f/ZKLobqUawxZ71nTkGyDbupjAAAAAAAAGiNIBNqbs1IwHio2RKxEr9DvkdTM1OZEa7PHl7JcG7SCyIDfETCGU4PEZEViMkikIhEAAAAAAGSLIBFob84hKPHW5mC8tTkRJDZdkRgPIR2DViSrIlGS8gKO9VBNyjXueEVi2NE2HWPYCgAAAAAAyBJBItDenBWJZkyKRRWMVyQW+N3WJU2ekRivSHRnrkjMDzgqEkO1Kdf43OlvF6UiEQAAAAAAZIkgEWhvzsnLkhQJKmQHiYnW5qamNserGT2pZyTWxisSCwKOgLHRGYmZgkQqEgEAAAAAQLYIEoH21miasqIhuyIx0docbSrgi2QOEusSFYl+r+Sy3qNxRaI3w187FYkAAAAAACBbBIlAe4s0qkiMhhSMxIPAeNlgOGrKzBTyZZjaHIrEFIqfqVjg8ySDxHBqkOjPVJFIjggAAAAAALJEkAi0t8atzdFQWmuz1ERVoj1sJRkkJgatSFK+3y25vNYDM7U92pfhr53WZgAAAAAAkC2CRKC9RYOpjyPBtNZmSYpkCvkSIaQjSKwNWdWMPo9LXrdLcmUoPZTkzTRshSARAAAAAABkiSARaG9prc1hR2tzMkgMRzMMXMnQ2lwXjA9aSUxTcXszfixnJAIAAAAAgB1BkAi0t7TW5uTU5kLHQYaRSExqPL05HiTOXLRNizfUSJJq4kGiHUK6PMok0xmJ5IgAAAAAACBbBIlAe0sLEsN2a3PA65ZhWMt5L54n3bGXFKx2XGsFiVVhl/7yygJJUl28tbkgkRQ2DhJ9hZKaqEiktRkAAAAAAGSJIBFob5EMZySGrSDR73XL67L+LAPfPi9tWyF9+ZTjWiuEDJoeedxW4phoiw54tyNIpCQRAAAAAABkiSARaG+ZpjbHz0P0e1xyu4zU56vWJO/HpzYH5VNxwDoLMRy1wkCvO/7n7AwS3X77zMRMQSJTmwEAAAAAQLYIEoH2lggSDbf9OFFV6Pe47EpDW9Va+24sXs0YkkdFASswTAxl8SZe5xy24itQolfal+GMxBgViQAAAAAAIEsEiUB7SwSJ/kL7sd3a7HHJ63bJJceQlepkRWKwoV6SFJJXhf5ERWIiSExUJDoSQ1+BZFjrXld6aJhpMDQAAAAAAEAmBIlAe4skgsTi+OOgPWzF73HL4zLkUzh5ffU6+24wGA8STY9MWcFgONJMa7M33xEkNqp0FBWJAAAAAAAgewSJQHuLT15ODEFRNKxQPEj0xSsSU4JExxmJoQbrjMSQvHYlYqhxa7PL2dqcDBJ9GSsSCRIBAAAAAEB2CBKB9mSaGVqbg2lnJPoVSb6mYZsUqpPWfK5Y/TZJUlgeReJDVtJbm50VicnWZo8jSAzEJ69QkQgAAAAAALLlafkSAK0m6qg0TFQkRkJ2a7PP40pvbZakzx6SXr5SfeIPQ/LIjAeIiUDRlwgS3Y4/a1++VGedmeic2lzg86ghHCJIBAAAAAAAWaMiEWhPibZmKWXYSshxRqLX7ZLPiKS+7qN7Ux6GHBWJocYViYmzF6XUMxIdRyTm+61wkdZmAAAAAACQLSoSgfaUUpFYFF9zDluxWpvNxhWJiQEtcWHTI1c8QLRbmz3xpLCgp+MzMk9tzvdaf/oxpjYDAAAAAIAsESQC7SkSr0g03JI3YN2Phu0zEq3WZpcMNapIjDSkPAzLI6NRkOhxxSsSnUGiN18yjPjzyeU8n1WRSGszAAAAAADIFq3NQHtKtDa7fZLbL0kyw0GF423Kfo9LXneGMxKdLdFKbW1OvNbnyRAkOqY253mSvc0j+1rVkFGCRAAAAAAAkCUqEoH2lGht9vgkt9daiiRDQr/XbVUWNj4jMZIeJLrjlYiJ8xW97kRrc4/khb5CO0g8eNceOitvsCaP7q36UFSPfbRSMc5IBAAAAAAAWaIiEWhPiUDQ7Zc8VkViNJwMCX1u64xEf9oZialBYlgeuxIx3HjYSlprs7VeUeDVtVNHa/ywCrlcVuhIRSIAAAAAAMgWFYlAe4rGh6a4fdY/SbF4SGgYVlWh1+2St3GQqNTAL2x65IkHiIkW54xBoqO1WWZysoo7fm4iw1YAAAAAAEC2qEgE2lMiSPQ4gsR4RaLf45JhGOpbEkg/I7GRkLyKxFKHrfgSQWJ+RfJCTyBjkOhKBIlUJAIAAAAAgCwRJALtKeIctpKoSLTCxUQQeOmkXVXmb/5twvIoHDF148vf6NnPVktynJGYX+64sD5zkBhfinJGIgAAAAAAyBJBItCeEsNW3D6rKlFS0aLndYPnPvm9bklSr+KAdu3hbfZtQvJofXWD/vH2UnvNk6hIdLmTF4brmm1t5oxEAAAAAACQLYJEoD1F4xWJHr9dkShJZ3jekD9RUSipR6D5gC8st2qDqZOd7dZmScqPT24eOtE6fFFKDRLjw1bIEQEAAAAAQLYYtgK0p5TW5tT+5R6+kH2/pdbmkOlVVUNqkOj1JINI/fwTqWqt1HuUoyIxmRoaiYpEWpsBAAAAAECWCBKB9pShtTmhrz85YKXU1/w45bA8CkVSr/E6KxLzyqx/UjJIjEXtpxMViQSJAAAAAAAgW7Q2A+3J0dpsulLPQeztT1YkFnubD/hCGf43gJQg0amZMxJNepsBAAAAAECWCBKB9mS3NnsVc6VWJFZ4G+z7Rd6WKxIb8zUVJCaGrziCxMSxiQxbAQAAAAAA2SJIBNqT3drsV7RRRWKFJ2jfL3BH1ZxMFYkex7CWFJkqEu3W5pY2DAAAAAAAYCFIBNpTNDlsJWykBoll7mRFojsWUnMicqet5dTaHA8SY1QkAgAAAACALBEkAu0pUZHo8SlsplYVlrrqkw8iVpBYbeY18Ubp1Ye5BIkugyARAAAAAADkhiARaE/2GYl+RRpVJBYZ8SBx7n3S5w9LkqrVVJCYrskzEhMHIqYEidYtU5sBAAAAAEC2CBKB9hSJty+7vWkDUwpVZ9156XJ7rabJisR0Xk/uZyTGCBIBAAAAAECWCBKB9rR1uXVbOjDtjMQCszbt8mrlZ/3WLbc2J0PDRGszU5sBAAAAAEC2CBKB9rJ5ibTmM+t+z93TzkgMRNODxFwqEptubW5u2ErWbw8AAAAAAHZyBIlAe1j3pfS370tVq63HFbsr1Kgi0Z8IEsuG2GshpV7THI87+9Zme9gKSSIAAAAAAMgSQSLQHpa/m/q4qI9CpjtlyROutu7k97DXehlbs/6InKY2x5dobQYAAAAAANkiSATaQ6Ak9bFhpFUbGsEq604sbK89Ez0o49t5XOnVh7kEie54RaJpSiZhIgAAAAAAyAJBItAeIsHk/YlXS5JCjc5IVKjGuo1GJEkP9P6NvokNyvh2mULD7TkjUeKcRAAAAAAAkB2CRKA9JILEoYdIB10hSQrFTJ0U/L0ezJtmPReNVyJGQ5KkGn9vhdQobIzLdB6it8kzEuPrjiDRMJLXRkkSAQAAAABAFggSgfYQjQeJRX3tAwrDkZg+Nkfo88C4+DVWgJhobXZ5vArKl/HtMlUfujO0O0tyVCRGM14bo7UZAAAAAABkgSARaA+JikSPP7mUqAR0x8PCRJAYb202PD4Fm5janKki0VllmPpEIkhMBoZuKhIBAAAAAECOCBKB9pAIEt3JIDEcjbcae+JhYTxATASKbo9Pa8zkBGenJgerZGLEp0NnmNosUZEIAAAAAACyk/kANgCtK9Jg3Xr8+nDpZt3/3jLtsYs1ydloXJEYb2023F4FZarBXahAtCbl7VZtrc/+szMMW3E5KhJjscYvAAAAAAAASEeQCLSHREjo8evUez+UJL369XpJjYJE07QrE91ev6QGLSv4nkZWvZfydj2L/NpYHdQ+g8r0vQGl2rVXYdOfnWlqs7O1mYpEAAAAAACQBYJEoD1kaG1OMBKtzTKlWNQOHT1en6QG/bfXBdq96gO5FA8Cy4fqL5PH6N3Fm3T54bupwN/Cn3GmikQXZyQCAAAAAIDcECQCbWnbd1KoLuOwlQTD45jMHAvbrc3ueMC4yjtQfxj1Hz3/6Xe6c+R8HXjcBZpY0ksTR/TKbg8ZgkTJmtwcjZmckQgAAAAAALJCkAi0lVhMum1P6/7QidZthiDR5XYEieF6O/CzWpulUCSmSm+BtqpYXw0+SweW9MttH4k25sZBomEoKpOKRAAAAAAAkJUOndp89913a8yYMSouLlZxcbEOOOAAvfzyyx25JaD1bF2WvL9lqXWbIUh0exoFiXFWa7MUjMQUiVphnyeXac0JzVQkSrQ2AwAAAACA7HRokNi/f3/ddNNN+uSTT/Txxx/r0EMP1bHHHquvv/66I7cFtI6185L36zZLkqKGL+0yj8ctueLFweE6x7p1bSgaUyQ+WtnrNtJe3yI7SEwNDD0EiQAAAAAAIAcd2tp8zDHHpDz+4x//qLvvvlsffvihRo8e3UG7AlrJui+T90M1kqR6M/1Pzut2SW6fFItIoVp73eNLtDZHFfZYYaDH1YoVifFQMkKQCAAAAAAAstBpzkiMRqN66qmnVFtbqwMOOCDjNcFgUMFg0H5cVVXVXtsDcucMEuNqo+60Na/bJbnik5sdFYler7X24dItjmt3pCIxNUikIhEAAAAAAOSiQ1ubJenLL79UYWGh/H6/LrjgAj333HMaNWpUxmtvvPFGlZSU2P8GDBjQzrsFcrBpYdpSTYYg0ec2JHc8SAzFg0SXVz5vE6FjrpoIEl1GoiIx1vgVAAAAAAAAaTo8SNx99931+eefa86cObrwwgt15plnav78+Rmvveqqq1RZWWn/W7lyZTvvFshB/da0pepIejjoSbQ2S1I43trs9smfITT0tEFFIjkiAAAAAADIRoe3Nvt8Pg0fPlySNHbsWM2dO1e33367/vGPf6Rd6/f75fenT70FOp1YVAqmt95Xh9PDQeuMxPifYqIi0e2Rz5MhSGyTMxJJEgEAAAAAQMs6vCKxsVgslnIOItAlNVRmXK7MUJHodRvJisT4UBa5vBmDRJ9nByoSY9GU5UQoyRmJAAAAAAAgGx1akXjVVVfpqKOO0sCBA1VdXa1HH31Ub731ll599dWO3Baw4xq2ZVyuCrkkpQZ6Po+ztbneunX7WrEiMR4+Nq5IdDG1GQAAAAAAZK9Dg8QNGzZo2rRpWrt2rUpKSjRmzBi9+uqrOvzwwztyW8COq9+WcXnh5nDamsflSg5bCSdbmzMNVtmxMxJTA0O3wdRmAAAAAACQvQ4NEu+7776O/Hig7TRRkfjKgi2SynX83v303GerJcVbm12Jqc2O1uYMQeJ2TW12xdupqUgEAAAAAAA7oNOdkQh0C4mKxLzylOUG06uDdq3QQbtW2Gsprc32sBWf/Blam7crSGxqarM7MbWZIBEAAAAAALSMIBFoC4mKxPIhKcshedWzyK/SfK+9Zk1tTm9tznxG4o60NlORCAAAAAAAth9BItAWEhWJFbulLIfkkcdlqCQvGSR6XI6pzQtfsW5d3ozVh61akehKnJEYa/wKAAAAAACANASJQFtIVCTmlUkFvezliNzyuF0qyfPZa16PoyKxfqt16/Yp3+fW3gNLU952x4atUJEIAAAAAAC2H0Ei0BYSFYmBUqlskOMJQx6XkdLa7DaMZJBoL3plGIaeuWC89h1cZi9nGsDSohaCRKY2AwAAAACAbBAkAm2hodK6zSuVSgemPOVu1NrcEI4mW5sTXNZAdZfLUMDrtpe3ryIx/pq0INH68ydIBAAAAAAA2SBIBNpCorU5UCqVDkp5yut2pZx1WBuKpAeJjsd+jyNIdLX+GYm0NgMAAAAAgGwQJAJtIdxg3XoD0ujjJUm1HqtF2d1o8vKoviV2BaLN0ers8ySv9+7QGYmpgSGtzQAAAAAAIBeeli8BkLNYxLp1eaW+Y6Tz39Gd71VKH1fJGw/w3v31RK2vatDufYoytDYnqxBdRjI89LTB1GYqEgEAAAAAQDYIEoG2EAtbt4nKwr5jVOn+UlKVfTZh/7J89S/Lj1/XKEhMVDQqGfhJO1qRmBokuhIVidFY41cAAAAAAACkobUZaAvRREViMquPxAO7jANTGk9tDlYnn3Kci+htgzMSoxQkAgAAAACALBAkAm2hcUWiki3EHlduQaLzelem17bEDhKjqR9pn5FIRSIAAAAAAGgZQSLQFqLxINHlCBLjpX8Zzzls3NocrLLvbld46MQZiQAAAAAAoBUQJAJtITFsxZ1sbY42V5HYaKJyamvzDu6liSAx0TIdpbcZAAAAAABkgSARaAsZKhLDzZ2RGKlPfZzS2ryDf6Z2kJgaGFKRCAAAAAAAckGQCLSFDGckNluR6JjSLEkaPsm+626j1ubkGYkEiQAAAAAAoGWeli8BkDN7arOjItEOEjPk9+G65P1J10jfn2Y/bPMgsXFbNQAAAAAAQAYEiUBbSFQkutz2UmI6cubWZkdF4kGXpzzVVkGih4pEAAAAAACQg+0KErdt26aPPvpIGzZsUCyWGk5MmzatiVcBO5FoemtzONpMRWKjkM/JbbRtRWKEYSsAAAAAACALOQeJL774on784x+rpqZGxcXFMhwhh2EYBInY+YQbpPsOkwbsL035qzXUJF6RaLo8SvyFJCr/MlYYTvyNtGy2tN8FaU+dtt9A3TlrsY7ao8/27c8V/zOPhlKWkxWJTYeYAAAAAAAACTkPW/nlL3+pc845RzU1Ndq2bZu2bt1q/9uyZUtb7BHo3Bb8R1r3pTR3hvU4FrWfmvL3D1XVYIWKkfjUZm+m1ubyodIvv01ra5akfqV5+ub6I3XXj7+/ffvzF1m3jknQkuRiajMAAAAAAMhBzkHi6tWrdckllyg/P78t9gN0PbFIo8dh++5328J66uNVkpKBXZNnHjbTwpznc6dU/+YkUGzdNgoSExWJMYatAAAAAACALOQcJB5xxBH6+OOP22IvQPfgCBbD8siMB3WJ1mavO+c/ux3TREWiO35WI2ckAgAAAACAbOR8RuKUKVP0q1/9SvPnz9eee+4pr9eb8vzUqVNbbXNA1+CoFDTN5KAVSRElpzaH463NOzyFOVeJIDHSIEVCkscnianNAAAAAAAgNzkHieeee64k6frrr097zjAMRaPRtHVgpxGLplQkRh1Fv8mKxPYOEouT94PVkqeHJMfUZoJEAAAAAACQhZx7LGOxWJP/CBGxU3KeXRgN2hWJIdMtZ7ViOJo4I7GdW5tdbslbYN0PVtnLbioSAQAAAABADto50QC6uWjIHrYSaVTwmwjsPO3d2iw5zklMDxIjsVj77wcAAAAAAHQ5WbU233HHHTrvvPMUCAR0xx13NHvtJZdc0iobA7oM0xHERUJS1Gptdp6PKCUDO097tzZL1uTmmnUpA1eSZyS2/3YAAAAAAEDXk1WQeOutt+rHP/6xAoGAbr311iavMwyDIBE7n2jIcT9oVySG04LEzlCRmAwSk63NJIkAAAAAAKBlWQWJy5Yty3gfgBoFiWH7jMRERWIiQIxEE0FiB5wokAgSG5KtzYnKSIatAAAAAACAbOxQomGapkyTEAI7uXhwKEmKOCsSrZw+FLEq/hKtze4OqUiMT25OOSPR+vNn2AoAAAAAAMjGdgWJ//73v7XnnnsqLy9PeXl5GjNmjB566KHW3hvQNaRUJCbPSIya1p+XHSTGKxK97o6oSEwEiY7WZoOKRAAAAAAAkL2sWpudbrnlFv3ud7/TxRdfrAMPPFCS9O677+qCCy7Qpk2b9Itf/KLVNwl0ao2DxFhqa3MoGpNpmnZg1zEViU1PbY4RJAIAAAAAgCzkHCT+7W9/0913361p06bZa1OnTtXo0aN17bXXEiRi55PW2mxVJDpbm53tw96OmNqcYdhKYugLFYkAAAAAACAbOQeJa9eu1fjx49PWx48fr7Vr17bKpoAupXFFohlvZY5XJAYjsZSwrkMqEgMZWpvdianNBIkAAAAAAKBlOR/WNnz4cD355JNp60888YR23XXXVtkU0KVEGp+RmNraHIxEU4LEDjkjMa/Muq3dZC9RkQgAAAAAAHKRc0Xiddddpx/96EeaPXu2fUbie++9pzfeeCNjwAh0e40rEmUFdOHEGYmRmKLRDq5ILOpj3dasT+7DSFQkxtp/PwAAAAAAoMvJuTTqxBNP1Jw5c1RRUaHnn39ezz//vCoqKvTRRx/p+OOPb4s9Ap2bM0iMOIatmMkzEsOOsM7TIUFiX+u2Onn8QCLQpLUZAAAAAABkI+eKREkaO3asHn744dbeC9A1OYetRENSPEAMO6Y2Rx0Tmw2jA4PEus3WQBiPXx7OSAQAAAAAADnIuSLxv//9r1599dW09VdffVUvv/xyq2wK6FJSWpuDyYpER2tzOGpVJHZINaJknZHo9ln34+3Nbpf1588ZiQAAAAAAIBs5B4nTp09XNBpNWzdNU9OnT2+VTQFdSuPW5mh6kJio+uuwINEwkuckVq9L2QsViQAAAAAAIBs5B4mLFi3SqFGj0tZHjBihxYsXt8qmgC6lcWtzLCIptbU5HB+24umIic0Jjc5JdDO1GQAAAAAA5CDnVKOkpERLly5NW1+8eLEKCgpaZVNAlxINpt63KxKtsxKD4U5QkSglKxKrUoNEKhIBAAAAAEA2cg4Sjz32WF122WVasmSJvbZ48WL98pe/1NSpU1t1c0CXkFKRGE4/IzHqOCPR3ZFBYrwi8fVrpG0rCRIBAAAAAEBOcg4S//KXv6igoEAjRozQkCFDNGTIEI0cOVI9evTQX//617bYI9C5pZyRmKxIDJuZzkjswNbmUcdat5EGaf4LnJEIAAAAAABy4sn1BSUlJXr//fc1c+ZMzZs3T3l5eRozZowOPvjgttgf0PmlTG1OnpEYjVckBiMxRWKdoCJx0Hjpe6dL8x6VQjWOMxJjHbcnAAAAAADQZeQcJP773//Wj370I02ePFmTJ0+210OhkB5//HFNmzatVTcIdHqNh60kKhLtqc1RReLDVtwdeUaiJOWXW7ehGrs6MrE3AAAAAACA5uTcZ3n22WersrIybb26ulpnn312q2wK6FIatzZnOCMxMRnZ25GtzZLkK7RuQ3UqzvPI6zYUiZn6ePmWjt0XAAAAAADo9HJONUzTlGGkV1WtWrVKJSUlrbIpoFPatFgK1qSvp7Q2h6Wo1dpsT22OJIetdHhFoi8+WT1Uq3yfRyd+v78k6Z63lzTzIgAAAAAAgBxam/fee28ZhiHDMDRp0iR5PMmXRqNRLVu2TEceeWSbbBLocGu/kP5xkDRgP+knr6U+F3EGicmKxERrs2laYaIkeTvyjERJ8uVbtyErED19v4F6fO5KfbJiawduCgAAAAAAdAVZB4nHHXecJOnzzz/XEUccocLCQvs5n8+nwYMH68QTT2z1DQKdwrzHrNuVc6xkMF6VW1kfVlEkmCztjSSHrUTiU5slqS5krXV8RWL87zZcJ0nqX2YFi1vrwgpFYvJ5Orj1GgAAAAAAdFpZB4nXXHONJGnw4MH60Y9+pEAg0GabAjq12o1SYS9J0kl3v69n6upVnMgHMwxbkaRN1VbVYmHA265bTeNobZaksnyvvG5D4aipjTVB9SvN68DNAQAAAACAzizn8qMzzzyTEBGdysz56/Xwhytkmm04fbhyZfL+poWSpFAkpkUbauRVJPlcNJisSHQEiSu2WMFdryJ/2+0xG95Ea7O1H8Mw1KvI+nteX9XQUbsCAAAAAABdQFYVieXl5Vq4cKEqKipUVlaWcdhKwpYtTH9F+9lcE9TPHvlE4aipNdvqdeWRI9rmg7YsS97ftFAa/ANtqbWqDFODxLB9/mCdkoH7nKXW30XPjg4S7anNtfZSzyK/Vm+r14aqYAdtCgAAAAAAdAVZBYm33nqrioqKJEm33XZbW+4HyMlzn61WOGpVIt47e6l+cfhu8rpb+Zw/05S2LE0+3rTYuqkJyqWYPEYs+Vy4TmqolCRVmfnqWeTXxuqgFm2wwsUOr0hs1NosJfe0sZqKRAAAAAAA0LSsgsQzzzwz432gXX36kLR1mbTHSVLvUZKkF+etsZ+OxExtrQvZrbqtpnqdPZxEkrRliXVTG0qtRpRUteE7uUr7qVBStfK1z6AyvfzVOvv5jq9ITG1tlqTexYnWZioSAQAAAABA03aodMs0Tb355pt66aWXtHXr1tbaE5Bu8xLp/y6W3vlf6fkL7OW1lalVdIl241ZV36hdv3ajtaXaoHyNgsTi6FZVb7LCzWozT2MHlaU83+ohZ67sqc210sq5kpIViRuoSAQAAAAAAM3IOkjctm2bzjzzTO25554699xzVVVVpYMOOkiHHXaYjjnmGI0cOVJffPFFW+4VO7N4eCdJWvuFVL/NWg5aQZ4v3s68paYNgsRwo4CtdpMkaXNNSAFZVXxR01CtaQVyfQ0reKxSgfYZXJ7y0o6vSCxI3r/vMGnDN+pVbO2JikQAAAAAANCcrIPEK664Qh988IFOPfVUffnllzryyCMVjUb1wQcfaM6cORo5cqSuvvrqttwrdmbBGscDU1o1V7GYqdpQVJI0oDxPkrSlrukgsSEc1bX/97XmLN2c22dH4kGiK34SQO0mKVgtz7p5KjSs52oV0GqzIuVl1Wa+du1VqL4lySrEDj8j0ZOX+njdl+oVb23eUE2QCAAAAAAAmpbVGYmS9PLLL+vRRx/VhAkTdNZZZ2nAgAF68803td9++0mS/vznP2vq1KlttlHs5ELVqY+/+1C1Aw6xHw7qUaAlG2ubbW1+7rPVeuD95Xrg/eVa+qcfyuVqevp4iki9dVvSX9q63GoLfmCKzlo7T1tdJ0qyJjSvNiu0m1bbL6s28pXndWvckHK98LnV7lzgz/pPrm24Gv1vB/4ihq0AAAAAAICsZF2RuH79eu22226SpH79+ikQCGjAgAH28wMHDtTGjRubejmwY4KNgsT1X6s2aFUjul2GXfW3OdHa/MWT0m1jpPkvJN8iHLXvf7S80bmHzUm0Nhf0klxe6/7aeZKkMzwzJUm1ZmpFYtQ0ZHoL5HIZ+tkhwyVJBwztkf1ntpdwnT1sZVNNSOForIUXAAAAAACAnVXWQWIsFpPb7bYfu91uGUayost5H2h1idZmt8+6rd+immBYklTo96hHgbVuVyR++m9p2wrpyWnSpkWSpJiZfLsrnpqn02d8qFVbHdOYm5JobfYGpILU9uWQrGCxTn6tcQSJNcpTvt96bvc+RXpv+qG6d9rYrL/cdhOqVXm+T554deamGtqbAQAAAABAZjn1Wf7zn/9UYaE19TUSieiBBx5QRYUVnlRXVzf3UmDHhOJBYulAafNiqX6rauIViYV+j8obB4mGIyNf94VUsavqQskJy6u21mvV1nr9/oWv9a+z9m3+sxNBoicg5VdI1Wvtp9yyKvjqFNAKs7e9XmUWqMCXDN77lTY6m7CzCNXJ5TJUUejXuqoGbagKqm9JJ90rAAAAAADoUFkHiQMHDtSMGTPsx3369NFDDz2Udg3QJhKtzSUD7CAxMbG50O9ReaF1zt/m2nhFXcRRWReyqg7rQsnW5oSN2QwYCcfPSPQEpILU9uQ+xlbrI1z5ivUYLsW3Wa185fs6+DzEbIRrJUm9i60gcX0V5yQCAAAAAIDMsk46li9f3obbAFqQCBJL4+dy1m9Vdb3V2lzgd6e3Nodqk6+NB4GZgsSs5q0kQklvXrK1upHxowbqwONOkf50iSTJp7AK/O6M13a4k+6Xnj7buh8PWXsWBSRVMrkZAAAAAAA0KeszEoEO5WxtlqRYRMHaSknWJORE6/DyTXWqagjblXaSpLAVliUqGJ2ymtycmNrs8UsFPTNe4vYXyuVLtgT3MrZ1/ITmpuxxgvSDX1j3Q8mKREkEiQAAAAAAoEkEiegaEsNWCnpKHiuwi9ZukiQVBTwaXFGgXXsVKhSN6bWv1zeqSIy3NoczVSRmESQmpjZ78qSeu2W+xleY8rDYqFNBZ25t9hZYt/HAtVeRNbl51ZYshs8AAAAAAICdEkEiuoZERaKvUMorkyRF66zzCROB3ZQxfSVJr3y1zm7ZtV5bK8ViqstQkejOJki0h634pbFnS+e+qehZr6Re47OCuRV+K2j8LDZc+b5O2tos2ftNfJ/2HlgqSfrPF2u1YnNtEy8CAAAAAAA7M4JEdA2JMxL9RXaQGKvdIkl2C/HeA6311VvrksGjJH1wp3TPgWoIhtLe1pXNX0AiSPTmSYYh9RurcMEuqdfEg7lHh96keyJH6+fhn3fe1mZJ8uVbt/HKzYN2rdCBw3soFI3pmU9Xd+DGAAAAAABAZ5VVkHj55ZerttYKHGbPnq1IJL2yC2hTiSDRVyjll0uSXA1WRWJRwJNyG2yolWSmvn7DfJXXL097W3c2ZyTarc0Be6nBW5R6Tby12V3STzdFTtcqs2fnrkhs1NpsGIb2HmAFsVXxITYAAAAAAABOWQWJf/vb31RTY1V4TZw4UVu2bGnTTQFpEhWG/iIpr1SS5GrYJilZkVgc8EqSYg01jV8tSaoPx9LWsjoj0R62kgwSg0aeQqYjKIxXJB49JlmpWJ/hTMZOw65ITLaAB7zWfw4aOvO+AQAAAABAh8mq93Lw4MG64447NHnyZJmmqQ8++EBlZWUZrz344INbdYOApOSwFX+hlGdVJHpC2yQ5g0TrNhqslfwZ3iNcJ6lHylIokh4uponEJxl7HUFixFSlCtVT1uToRJA4apdi/eyQYbr77SU6bGTvlt+7o9hnJCbPQwx4rWCUIBEAAAAAAGSSVZB4880364ILLtCNN94owzB0/PHHZ7zOMAxFo4QQaGWxmN2CK1+R3dpcENwoSSr0WwFYUbwiMaBg5vcJp08kzio0CycqEvPspWAkqlqzWD2NRJCYnNp85ZEjdPGhw5XfhaY2S84gMYtwFQAAAAAA7HSyam0+7rjjtG7dOlVVVck0TX377bfaunVr2j9antEmnINT/IVS3+9JknZt+FJScmpzwOuS122oQA0Z38YTyRQkZlOR6JjaHBeMxPRxbPfkNYkKv7hOHSJKTbQ2W0Fip27JBgAAAAAAHSantKOwsFCzZs3SkCFD5PF08qAE3Udi0Irhts4pHHywJEODoivUU9vs1mbDMFQU8CqvPnNFoi+WHjBmFZo5pzYnthSJ6t3YHvofvR5/84IML+zEEvsNc0YiAAAAAADITs5p4IQJExSNRvXMM8/om2++kSSNGjVKxx57rNzuTjylFl2Xc9CKYUgFPaS+Y6S18zTe9ZXyfT+0Ly0OeFRQn7kiMd9IX8+utTl9anMwHNMHsdHJaxxtz12C1xEkxmKSy6U8zkgEAAAAAADNyDlIXLx4saZMmaJVq1Zp992t1s4bb7xRAwYM0EsvvaRhw4a1+iaxkws6gsSEPlaQOMDYmNJGXBTwKj9+RuJms1g9jCr7uQI1yOd2KRRNtjNnV5GYYWpzJKYqFei+/J/oJ6MNqWLX7fjCOlCitVmywkR/IWckAgAAAACAZmV1RqLTJZdcoqFDh2rlypX69NNP9emnn+q7777TkCFDdMkll7TFHrGzC8Vbmx0DTZRXKkkqNuqU70tWwhYFPHbl4SazOOVt8hRUni+1ajaY1RmJmaY2WwHky0UnSVP+16qU7Eo8eZLiew5aYavd2hyhIhEAAAAAAKTLuSLx7bff1ocffqjy8nJ7rUePHrrpppt04IEHturmAEmOisRkkBjzFcslqUh19hmJklTcqCLRqcBoUL7Prcr6sL0WisYUjZlyu5oJAjNObbYCSL835yy+c3C5pB7DpM2LpXVfSrWblKeekqT6EEEiAAAAAABIl3OQ6Pf7VV1dnbZeU1Mjn8/XKpsCUiSGrTham8PeQvklFTWqSAx4XcqPT23erNQgMV9BFfrTf+UbwtGUMDJNpqnN8UpGv6cLnws6YD8rSHz0FEnSwOHHSDqNMxIBAAAAAEBGOZdTHX300TrvvPM0Z84cmaYp0zT14Ycf6oILLtDUqVPbYo/Y2SWGrTham4MeK1QsMerk9yR/jasaIso3Mlck5iuowoBHjYsPmz0n0TSbnNosKeWzu5wB41IeBtZ9IklqiHBGIgAAAAAASJdzCnLHHXdo2LBhOuCAAxQIBBQIBHTggQdq+PDhuv3229tij9jZZahIrHdZU4dLjHoZjvMJt9aFVKxaSdI2Oc5UlNXaXBTw6pkLx+uAoT3s9WYr8KJhyYwHa42GrUhdPUjcL+WhK2a1fIciVrs3AAAAAACAU86tzaWlpXrhhRe0ePFiffPNN5KkkSNHavjw4a2+OUBSxorEOpd1v9ioS7l0995FKlkbDxLN1CAxT0EV+T3ae2CZHjtvf33vutdUWR9uPkjc8HXysx1BZjJI7MKtzT1HSAdfaQ1bmXOPjPotMhSTKZeCkWjKNGwAAAAAAIDtTgqGDx9OeIj2kWHYSp2RLyk9SLzyyBHaujwqVUuVZkHKc1ZFYvJXPs/rjgeJzbTyLn7duh16iORKhobBePjYZYetSNak6UOvtqZSz7lHhhlVsepUqUI1hGPK58hTAAAAAADg0KEpyI033qh9991XRUVF6tWrl4477jh9++23HbkldEYZWpurZYWE5eY26c0/SjErDCwv8GlYUUSSVKkCvTb011JemSQpXw0pw1YC8RCw2TMSF79h3Q6flLql7tDanODxS37rPMk+Hiu0bfZ7AgAAAAAAdkodmoK8/fbbuuiii/Thhx9q5syZCofDmjx5smpraztyW+hsQvEg0dHaXG3mJ5+f/Rfpy6eSj+u3SbIqEt8vPVbrj/qnJGvYSlHAa18W8FoVhvWhZkKz9fOt24EHpCx3i9Zmp3zrzMhEkMjkZgAAAAAA0FiHHoL2yiuvpDx+4IEH1KtXL33yySc6+OCDO2hX6HTs1uZkRWKlGUi9ZsP85P2GbdY1KlB1Q0Q/eewb/ccv5RsNKnS0Nvcs8mvBumot21Srg3frmfmzw/FQ25+cAB2LmVq5xWqp7hYViZIVJG5dpt5ugkQAAAAAAJBZp0pBKisrJUnl5eUZnw8Gg6qqqkr5h51AhmEr9eFGU4W3LLFuYzGpwfo9qjQLtKG6QfXyS5IKlHpG4v7xyc3vLd6U+XOjYSlmtUnLm2cv/+u9ZXpjwQZJXfyMRKeCCklST4JEAAAAAADQhO1KQd555x2dccYZOuCAA7R69WpJ0kMPPaR33313uzcSi8V02WWX6cADD9Qee+yR8Zobb7xRJSUl9r8BAwZs9+ehC7HPSEwGibWN25HXzLNuQ9WSabUdV6lAK7fUqSreBl2oehV7k4NVxg+zgsQPl25WNNYomJSkcH3yvjfZSn3DS9/Y97tPa7MVJFYY1ve62QE0AAAAAABgp5RzkPjMM8/oiCOOUF5enj777DMFg0FJVjXhn/70p+3eyEUXXaSvvvpKjz/+eJPXXHXVVaqsrLT/rVy5crs/D11IhtbmumAk9ZrK76S6LdLc+yRJUZdfQfm0cmu9NqpUVWae3IapnsHk78ye/UpU4HOrqiGipRtr0j/XDhINayBJ3F4DSpMfWx/eoS+t0yiwQtUehlXl2+y5kQAAAAAAYKeUc5B4ww036J577tGMGTPk9SYHVxx44IH69NNPt2sTF198sf7zn/9o1qxZ6t+/f5PX+f1+FRcXp/zDTsAetuIIEjMFXZ8+KL1xnSQp4i+RpHiloaEF5kBJUkXtIvtyj9ul3sXWWYtbakPp7xe2zkGUN18yDHu5R4HPvj+0Z0HOX06nFK9ILJMVJL69cKPmLN3ckTsCAAAAAACdTM5B4rfffptxEEpJSYm2bduW03uZpqmLL75Yzz33nN58800NGTIk1+2guzNNR0Viamvzz0MX67vSccmzE1e8bz9vuFJbjhfErCCxuGphynpRnhWGVzU0qnCUkhWJjvMRpeTE5oN2rdAP9+ib29fTWQWs4DUvZg2XeejDFTptxodavCFDpSYAAAAAANgp5Rwk9unTR4sXL05bf/fddzV06NCc3uuiiy7Sww8/rEcffVRFRUVat26d1q1bp/r6+pZfjJ1DpEEy49WHjmErtcGIXoyN12tj/yGVx3/vYskw0Fe7NuVtEhWJ+VsXpKwXx4evVGVqUbaDxPyU5cQgkh/vN1Aul9H4VV1TvG28yNVgL8VM6dMVWztqRwAAAAAAoJPJOUg899xzdemll2rOnDkyDENr1qzRI488oiuuuEIXXnhhTu919913q7KyUocccoj69u1r/3viiSdy3Ra6q8SgFSklSKyJn5FYHPBKeaXW4rbvmnybRbF+kiTvtqUp6yXxisSMZx3arc2ZKxK7zaAVSQpYxwT0ywtr4u49dUB8ovVXayo7clcAAAAAAKAT8eT6gunTpysWi2nSpEmqq6vTwQcfLL/fryuuuEI///nPc3ov08wwKRdt4r9frtWyTbX62SHDZBhdqIouEST6CiVXMveubrCCv6KAx27LdQaJ9ROvl15Ovs1WWSGkEaxKeftiu7W5uYrExkGiVZHo92zX0PPOyW8FiYVmne4/e5xe+Hy1Pli6WV+tJkgEAAAAAACWnINEwzB09dVX61e/+pUWL16smpoajRo1SoWFhS2/GB0iFjP1s0esQTi79irU5NF9OnhHOQjFz+jzpf5+VcfPNCx0BonR+MCUib+V5wc/l15OJonl5T2kWskIVlvnLsbD1OJAPEisz3RGomPYikNDOF6R6O1GFYnxIDER3O7Rz/qezl9bpUg0Jo+7G4WmAAAAAABgu+ScDlRWVmrLli3y+XwaNWqUxo0bp8LCQm3ZskVVVVUtvwHa3cqtdfb98x76RH+flX7GZadTv826zTBoRUoGiUUBrxQoTX1tQYW8bpd8jorBcw79nnUnFpYiQXu9OC9+RuJOX5EYn4gdrJJMU0N6FMjrNtQQjmldVUPzrwUAAAAAADuFnJOQU089VY8//nja+pNPPqlTTz21VTaF1rVgXXXK45tf/baDdpKlL56S/jxI+uDvzVQkWsFfod9RkZgQf1zoTxbcFpeUSIq3dDvam5MViY4gsaFS+upZqW6z9biJMxID3m4UJMbPSFQsIkUa5HIZ6lnolyRtrA4280IAAAAAALCzyDkJmTNnjiZOnJi2fsghh2jOnDmtsim0rgVrq9PWElV1TpFoTD99cK5unbmwPbbVtGd/at2++pvkGYmJijlZZ2smh600HSTWNCTblQf2KHRU3SW/HxmHrTx7nvT02dJrV1uPG7U2B8PdcNiKt0B20NpgBa09iwOSCBIBAAAAAIAl5yAxGAwqEkk/Ty4cDqu+vr5VNoXW9e16Kxg6+8DB9lqmKcVvL9yo17/ZoNvfWNReW2tZhiCxLhRVLD6nx2ptbhwklkqSQtGYvdS/LD+1fTcuOWzF8Tu98JXU93NUJJqmqYZEa3N3qkh0udLOSUxUJG4gSAQAAAAAANqOIHHcuHG6995709bvuecejR07tlU2hR007wlp7Tz74aL1VnvwhN16WhV8atTKG5cYIiJ1oonajtbmxJ4S5yO6XYbVXtxEReLYQWWSpKuOGmGtNwrKJDX7/bA5KhLDUVOJb023qkiUHEGrNam5VzGtzQAAAAAAICnnqc033HCDDjvsMM2bN0+TJk2SJL3xxhuaO3euXnvttVbfIHK0ZJb03HnW/WsrFYuZWrHFGrYytKJQJfleVTVEVJlhSnF8kLEk6xzAQGeYShwfthLxFOiIW97W9weW6fwJQyVJRQGPDMNoMki8/dS99PWaKk0e1dtaTwRlDZkqEpsLEpMVic6W8G51RqJknZNYJSoSAQAAAABARjknIQceeKA++OADDRgwQE8++aRefPFFDR8+XF988YUOOuigttgjcrFhfvJ+zUatqaxXKBKT121ol9KAfSZgsxV4kmqD6UFjh4hXJC6tlpZsrNVTn6yy25DtYSppQaJVedi/LF9HjO5jhY1SxjMSE8NWaoIRxRL90m5/6vs5KhKdVZs+dzcLEhsFrVQkAgAAAAAAp5wrEiVpr7320iOPPNLae0FrqN2UvL/mU61wWe3mA8ry5XG77CCxrmqz9MHT0ujjpeK+kqSGcLLari4UVY/223UTDPs8wzqjwF5NtDYXxUPAtCDR0ygITMgUJOZZfwKmKVUHI9b3x18k1TnCswwViX6PKxlQdheNvj/Jqc0NHbUjAAAAAADQiWQVJFZVVam4uNi+35zEdeggW5Ym7694T8uKrPMBB1dYQVwiSBz16TXSuldV8+H9yrv0I7ldhmpDySCxpqMqEp1nM3rz7NbmeiXDvC21VshXFD/fUEW7SKWDpG0rpOL+Tb93IHFGYvJ32Od2ye0yFI2ZaghHHUGiI5BNCRKtisRO0fbd2vyp359e8anNtDYDAAAAAAApyyCxrKxMa9euVa9evVRaWpqxEss0TRmGoWg0muEd0G6cQeJ7tyswrI+kQRrcIzVIHLj+TUlSYeVC/f7Fr3X9sXuozhEedlhrc0Nl8r4nYLc21ypgL6+rjAeJidZml0u68D3p3dukXfZu+r396UGiYRgKeFyqDUVVnwhS/YWpr3O0Ngfjrc1+Tzdra5bSKhIrCn2SpM01oY7aEQAAAAAA6ESyChLffPNNlZeXS5JmzZrVphvCDjBNacuylKUB616TdK4GV1hhWGK4SEyGEjV1//5ghc4cP1h1jopEZ3Viu6rf4nhg2hWJW6PJduX1VVarrV2RKFkh2KTfNf/eGVqbJSnP51ZtKKqGSBNfszcZYiau8Xe3QStSsmIzHuYmfldC0ZgawtHuWYUJAAAAAACyllWQOGHCBElSJBLR22+/rXPOOUf9+zfTQoqOUbdZClVLMrR43PUa/tHv1FC1WZI0qq8VEpU4gkSn+99bpk9WbLMfd1hFYt3W5P1wvdSwTZK0KeSzlz9baa3ZZyRmq4kg0e+xAjK7IjHSqAIvY0ViNwzV7IpN6/tT6PPIMKx8uqohTJAIAAAAAMBOLqeyKo/Ho5tvvlmRSCeZ6ItUibbm4n567BsrDCsxauUypFG7NAoSY2bKSx/+8Dt9szbZ8tthQaKzIjHSYE2hNlxaEOlrL8+LB4mTR/fO7b2bqUiUHBOZo43OBKzYVZFoTLe89q3eXrhRkhTojhWJjYJEl8uwJ2MnBtwAAAAAAICdV85Tmw899FC9/fbbGjx4cBtsBzskESSWD5HqSqVqqVi1CnjdyvdZP+qmKhIb65AgMRKU3vxD+vroE/TtqlJJyQBw0oheOmjXnrm9fyJIbEgdGJQIBe2p1c6KxD1OksqH6tmPV+qONxcn36pbViQmgtbk96c44FV1Q4QgEQAAAAAA5B4kHnXUUZo+fbq+/PJLjR07VgUFBSnPT506tdU2hxzEYilB4vpt1qThUqNGZXk+adlsactSlRZNkSSZLQWJHXFG4so50tp56XsZPkULPk6tIhxQnp92XYt88SEq4dqU5TxvoiIx/jUnKhJ/cLk08WpJ0ppt9Smv6ZbDVgKpFYlS8hzK6oZwR+wIAAAAAAB0IjkHiT/72c8kSbfcckvac0xt7iCvXyt98oDUY1frcflQLZ5n/WiLVaf/PXmM9PjeUrBKYw/ZJsPYtcW37JCKxESA1XsPafNiq7VZ0tWvrZc0MOXSsnyfcuaLh96h1CAxcfZffeOKxL3PkNzW9zHf5874mm4lQ8Vmcfwcyqp6KhIBAAAAANjZ5VxWFYvFmvxHiNhB3r1Vqt8qrfpIkhQsHqxltVbQ5jFi2r9Hnd2umjf7D+qdbzRqbTYbv2PHBInheNVffrnkzbOXv9ianneXFeQ4aEVyBIl1KcsBbxNnJLqTYWWeL3UP3bIi0U9FIgAAAAAAaFpOFYnLly/XzJkzFQ6HNWHCBI0ePbqt9oUdsN6zi4LapKDpld8IS2s+Tz4Zi+iUPQLSl8kg0a+wgkqt8KsJtkEoXLNR8gaSlW+NheMBnzdfMpIVf5tNK+AqDnhUFT+rb/sqEuOtzc1VJJqmFI1XJHoC9jWNG8G7d5CYrEhMBolUJAIAAAAAsLPLOkicNWuWjj76aNXXW1VjHo9H//rXv3TGGWe02eaQhUahmLz5WqG+kjapxlUkv7kl7dzBi/YplL4xpHhWWKCGtCCxLtTKwVH9Numvw6XC3tIVCzNfk6hI9OYl70uqknUe4pF79NGTH6+SJJUXbEeQ6I2fqxiqsQJDw4oH85zDVqKOQSue5GfY5yfGdevW5mC1deamTP103fUa6clTdcM1Hbo1AAAAAADQ8bIuq/rd736nww8/XKtXr9bmzZt17rnn6sorr2zLvSEb1etSH489W+vrrR9rvTseDK39POUS/wOHyx9NBpD5RkPa29a0dmvzui/jb7w+pXU2hV2RWJAyEMWM/5qWOcLD0vwdaG02o9aE6LiAc9iKY11uv303GImlvFVx3nZ8fmeXGLYi0wpbV7ynPba9qfM9L6m2rr7ZlwIAAAAAgO4v6yDxq6++0p/+9Cf17dtXZWVluvnmm7VhwwZt3ry5LfeHljiDxD1Plg692j7PLuiJB4nO1uYMCpUeJG6sDurhD1doa20owyu2Q9hxLuHTP5G+myNJev6z1brokU9VH4oq0lBjPe84HzEh4HWpwHFO4XZVJPocE8Yd+0mZ2uysSHSckRhsVJE4rGfqtPJuwROQXPHvcbBa2rzEfsqoWdNBmwIAAAAAAJ1F1kFiVVWVKioq7Mf5+fnKy8tTZWVlm2wMWapea90O+oF04j8lX4F9nl3QW2I9V7ep2bcodgfT1hasq9Zvn/9Kp977oSLRWIZX5bpPR+C56FXpX5OldV/qsic+10tfrtXI37+i+9/6xno+Q5CY53XLdMyE2a4zEl1uyRN/71CNveyPB4mvzV+vNZu2xa/1Sq7kn0fjisRhPQtz//zOzjBSz0lMVJFKCtSu7qBNAQAAAACAziKnYSuvvvqqSkpK7MexWExvvPGGvvrqK3tt6tSprbc7tCwR0BX1SS7FKxIjvuLUa3vvKa3/Uo39/aTdNCu8p6585ou0575dX60XPl+jE8f237F91mxIX/vwbklT7IcBWYFm1JOnxicQ5nndCjmmgm/3GYW+fClSnzxbcvUn2mPrHEmDtGJznU67Z7be9kvy+FNe1jhIHN6rGwaJknVOYv0Waelb0sf32csF9VQkAgAAAACws8spSDzzzDPT1s4//3z7vmEYikbbYNovmpaoSEwJEuMVifl9pETnueGShk7IGCT29IV1yl4DNH9tlVyGodmLNmrxhmTF3orNtWmvyVnNurSl2JZlKY/zDKutuDrqVWmjawNet0KRVqiM9BVIdZutINE0pRmHarKk3Y2b9K05UF5ZIayzrVlKH7ZSuj0VkV1B4pzEV6anLBc3rO2AzQAAAAAAgM4k69bmWCzW4j9CxA5Qs966zRAkbu65X/K6niOl0oGZ3yNenXft1NH6/TGjdPio3ilPVzW0wuCVxD4dzK3fpTxOVCRWRjxW8CmppmQ36zmvu3XaiX3x9wjVppwB2N/YKEnyK/61tlCR2G35izMul4XTf34AAAAAAGDnklNFIjqh+q3WbV6ZvVQVb22u6zMueZ3HL+X3yPwewRpp02KrpXXAOF06aVcFPG6t3Fqnpz9ZZQeTOyRDa7OrZq3ciioab2TOk1WRuCXk1qCfzJTeuUWfDrlUen6T8nxunTS2vzbXhnTAsCa+jmwkBq7UbZYqV9nLZYZVgenLoiLx/rP23f7P7+ycQaLbp3WH3Kw+b1yqiihBIgAAAAAAO7usKxLRSQWrJUmbwn5d9+LXuuutxaoJWsFfQUGB1Hcv67q9z5DySjO/x+ZF0p1jpfsOl2o2KOB169LDdtVeA6zrE8HkDnEOWxl3nuT2yTCj6mtssZdLvdbnbAp6pP77SKc9qq0B62zGgNclj9uliyYO1/cHlmm7JYLEp8+WXrvaXu6lbZIkvxEPYWOelCEziYrEv5w4RhNH9Nr+z+/sihzVqMW7yNtjqCSpr7lBpnPaDQAAAAAA2OlQkdjVNVRJkv781lo9tSVfkhW6SVJRwCOd8Yy0/F1p5FRp2duZ3+Oje5P3K1dJhVZQVpznlZQc3rLdTDNZkXjJ51L5EGnxG9KWJeqnTVpt9NSfjt9TfWebUo20scGwX1ofsioB87Z3uEpj3oLk/UQ1p6SexjZJyYrE5dsi+vij7zTtgMGSpGDE2off282z94rdk/eL+ymvzzBJ0i7apLr6ehXk53fQxgAAAAAAQEfr5qnITiBoBYkLtibDt4awVT1X5PdKBRXS6OMkl0saeIDUc0TytZ5Ak+8nxYNIacdbm6vWWJOSDbdUvIu1VjpAknU24fF79dNp4wbarc3r6pK/lvXxluLtntLcmK8g43IvwwoVffEzEkPyaMY7S+3nE99Tv6eV9tFZ9dwteb94F+WV9lWt6ZfbMFW3YVnTrwMAAAAAAN0eQWJXF69IrFZe2lOJINDmDUg/+1D63Wbp+Huln39qVSqmvF+lfbe4tYLEdfFJ0T1HJIeYlFhBYj9jk3oUWucR+uPDVtbUpYeirRYkejOEp5J6NapIDMqrEX2S5wXulBWJhb1luFxaZViDfEIbFnXQpgAAAAAAQGfQzVOR7umNL1dq4aqNUiwmhawzEmvM9JbTtCBRkgxDcnuk7/1IKuknHft36SevS7tOtp53BIlFAau1eYfPSEwEiX32cGyurySrpbii0AoXvbEG63JHkJioSGy11ua6LRmXE2ck2hWJpidlUrMdaHb3isSS/sn7EevnsdZtVZGaGxZIqz6WYkxnBwAAAABgZ5TVGYllZWUyDKPlCyVt2ZI5qEHreH/eN9r32UPlV1g69Nf2erXytGuvQi3aUGOvJYLAZgWKpQH7SoFS63FKRWLijMSITNPM+ncgzbovrNs+e9pL4bwKeSVVGJVyV1jtxu5EcFXnsj8vMS05z9dKAV7V6ozLVkWiKV982EpIXm2tDdnP7zQVic6fcb+xkqSN3n5SVOr/8Y3SxzdKR94k7X9hB20QAAAAAAB0lKyCxNtuu82+v3nzZt1www064ogjdMABB0iSPvjgA7366qv63e9+1yab3KmZpmTGJJcVpC2a+5rGG3XWU+/fLkNSWB4F5dNxe/fTza9+a7/U58kh9AqUWLcpFYnWr0c0Zqo+HFW+bztn8yQqEnsnKxI/2ujVgZL6eao0Mj4F2YhYX1dNzKfK+rBK8312kBjI5WtpTs8R0prP0pbzjJAKVZ9yRuIWZ5Bon5HYzYNESbrwA2nFe9KYH0mStvj7Sw2O52ffTJAIAAAAAMBOKKtk6Mwzz7Tvn3jiibr++ut18cUX22uXXHKJ7rzzTr3++uv6xS9+0fq73Fm9eYP0wV3S+Iulib+RJLk3fmM/bQSttubKeFvzyfv0160zFyoSM3P/rAxBYr7PLbfLUDRmqrohsn1BYrhe2rrcut97tL382RYrSBzor5XX7ZKiYRkxK8Srl0+baoIqzffZU5sDrVWRePj11gTpJW9Yj4v6SrUbpVhE4/v75F/rqEisSwaJDa099KUz6z3K+he3quh7UqXj+Z4j239PAAAAAACgw+VcXvXqq6/qyCOPTFs/8sgj9frrr7fKphDn8krhWql6nSRpW11IPeoWp11WbeZpRJ8i9SoK6M8njpEk7dmvJLfPyhAkGoahQr8VHlbVWwHbW99u0KL11dm/7+Ylkkyrdbqgp728tN4KPwvC8Vb4UK39XIP82lhthXj21ObWOpuwsJd0wr3Jx/4iyVcoSSrzhFLOSKwLRe0AMXFe4k5RkdhIXfGw1IVAceYLAQAAAABAt5ZzKtKjRw+98MILaesvvPCCevTo0SqbQlyRNS03ESSuq2rQbsaqtMtqlKcDh1dIkk4c218P/2Q/3Xn63rl9VuMgMRKSlrypioAVpFU1RPTV6kqddf9cHX7r7Ozfd1O81bpit5Tz9xbVWlOmvdE6qXazdPv37OdC8mhTjTXBOTHkpNXOSJSSX6skGS4rTJRU4g7aU5tDss6H3FoXkmmadpC4U1QkNlIU8OjF6P7JhfikcAAAAAAAsHPJuVf1uuuu009/+lO99dZb2m+//SRJc+bM0SuvvKIZM2a0+gZ3anaQuFaStHVblcYZVqj4UWx3jXNZIV21ma8x/ZPh2A92rcj9sxoHibNukN67XdN9h+lcnaPqhrDmb623L4/FTLlcWQxf2bTIuq3YLWV5aZWhesOnPCMkvf57qWGb41lDyzbV6vnPVmvVVuvcxFab2ixJbucQGkPyWcNeSt0hmfawFetPY0ttSGX5PvvqnbEisTjg0fTwufpeUY0G1n3V6GcFAAAAAAB2FjmnImeddZbee+89FRcX69lnn9Wzzz6r4uJivfvuuzrrrLPaYIs7sUSQWLNekhRb+aHchqn1ZqnmxJLn1FUrX/3L8nbssxoHie/dLkk6PGS1q2+sDiocr8qTpC2O8wObtWmhddszGSRWN4RVG4ppkxn/zM8etp/7sOdJkqRbZi7UZU98rgXrrDbqQFtNSzYMu7W52NVgtzabbr8kaWtt2K5GlCR/a7VYdyFFAa9qlae/us6WJG3dslHH3vluylRrAAAAAADQ/W3XGN799ttPjzzySGvvBY0V9bVuazZI0YgKV70rSXovtqc+ju1uXxaWR/3L8nfsszKckej0/pLN6lXstx+vr2pQRaE/47Uptiy1bnsMt5fWVVojgLe4SjVAG5PXXrFIcz6slFYuTHubNg3w/FaQ6I3WKRpvbS7Iz5eC0ubaoILxcxJdhuR1Z1GF2c0U51n/mfhysyS/5AlVad6qSj360Xe6aOLw5l8MAAAAAAC6je0q81qyZIl++9vf6vTTT9eGDRskSS+//LK+/vrrVt3cTi+/QjLckkypdoN6b3pfkhQefIi29B5vXzbYtV49swn1mtNCkPj2wo1a5Wht3lAdzO59a6zfD7u6UtZZj5JU6ylPvTavTBVFPmUyoHwHg9ImJSsSXeFauyIxkGdVeFY1RByDVtwyjJ0vSOxVFJAkVZpWC3iRUS+3oqpqCHfktgAAAAAAQDvLOUh8++23teeee2rOnDl65plnVFNTI0maN2+errnmmlbf4E7N5UoGcJWr1KvWOm+wtu/++vdPx+tX4fMUNQ096D4hu/MKmxMotW5DNdagFYfigEtbakN6ff56e21DPAxslmlKtfGKQ8fE5rXxisQGv2M4j79EcnvVOx5aJdxzxlg9+7PxGt6rMPuvJRcl/e0g0ROplS9+RqLLY+2jpiGiYMSqSPS3VXt1JzeyrzWluVrJMLdQ9fpuc11HbQkAAAAAAHSAnJOR6dOn64YbbtDMmTPl8yWrxw499FB9+OGHrbo5SCrsbd2u+UwuxRQ0PcrrMUBlBT49FT1EI4MP6LmGfXb8c/LKJK9VcaYtS1KeGtfLunWeFbi+KouKxIZtUjQeShb0Sr42HiTG8pPhovKt6sQ+JalB4q69C/X9gWVZfAE5Ov1Jaegh0pT/tVubPZFa+eMViR6fVeFZEwzbk6N97p0zSOwdb2kPy6M607pfYtRqycaajtwWAAAAAABoZzknI19++aWOP/74tPVevXpp06ZNrbIpOCTOSVz6liRpnVmuHo425pC8crVGu63LlRyIsuK9lKdGF6YHRhuqs6hIrI3/PviLJW8yIEy0NhuJkFSyg8TexalBYo+CzK3OO2y3I6RpL0ilA+yKxJ6+sHzxMxLdvmRFYigab23eSSsSne3clbLC5mLVatmmWkWisaZeBgAAAAAAupmck5HS0lKtXbs2bf2zzz5Tv379WmVTcBhysHX77X8lSWvVww4Sbz91L/ncLt126l6t81m9Rlm38dAyYXheepCYVUVi4nxER1uzlBy24i11BolWm3Pj4LA44G35c3ZUPEj8fh+vBpZYg0W88SCxOhhRKLJzVyRK0rghVtCbaG/u6alXOGpqpePcTAAAAAAA0L3lnIyceuqp+vWvf61169bJMAzFYjG99957uuKKKzRt2rS22OPObd+fSD1H2A/XmuWqKLTCtmP36qevrz9CP9yzb+t8VuJzls5OWR7oTR/AsnB9tUzTbPq96rdKs2+27hcm25pDkZh9RmJBuWPf8SCx8VmPO3z2Yzbirc2+aJ1GVFjfW6+zIjERJLbl5OhO7m+n7a2jx/RVvz7Wz2xYkXVu5PLNtdYFW5ZJT58jrfncevzdHOmbFztgpwAAAAAAoK3kHCT+6U9/0ogRIzRgwADV1NRo1KhROvjggzV+/Hj99re/bYs97tzcXmnE0fbDtWYPlTmq9rytWSXXa6R1G0wNDncJJs9M/J/9B8nncWnF5jrd+voi1QYjmd/rjeulpbOs+/GKxI3VQe37x9c1f22VJKm4on/y+rzyxu/QfuIViQrV2Gc6+gLW1OYaZ0WiZ+etSOxdHNCdp39fBSVW4Dsw3/o+2QNXnj1P+uoZ6aHjpHC99K/J0hNnSJuXNPGOAAAAAACgq8k5GfH5fJoxY4aWLFmi//znP3r44Ye1YMECPfTQQ3K7d96KrTY1YD/77gb1UJHf0zaf46h8lGQPSCnfONde2ndIuQ7etUKSdMcbi/Svd5dlfq8FLznex7r+nUUbVVkftpd79BmQvMaTPPex3fniQ2ZCtVLEatn2B+IVicGIPWTGvxO3Ntvi36u++db3xK5IXPWRdVu/NbU1fv3X7bg5AAAAAADQlrY7kRo4cKAGDhzYmntBU/onpzK7fIGU4RetqqS/5CuSQtXW47FnSbP/Ivemb7R3j6i+3OrRgcN6KM/r1uvfWOcfrm9q6MqAccnW1ur1kqTCRgFoWUlp8oEZbcUvJEf+Ius2WC3FrApLv986C7C6IaJQ1NrbzlyRaPPGz0j0W9+n7zbX6Y1v1muS8xpniLxpYfvtDQAAAAAAtKmsgsTLL7886ze85ZZbtnszaEJ+ueqLBiuverm+zf9+232OYUg9d5dWf2w9HnSAVaW4cYGeLrhJm8/5j3oU+nX4qN76n/0H6aEPV6gh3MTUXuf5iaOOlSTVh1PDQsPlCOZiyef+8T9jdcHDn+gPx+7RKl9Wi5ytzXGBQJ6kkBUkJioSCRLt71UPrxUkvrFgg95ZsFoLncO2F81M3idIBAAAAACg28gqSPzss8+yerM2q5SD3jnkSf3p6XdU0bt/yxfviB7Dk0Fixe7Sob+VnjhD7g1fq1fNAqnHeEnS0J5Wi2tDuIlKwnD87LzRJ0h7ntz0tXufIX31rLTf+fbSEaP76Ktrj1BBW7VwNxYftqItS+2lvLx8SSHVBMOckejksyoSS73JFvXBxrrUa2ocjzd+2x67AgAAAAAA7SCrpGbWrFltvQ+0YGMkoOVmXw3P97V88Y5wnlVYvItU0k/qNVra8LUUqrOfCnit8zCbrEgM11u3o4+T4pWHdaFkkPj4eftbd6beKf3wr5I3L+Xl7RYiSlJ+RdpSXl6epG1qCMfsfRMkym5tLjCCqij0a1NNUMOMNU1fv2mhFIvZvwMAAAAAAKDr4v+77yK21VkVYGX53rb9oFFTrduivlarsyQFiq3bcK19WcBr/eo0WZEYil8bD56kZGvzyWP7a/+h1vRfGUZaiNjuivtK+12YshTIL7Dv3/jyAkmSj2ErdmuzK1ynSyYNlySVG9Xp13nyJMNtVabWrEt/HgAAAAAAdDnbVfb18ccf68knn9R3332nUCiU8tyzzz7bKhtDqm111ve5rKCNKxKHHyad8YzUc2RyLRH0JaoMJQU8iYrEplqb49c6g8R4ZV+erxNO9x53rjTnbvuhzxdIu4SKRNmtzQrV6vRxA7VmW4Mi776Ufl3pACkakrYut1rGi3dp120CAAAAAIDWl3My8vjjj2v8+PH65ptv9NxzzykcDuvrr7/Wm2++qZKSkrbYIyRtrrWCxJK8Nq5IlKwwsaRf8nEiDAw7WpvjYWBDpIUzEh3Vhp06SExMbk5wtnjHESQq5XfB43Zp+lEjVOaxqmUjeY4W8aK+UvlQ6/6WZe28SQAAAAAA0BZyTkb+9Kc/6dZbb9WLL74on8+n22+/XQsWLNApp5yigQMHtsUed3p/fGm+nv10tSSprK3PSMykmYrE+lALQaIv2SJcF69ezPN2gSDRnf599ns64b7bmz3hOtnmXhIPEmsrvpe8rrC3VDbEur+VIBEAAAAAgO4g5yBxyZIlmjJliiTJ5/OptrZWhmHoF7/4he69995W3+DObF1lgy57/DPNeCcZxLT5GYmZ2EGic9hK4ozEFoatOCoSG+KhY35nrEj0NGpl9vh13F6p7bhUJCqltTmh2GNVy1YW7Zq8LhpyVCQmp2EDAAAAAICuK+dkpKysTNXV1nCFfv366auvvpIkbdu2TXV1dc29FDn63Qtf6fnPUyfiFgbacZpxgt3OmqxITLQnBzO1NseiUqQh/lpHRWKoE1ckJgbLJLj9uvnk72lEn2Slop8gMfnzdITKxS4rSKxR8jxMmTGp3KpIjNHaDAAAAABAt5BzMnLwwQdr5syZkqSTTz5Zl156qc4991yddtppmjRpUqtvcGd25RG7pzzes1+Jvj+wrP030uywlZhUtUZaOTd5veO6lDMSE63Nvg4IQ7PhbGd2e+R1u9SvNLl/pjYr2aruqEgsjAeJtaZPOvS3kr9YmvBrVQb6S5Lq1i1u920CAAAAAIDWl3Oic+edd6qhwao2u/rqq+X1evX+++/rxBNP1G9/+9tW3+DObNfeRfr5ocP1tzcX68FzxmnCbj07ZiOZhq3Eqwrrw1HplviE5/NnS32/l3Ldfxds0w/HWK+v78wViZIVJEZTp5Dn+5N/IrQ2K2Nrc4ERlCRVxfzSwZdLP7hccrk1e+5CHSOp0KxRpG6bHpu3TW99u1G/O3qUBlcUZHhzAAAAAADQmeUcJJaXl9v3XS6Xpk+f3qobQqpfTt5dFx4yTPkdWcWXoSIxEQZGY2byumWpQWKd6dfPHv1My8dYZw0mKhI75RmJUsYBKwWOvRIkKtnaHA1aLewut/IUDxKj8fM7XfGQ2cjTFrNQ5UaNHn3tff3+Q+t3ZfQuxbp88u5pbw0AAAAAADq3nJOR//73v3r11VfT1l977TW9/PLLrbIppOrQEFHKWJHo92b41UmcixiKB4nypzydCBIDnbUi0eNPW8pzBImckaiUKdyJqsREkFgZSR0EtLE6qNVmhSRp9fIF9vqyzZylCgAAAABAV5RzMjJ9+nRFo+kDNmKxGNWJ3VWGYSt+j0uGIXkUSV4XCaZc16DUCr/6zjy1WWqiIpHW5hQev2TEvw/xINFvWgHy1nBqkLhmW71Wm1Y7fnTLd/b68k21AgAAAAAAXU/OyciiRYs0atSotPURI0Zo8WKGKnRLidbmULKSzDAM+T0u5asheV2iIjFsBUV1ZuaKxLwuFCQ698qwFVnTrRtNbvbFrNvGQeLaygatilck9optsNeXbaqVaZoCAAAAAABdS87JSElJiZYuXZq2vnjxYhUUMEChW8rQ2ixZ5yQWOoPEhqr4dVZFYn2j1ua6UMR+XaeUobWZMxIzaDS52RONVyRGMlUkWkFiP2OjvV4TjGhTTepQGwAAAAAA0PnlnIwce+yxuuyyy7RkyRJ7bfHixfrlL3+pqVOnturm0ElkGLYiWWcdFhiOILFus3UbD5gSQWJtMKJYzFRDOCapa1Uk5tPanK7R5GZPxAqYt4RSz/JcW9ngCBI3pTy3fDPtzQAAAAAAdDU5JyN/+ctfVFBQoBEjRmjIkCEaMmSIRo4cqR49euivf/1rW+wRHS3DGYmSFSQWyrGWCBITFYmmFcxtrA6qIZI8V7PTnpGYoSIx38+wlTS+Qus2WCXFonLFrOpCZ5BYH4qqsj6sdaY15b2nUSlJGtm3WJL01erKdtwwAAAAAABoDTmPAy4pKdH777+vmTNnat68ecrLy9OYMWN08MEHt8X+0BnYFYmprc1NVSSaoVoZSk5t3lgTVFEg+asW8HTSINHtTVvKT5na3En33d7Kh0rrvpA2LZQGHmAvb3IEidvqrXBxo1kqSeqpbZJMTdmzj75ZW6V3F23S2QcOacdNAwAAAACAHZVzkChZgzYmT56syZMnt/Z+0Bk5W5tNU1r+rtRzhAJelwqcZyTWWu2rkZpN8kqqMq2z9DZVB9WryAoV87xuuVxGe+4+e0fcKP1zknTgZfYSrc0Z9BolzX9e2vCNHS7HTENbwi6ZpinDMFTdYJ2HucWwKhB9RlQlqtUhu/fSX19bqA+XblYoEuN7CgAAAABAF5L1/xf/wQcf6D//+U/K2r///W8NGTJEvXr10nnnnadgMNjqG0Qn4By2suxt6cGjpRmHKuBxq8DR2hyr36pwOKzIZmsYz0qzlyTrrLzlm63AqX9ZXvvuPRd99pCmr5QmXmUv5TO1OV2vkdbthvn2OYl18isak4IR6xzMqvqwJKlPeYm2mlYrdE9jm0b1LVZ5gU+1oai+WkN7MwAAAAAAXUnWycj111+vr7/+2n785Zdf6ic/+YkOO+wwTZ8+XS+++KJuvPHGNtkkOliiIlGmtOC/1t3K71ToNVNam10y9fH8RTK2LJMkrTB7S5KWbarV0o01kqShPTv5ZG9P6sAVKhIz6DXKut2wQApZP9fEYJ2aoFWJmKhILA54tVmlkqxzEl0uQ7v3LpIkLdvIwBUAAAAAALqSrJORzz//XJMmTbIfP/7449pvv/00Y8YMXX755brjjjv05JNPtskm0cESFYmS5EpW6A2NLVehs7VZ0ooFH8tduUKS9F28IvGhD1fouhfnW6/pWdjGm21dKRWJBImW8iGS2y9F6qWN30qS6hWQZE3olqSqBqsisSjgUV5ZH0nSQX2sgTuDK6zfpxVbUs/cBAAAAAAAnVvWycjWrVvVu3dv+/Hbb7+to446yn687777auXKla27O3QObo/kjlfqxasNJWlvY5HyjdQgMbLsfXnrN0qSVsSDRKehFZ28IrERjzt5nqPL6KRnO7Y3l1sq6Gnd32AFxDUuKyBOVCQmWpuLA1717T9YknTWGCtAHFhu/Q58t5mKRAAAAAAAupKsg8TevXtr2TIrRAqFQvr000+1//77289XV1fL602feotuonSgdbvifXvp+56lKoyfkRgzrZBt37p3JEmVZr569eqT9jadvrW5kZ6Ffo0bUq5xQ8pVls/vt80fryxdZv28l7qHSpJqg1bVYVWitTnPI1eh9T9A5IesYTyDeliBYuLcTAAAAAAA0DVkHST+8Ic/1PTp0/XOO+/oqquuUn5+vg466CD7+S+++ELDhg1rk02iE0icixdMDsioiKxTqccasDMnZg3g2N21SpJ1PuIupemDVYb3LGrjjbYuwzD0xHn764nz9pdBRWKSLx4Ir/5YkrTcv5skqSZoVSImW5u9UmG8MrVmg6RkkPgdrc0AAAAAAHQpWQeJf/jDH+TxeDRhwgTNmDFDM2bMkM+XHEzxr3/9S5MnT26TTaITSASJDq6q1RpeYt3/IDZK1aYVHK4zy/SPyDEqCnh0zPd2kST9/uhRevqCA1TSBav6DMMgRGzMl3rW5aq8EZKkmnhFonPYiuIViapZL0ka1MMKIbfUhuzAEQAAAAAAdH6eli+xVFRUaPbs2aqsrFRhYaHcbnfK80899ZQKC7vWIA3koNfI9LWqtRoxcKhUKa1RD11YcKu2bN2i+eYgSYbu27ufDhjWQ1cesbsGlOenvx5dl99RWeryamvhcElbk8NWEmck5nnSKhIL/R6V5Xu1tS6sNdvqVdyn64XLAAAAAADsjHIeQ1tSUpIWIkpSeXl5SoUiupneo9PXYmF5l78lSTrvqP01fMQYzTcHSzJ01VEjNGlkb+X7PISI3ZGzIrGwtwIBqxo1ObXZui3KUJEoSb2LrSnP6ypTh/UAAAAAAIDOK+cgETup8mGS1zEopahv8v7A8drtgGPUvyx5JuL3BpS2397Q/nyO34W8UhX4reLmxNTm6obE1GZPMkis2yxFrfU+JQSJAAAAAAB0NQSJyI7LJZ3xtGS4pAH7JdtVJemIGyS3V/m+ZKf8nv1KOmCTaDd+R0ViXpkK40FiemuzV8ovlwy3JFOqtSY3900EiVUEiQAAAAAAdBUEicjeoPHSpfOkHz8lVa5OrvfdW5I0cURP+dwujRtcbleooZvyOc5IDJSoND5EZ/7aKknJYStFAY/kcksFPa1r4+3NtDYDAAAAAND1ECQiN6UDpUCJ1HeM9bigl1WtKKlvSZ7em36o/v2TcR24QbSLRhWJR++5izwuQ+8t3qw5SzdrS21IktSjwG9d02jgChWJAAAAAAB0PQSJ2D7H3CHtc4507hspyz2L/Ap404fxoJtJOSOxTAN75OuoPa1zMx+Z850iMVP5Prd6FzcKEmutIJGKRAAAAAAAuh76T7F9SgdIR9/a0btAR3FObc4rlSTtUmqFg/NWbZMkDakokGEY1jWNJjf3LbEG81CRCAAAAABA19GhFYmzZ8/WMcf8f3v3HSZVdfBx/Hunz+7ObO/0LkUEEcResJeoscSoMRpjbLHlVWPeqKmvxiQmrz3ltSQaNfYSS7A3BASRjkiHbWyfLVPvef+4MMsGFEG2we/zPPvMnXPPvXPucET4ccpJlJWVYVkWzz33XE82R0S+Kv8WayQGcwEIbVoXc01dGwBDCrcIGzcHibWfA1CyaURiY1uCaCLVxY0VERERERERkV2hR4PE1tZWxo8fzz333NOTzRCRHbXliMRADkB65+bNhhZuMf156BHO65IXId5GOOghuGkKvKY3i4iIiIiIiPQNPTq1+bjjjuO4447rySaIyM74jzUSAbIC3k5VOo1IHHgg5AyExjWw7GWscadTkh1gVW0rVc1RBhVkIiIiIiIiIiK9W5/abCUWi9Hc3NzpR0R6wH/s2gxbj0gszwl2vHG5YNg053jjMqBjerNGJIqIiIiIiIj0DX0qSLz11lvJzs5O//Tv37+nmySyZ/JtsUZiIBuAUKBzkJiX6et8TXrn5o0AlGRvChK14YqIiIiIiIhIn9CngsQbb7yRpqam9M+6det6ukkie6YtRyRuChL/c0RiXsZ/BIkZ+c7rfwaJGpEoIiIiIiIi0if06BqJO8rv9+P3+3u6GSLiDcJpfwU7CRl5AGRtMSLR7bK2GqFIZqHz2loLaGqziIiIiIiISF/Tp0YkikgvsvcZsM/Z6behLUYkZge9uFxW5/qbg8S2TUHiphGJry6q4h8z13ZtW0VERERERETka+vRILGlpYV58+Yxb948AFatWsW8efNYu1ahgkhfk7lFkBj0urdRocB53TS1ecvNWB6dsRJWvQupRJe2UURERERERER2Xo8GiR9//DETJkxgwoQJAFx77bVMmDCBm2++uSebJSI7IcPXER563dbWFTaPSIw2QTLOmLIwJ4wrBeCUpr/BwyfB+3/ojqaKiIiIiIiIyE7o0SDxsMMOwxiz1c9DDz3Uk80SkZ1gWR3hoce9jd9aAjlgbQob2+qwLIubTxoNGL5vnnbK3/p1uvpL8ys47LdvceVjnxBLprqu4SIiIiIiIiLylfSpzVZEpG/wbitIdLmcnZtba+DR06Fkb/JO/F+mWEs712tvZGWLhx8+9gnGwOq6NvKzfNxy0pjuabyIiIiIiIiIbJOCRBHZ5XzbmtoM4Nr0W071QqheiHfwIdztv6tznTUf8Ny64RjTUfTB57Vd01ARERERERER+cq0a7OI7HLbnNoMUDah8/vnL6OQRtbahawtPhKA+Lq5vPhpBQBXHjkcgA0N7Zgtk0URERERERER6XYKEkVkl5syOG/bJ46/HU77K1zwqvPe2ADMMSP42/oSAJYsmMuq2lYAzp0yAIDWeIrGNu3oLCIiIiIiItKTNLVZRHaZ164+hOmLq7jo4CHbrpDdD/Y+A+wUuH2QigNQafJZaZwdnL2NKwDwe1wUhvwUhvxsjMRY39BObqYPgDumf0YsmeLHx47qtMmLiIiIiIiIiHQdBYkissuMLAkxsiS0/YouN+QMhLrlAFSaPFaYMgAGW5VY2NwceBLrw8/olztpU5DYxsiSEIsqmrjzDee6s/cbwKCCzC57HhERERERERHpoKnNItIz8ganDytNPutNIXHjJmjFOdL1Ceckn4XpN3Nd7B72tZaxvqGd6576lFPv/TB93ZLK5p5ouYiIiIiIiMgeSUGiiPSM3I4gkXAZFx06nBpvOQAnuzvCwgOa/sXT/p+zpr6V5+dVdLrFYgWJIiIiIiIiIt1GU5tFpGdkl6cP//rDUyCzgLmf702/urWc7J6xVfWn56zfqmxxhYJEERERERERke6iEYki0jM8wY7jjHwAmgYd94XVcxIbASjNDvCjo0YAmtosIiIiIiIi0p0UJIpIz9jrJOe132TYtPNy1l5H0mwytll9uMsZkXjaxHLOP3AQABVNURpa413eVBERERERERFRkCgiPSVcCtetgPNfTBcNK83nusQPmG2PYF358XDDahh+jHPOqiAU8HD6vv0JB7z0z3NGNGpUooiIiIiIiEj3UJAoIj0nswC8gfTb3Ewfr9n7cUb8Z6w69E4I5kLp3gBcOLyN964/nMEFmQCMLg0D2nBFREREREREpLtosxUR6VUe/O5+fLq+kYOHFzgF/SY7L/UzIehN1xtdms1ri6oVJIqIiIiIiIh0EwWJItKrHD6qiMNHFXUUDD7Y2ZileT1UL4KSsQDsVRoCYGllpCeaKSIiIiIiIrLH0dRmEendvEEYcphz/Pnr6eKSbGdKdEObNlsRERERERER6Q4KEkWk9yse7bxGKtNFoYAzzTkSTfZEi0RERERERET2OAoSRaT38zvTmIl2rIeY5XdWZmiJJbFt0xOtEhEREREREdmjKEgUkd7P7+zQTKwjSAwFOpZ4bYlrVKKIiIiIiIhIV1OQKCK9XyDbed0iSPR7XHjdFgAtmt4sIiIiIiIi0uUUJIpI77d5ROIWU5sty9I6iSIiIiIiIiLdSEGiiPR+m9dI3GJEImy5TmKiu1skIiIiIiIissdRkCgivV9g6xGJ0LFOYrNGJIqIiIiIiIh0OQWJItL7pTdbiXQqTo9IVJAoIiIiIiIi0uUUJIpI77d5RGIqBslYunjzGoktMQWJIiIiIiIiIl1NQaKI9H6+UMfxFtObN09tjkS1RqKIiIiIiIhIV1OQKCK9n8vVESbGtg4Se8vU5p+9sIhv3PMB7fFUTzdFREREREREZJdTkCgifUN6w5WmdNHmNRJ7w2Yrxhge+nA1n65r5JWFlT3dHBEREREREZFdTkGiiPQN29hwpTetkVjfGk8fVzfHvqSmiIiIiIiISN+kIFFE+obNIxK3mNqc1YvWSNzQ2J4+Xl3b2oMtEREREREREekaChJFpG/wbz21uSDTB8Bri6p58INV3Rcoxtvgb6fA+39IF1VsESQurY5s4yIRERERERGRvk1Booj0DXmDndfPXksXHT6qiNLsAAA/f3ExD36wunvasugZWPkWvP4zMAaADY3R9Onl1RFs23RPW0RERERERES6iYJEEekbJl3ovC55Af5xFiRjBLxubjlpdLrKnDUN3dOW9i0+p7kCgA0NHSMS2+IpVmp6s4iIiIiIiOxmFCSKSN9QtBfsdbJz/NmrsOJNAI4dW8rTl04FYMGGJozphpGATes7jmuWALBiY0unKvPWNXZ9O0RERERERES6kYJEEek7zngIBh/qHC//d7p4bHk2XrdFfWuc9VuMDOwqdt2K9PH6ZbN54dMK3vlsIwDDi7IAeHtZDbFkqsvbIiIiIiIiItJdFCSKSN/hcsPUK5zj5dPT6xP6PW5GlTibsSzY0PRFV+8y0erP08fLF87mvredYPGwkYVcNW04AC/Nr+SaJ+Z1eVtEREREREREuouCRBHpWwYdBC4PNK2D5g3p4nH9sgGYv76Lg8RUAn/LuvTbwW0LWVLpfObvzxjPlMH56XOvLqzSpisiIiIiIiKy21CQKCJ9iy8D8oY4xxuXpYvHp4PExl37eSvehN8OhyfOhdZaeO5S3CZJ3LhJGDeDXNUMsSoZWx4mP8tPYcjPmz9ypl/bBjY0dv1UaxEREREREZHuoCBRRPqeghHOa+1n6aJx5TmAM7V5l44CXPAUtNbAkhfh3d/Cgiexsbg8cRUf2XsBcITrEw4bUZS+ZEhhFiOLQwB8XtOyzduKiIiIiIiI9DUKEkWk7ykc6bxuESSOKPCzl6eSVLSFVXWt6fJkyqYtntz5z6rrWA+RmfcDsNY9kOn2JKbb+wLwA89LnL9PqNNlw4udTVeW10R2/rNFREREREREehEFiSLS9xRsChI3dgSJnn//mFc8P2K2/1JeeP1tABasb2KfX0xn9M2v8Zd3V+7cZ9Uu36roY9vZUGX4MZex3PSj0GqicOFfO9UZXuQEi0sqI8STNlVN0S/8iI2RGC8vqMQYracoIiIiIiIivZeCRBHpewqcII+q+dC4DmIRmPcYAJlWjJLFf+X95bX85b2VtMSc0Yi/fW0ZKzfu4DTjtnpor9/0xkoXfxgbCsDJ+w1l2Gk3O4XLXu106YQBOQA8+8kGxt7yGvvf+gZPzVm/zY856a73uezRuTw9dwPN0cSOtVFERERERESkmyhIFJG+p2Scs+FKrBn+OBb+dx9IdmxqcqrrfS77vzd54dMKAEIBD/GU/YVB3heqW+G8hspgzCkAtBo/79vjGFUSIjvoxRp+FFguqFnkhJrzHoM5D3Pw8AJOm1AOQDxlA3DTcwupXrmg0yjH5dURqpqd0Yr/9eSnHPG7t4koTBQREREREZFeSEGiiPQ9bi+c+beO9221zusRN2HnDiZgJZjocsK6seVhbjh2FAALK5q3f+9kHB44Fh45Hd74uVOWPxROuY+/jXuIA2J3kVs8gKcvPcA5l5EH/SY7x9NvhucugRevxKqcx23f3Jt7z5nI3y6czKiSEFmJWor/dhD8dRrE2wB4eu6GTh9f2xJnwYamnfteRERERERERLqQgkQR6ZtKxsFNdZ3L9v0urv5OqDfeckYTnj15AGPLswFYtKGJpvbEl2++snaG8/P5dFj9nlO295ksrUtw26dBmsji6mnDyfR7Oq7Z73vO66JnOso+uh+fx8Xx40o5ZEQhh44s5ALPa865aCM8fRGsncmcNfX8p8rGL15PUURERERERKSnKEgUkb7L7YET7nCOJ/8AMgug3NlJ+WLPS1zneZxT89cxqsTZ+KSuNc74n/+bg37zVnrtxK2serfz+4nnUz/yW1z08Me0xVMcOCyfo8eUdK4z9nQom9i5bPFzkIyl3+5THuYs91sd55f9Cx44mkXbGCW5pr5tu48uIiIiIiIi0t0UJIpI3zbpQrj4HTjmf5z3mwK9TCvG5Z4XyPj39QS8bopC/vQl9a1xlldHtn2/Ve90fr/3Wdz5xnLWN7QzIC+Du8+eiNtlda7jcsF5z8C3HoOL34bMQkhGYcPcdJWJwUryra0/MxVvJ+h1dypbpyBRREREREREeiEFiSLSt1kWlO3jjE4EZ8pzMLfjfN1ysG0uPWwo/XKD6eKqpii01EBqi5GJto294ZPO9+8/maVVzqjBq6cNJzfTt+12BHNh1PFQNgEGblo/cc0HzmvlfIqePGWblw2xKvF5XPz0hL3SZWvqWrf31CIiIiIiIiLdTkGiiOxevAH4wXtw5SdguSEVh5YqLjhwMO/fcAQn7F0KQPuGhfD7UfDsD9KXRiN1uIwTLDZM/hGc/Ti4vVRsWrOwX27GV2vDwAOd11XvgjHw3GVYcWc04t3Jb7DS7pgaPdxaz7n7D+Cig4fw0g8PAmCtRiSKiIiIiIhIL6QgUUR2Pzn9IW+I8wrQsDp9qjQcACB37XQwKajomH68Zq1Tr9FksnLMFTDyOGzbOKMXgbKcwFf7/GHTAMuZJv3B/0L1gvSplcXHcUT8Dv6RPAKA/5pgc8XhwwEYkO8ElbUtcZraEjv61CIiIiIiIiJdSkGiiOy+cgc5r1sGiTnO9OaSxjlOQWtt+tyGDWsBqDNhNkbiznFrnHjKxrKgOPwVg8T8oTDxPOf49Vuc13FnwjWLOOjAgwFYZpyQc0B8BUGfs0ZiOOBNT79eXLn1JiwiIiIiIiIiPUlBoojsvrYRJJZlB/CQZFDbQqcg1gwJZ8ThxqoNANSSzcYWZ8flisZ2AIpCfrzuHfgt87AbO7+fehlk9+P4caUcM6aYfuMOdcrXzgQ7la42ujQMwKKKpq/+WSIiIiIiIiLdQEGiiOy+NgeJC5+BuLOBSWlOkLHWaoJEO+q11WKMoXFjBeCMSKyNOEFiZZMTJJbldGzU8pWEy6D//s5xIMfZhAUIeN386bxJfP+Mb4A/DLEmqOqY+jymLBvQiEQRERERERHpfRQkisjua6izDiF1y521CnFGJE5xLelcr6WGhz5cTbSp2qluwluMSNy0PmL2DgaJAKf9CUZ/A857Zutzbg8MmOocr34/XTy6zBmRuLhCQaKIiIiIiIj0LgoSRWT3VToeDrnOOa74BICicIDTC9Z0rtday7OfbCAfZzpxHWE2bhqRWN3sBIkl2V9xfcQt5Q6CM/8G5ftu+3z//ZzXLUYk7lUaAmDFxhYSKXvHP1NERERERESkiyhIFJHd2yBncxPWzoRFz0EqyfCosz7iRuNMI166YgWralvJt5xRgLUmOx0kNked3ZNzgt5d37bcwc5r49p0UVl2kAyfm0TKsKaubdd/poiIiIiIiMhOUpAoIru3zeskxprgyfOdXZRjzUStIB/YYwB49v1PiUSTFGwKEutMmHnrGrntlaW8t9zZ1Tkr4Om6tm0RJLpcFsOLsgD4vCay6z9TREREREREZCcpSBSR3Vu4vPP7GXcDUBUaTY3JBUiPRCxyO8FdnXHWKbz/nRWsb3A2WwkFumBEYs4A57V5AyTj6eJhRc705uXVLbv+M0VERERERER2koJEEdm9ubc9knBjeGw6MLzY8y+OcM0lDydIHDV00Fb1Q10xIjGzEDxBwEDz+nTx8GJnROJnNQoSRUREREREpPdQkCgie6R+Yw9mHiPS7+/23kXIOEHiL751CNOvOaRT/S4JEi2rY1TiFtObN09tXl6tqc0iIiIiIiLSeyhIFJHd3/6Xb1VUOuYQ7rnxcu6a8DLL7H5kWLGOk8FcsjM6T2UOd8XUZugIEhs6dpIevmlq88raVpLauVlERERERER6CQWJIrL7O/ImuODVjveDD4FQMQVZfr57zGSiQ47uOOcPg9tLTtDX6RZdMiIRoGDTqMgNH6eLynODBLwu4kmbdZvWaBQRERERERHpaQoSRWT35w3CwKlwyHVQPA5OuT99KhTwMn7UyI66QWcDFp/HRcDr6lSvSwyf5rwuexVsZ/Sh22UxtFDTm0VERERERKR3UZAoInuOI34Kl74P2f+xk3OouOM4Iy996HFtGSR20YjEgQc5oyBba2DDHDAGgBHFm3Zu1oYrIiIiIiIi0ksoSBQRydoiSAx2BIlul5U+9rq76LdLjw+GHOoc/980uHMfqJjHsE0brrwwr4KfvbCIJZXNXfP5IiIiIiIiIl+RgkQRkawvGpFobaNyFyif1HHcsBoeOY39BzkjEpdVR3jow9Uc97/vsWKjRieKiIiIiIhIz1GQKCISKuk4dndssuLutiBxYuf3bXVMCGzcqtrri6u7pz0iIiIiIiIi26AgUUTEl9lxnEqkD7stSCzdZ6siV/V8rjh8WKey+Ruauqc9IiIiIiIiItugIFFEZEupePrQZXVTkBgIQ9amUZHF45zXyvlceeRw7j93Xx74rjP1edaqepraE19wExEREREREZGupSBRRGRL5fumD8eUhbvvc7/3bzj/RZh6ufN+4VP4ki0cO7aEiQNyAdgYiTHhF/+mPZ7qvnaJiIiIiIiIbOLp6QaIiPQKl34In78OUy5JF/3q1LFkB718e8qArv/83IHOT/1KsNzQuhGevQTO/gc5GT6GFWXxeU0LtoF1DW2MKA51fZtEREREREREtqARiSIiAMVj4MCrwNOx2UpRKMBvzxjPhE0jArtF3hA49AbnuGZRuvhP53WMlNwYiXVfe0REREREREQ2UZAoItLb7H2m8xqpAmMAGFqYxdQh+QDUtihIFBERERERke6nIFFEpLcJbdp4JRmFaMdOzQUhP6ARiSIiIiIiItIzFCSKiPQ23iAEsp3jlup0cWHWpiCxD49INMZgNo2yFBERERERkb5FQaKISG+UtWlUYqQyXVQQctZv7BMjEpsr4I1fQqQjCG1ojXPAbW/yoyc/7cGGiYiIiIiIyM5SkCgi0huFip3XyNYjEmtb4j3Roh3z9m3w3u/gvgPSRbNW11PZFOWZuRv48PPaHmyciIiIiIiI7AwFiSIivVGo1HltqUoX9ak1Etd/7Ly21cK62QDUbRGA3vfOip5olYiIiIiIiHwNChJFRHqjrM0jEjcFibZNYYYb6Ni1uTWW5InZa2mLJzuuS0Qhleh0q/97fxWn3PMBjW3dOJLRG+w4nvcIANXN0XTRRyvraIklefLjdVz8t49pjSX/8w4iIiIiIiLSyyhIFBHpjTaPSGxY7bw+cQ6jH92XUuqobYmxvqGNnz63kBueXsDPXljk1Im3wv+OhweOBWDlxhZufGYBv3xpMfPWNfL47HXd1/7mio7jJS9CMs7+S/6Hy9zPAZBIGZ6ft4HrnprPvxdX88D7q7qvbSIiIiIiIrJTPD3dABER2YaBm9YWXPGm87PsZVzAfxV+xI82nsA9b63g2U82APDPj9dxSev9DFn1D+ealipi8RhH/eFdUnbHDskel9U9bbdTnXabpq0Opt/M1PpnmeqFF11Hsi4R4r+fXZiusra+rXvaJiIiIiIiIjtNIxJFRHqj0vFQuBcko/D3U9PFJ5p3uNt7J5lz7gPgONdMVvrP7QgRN5l883OdQkToniCxqT1BrKkSTAosFxx0jXNi5n3pOreNr6Igy9fpulW1rV3eNhEREREREfl6FCSKiPRGlgXjv7VVsb9lPSe6P+Kn3kfJpZlz3K/jssxW9cLW1sFcy65eh9C2AWfNxjlrGlheHeHk257B/79jnPNZxXDIdZDdv9Nl41pn8vjF+3cqW1TRvFXwKSIiIiIiIr2LgkQRkd5q7zM7v59wXqe33/B8xDh/DQBr7cJO58K0ce7+AzqVRaJfM0hMtMOjZ8DL18Enj8Av8zGfPsF3/m8W37zvQ476w7sclvygo34qDr5M2qf9utNtsqo+YmhBZqey9kSKFRtbvl77REREREREpEspSBQR6a3CZZA/zDmeeL4zTdjlTZ++oXg22cmNAHy23887X2q1cdiIIjJ97nRZ8w4EiZ/XRHhs1lo+r9ki3Fs+HZb/G2b9GZ6/HIyNeeGHLK5swsIZnZhDR/3V0UzmrGlgTcFh/C5xBvclTyJu3Lja67Ga1nHPtycycUAO/XKdHZ7nr2/6yu0TERERERGR7tcrgsR77rmHQYMGEQgEmDJlCrNmzerpJomI9A7nPg2H3gDH/Bryh8L334CzHgUgWLdpt+asYqYd+81Ol4VpZVRpiJeuPJiCLD/wJVObl0+HN34JbfXYtmHGijqO/eN73PjMAo76wzv8a36lU+/z17e61JWK8ZzvZj4JXs60fjZlVl363A3t5/PDf8xlXUOUu1On8pvk2bTnjnJOVszlhL1LeeayAzlmTAkACzcoSBQREREREenNejxIfOKJJ7j22mu55ZZbmDt3LuPHj+eYY46hpqamp5smItLzcgfB4T8Bf8h5XzoeRh4PgZyOOgUjwBvgH/v8jSaTAUCRN0p5TpDBBZlcf+xIACLRRMc1xsDGZbDwaWe68nu/I3nfQRxz63Oc/ZePSNqGIFGOtWbyznN/pTYSdXaPBv7sPYeXU5PTt9rHtYIc08Rf917GcQNSAPwofgkzzV5UNEVZ3+DsyHzc2BKyh266bu7fnd2dgb37ZQPw0IereeSjNbvy2xMREREREZFdqMeDxDvuuIPvf//7XHDBBYwePZr777+fjIwMHnjgga3qxmIxmpubO/2IiOxxXC4om9DxvtAJCofufRBv2fsAsH+ZG8tydmkO+T3Af6yR+N7v4Z7J8NSFgLPJiSeygYvaH8KFTSENzC35Dff5/pfb7d/xyh9/AE3riBovd0SmcVnian6cuKhzu9Z8QChWBUAF+enij9c0ANA/LwPK93UKV7wBd0+CjcsYW56drvvT5xaytEq/t4uIiIiIiPRGPRokxuNx5syZw7Rp09JlLpeLadOmMWPGjK3q33rrrWRnZ6d/+vfvv1UdEZE9wsADOo4nfsd5GZhLdm4BAMcMDaZPhwLOuorpEYm1y+HNX3a6Xf1x9wNwludt/uT9A7/Ieppg47L0+W8nnwfgxdRUJgwpw7LghdQBne7Bqvew6pYDUGk6gsTNU6P75QZhzKkw6XvgzYT6lfDvmxicn8nkQXnp+r977bMd+y5ERERERESkW/RokFhbW0sqlaK4uLhTeXFxMVVVVVvVv/HGG2lqakr/rFu3rruaKiLSu+x7gbOL8wWvONOdAa/bxeHjhwPgSXRsehIKOCMSWzaPSFz2cud7DTyI2ZmHcV/yJACOcs/huKQzjZnJFwPgtpxRi4+mpvHTE/ci6HXTRoBbEucTLx4PvhDYHVOnn7vxDC49bGinj+mfmwH+LDjxDrjodcCC5a/hqv+cJ36wP9OvOQS3y+L1JdXMf+cZeOhEqFmavr6+Nc6FD83m8Vlrv8YXJyIiIiIiIjurx6c27wi/3084HO70IyKyR8oqhG/c3XlkIkBg0zThaMfGJZuDxPTU5sr5zuvIE2gecCR/zb2aWasb+E3ybD4NH95xr/JJsP9l6beL7IFMOfgoxpRlM7ggE4CHU8fgu/RdOOiqjusyi8gJh/neQYMJep1do10WjCnb4vfs4tEw4hjn+NPHsCyL4cUhzp86iGLq2futC2D1e/DhnelL/u/9lby5tIY/vP4Zxpgd/cZERERERETka+rRILGgoAC32011dXWn8urqakpKSnqoVSIifdg2gsSsgIeh1gYOTn6A3VILVU6QWDPibCat+D6/+ijO/72/CoCNw89yLsrIh5PvdDZ7yXCmS7v2+x43Hj8agN98c2/2G5TLs5dtCjLHnQlun3N80DUAFGT5ufW0cRw1upgnLzmAonCgc1vHneG8LnrW2fwFuPCgQVzs+VdHnZolALTHUzw60xmJWN0cY31D+85/RyIiIiIiIrJTPD354T6fj3333Zc33niDU045BQDbtnnjjTe44oorerJpIiJ90zaCxLAd4Snfz8m1Wojf8Sd8dhSAe5ZlEU+1dbo8b/yxMPo5ZwOXcJlTePztsOZD9jr6B+l6Y8uzefKSLUZD5g6EC18Dlzs91RrglAnlnDKhfNttHXEseALOWokr3oSScfTLzucU78zN+79AzWJIJXj2k0oa2zqmTs9d2+Bs3iIiIiIiIiLdpkeDRIBrr72W888/n0mTJjF58mT++Mc/0traygUXXNDTTRMR6Xs2B4lrPoCVb8OQw/B/cDsBy1kzcXOIaLJKeGlFstOlx44pYZ9+OeA6vFM5Y7/p/GxP+cQda6s/C4ZNg6UvwSOngcsLe51Ivqmn2WTgJUkwGWXhvJk88EEKgPxMH3WtcT5e3cA39vmCgFJERERERES6RI+vkXjWWWfxu9/9jptvvpl99tmHefPm8eqrr261AYuIiHwFhXs5OyIDPHkBtDdirXgLgBmp0elqNUNOo641Tpbfw8c/nca/rjyI+86diMtldW97x5zacWwnnGnOwBv2BD62RwDw+DNP8XlNCz63ixuOHQXAnDUN3dtOERERERER6fkgEeCKK65gzZo1xGIxZs6cyZQpU3q6SSIifVO4FK78BLIHQHs9fHQvRCoBWDj6WtbZhXxsj+SZ7PMAOGhYAQVZfsaUZWNZ3RwiQseGK//hY3sks20nNNzf5ayTuFdZmENHFgKwtKqZllhym9eKiIiIiIhI1+gVQaKIiOxCoWI42NnwhBVvQdyZ1nzBKcdyaOKPnBG/iZlrnbJOOyn3BH8IzvwbHHkL7HVyunj4voczw3ZGUE5xLQYMe5dnUxwO0C83iG1g3trGnmmziIiIiIjIHkpBoojI7qhgpPO6fpbz6s/GEwxRFApicPHRyjoABuT3gg1LRn8DDr4WCoani8456Th+dul5pNx+Cq1mxlmrGF8aBGDfgbkAzFhZ2yPNFRERERER2VMpSBQR2R3lD+38PlwKQEl2AIBowgZgUH5mtzbrS025BPKHw4FX4fV6GTOgCIY7U59f9P+Uk2acCfE2jtzLWUP3nrdW8Nf3VpKyzZfdVURERERERHYRBYkiIrujrGLwZXW8DzlBYummIHGzXhUkZhXBDz+Go36RLnIf/XNslw8Af+Pn8Ok/OGFcKaNKQgD86l9LeHz22h5proiIiIiIyJ5GQaKIyO7IsiBvcMf7TUFicbgjSMwOesnO8HZ3y3ZM3hBc5z0Dpfs47z+8C7dJ8fszxxPyewB48IPVGKNRiSIiIiIiIl1NQaKIyO4qf1jHcXjrEYmDesP6iF/F4IPhgpchmAcNq2HJC4wpy+aDG48g0+fm85oW3v9c6yWKiIiIiIh0NQWJIiK7q71O6jjOGQB0HpF44LCC7m7RzvNlwuSLneMZdwMQDng5Y1J/AB76YHUPNUxERERERGTPoSBRRGR3Nfab8J3n4ZDrYcxpAIwpC2NZkJ/p44ojhm3nBr3MfheBywMb5kD1IgC+M3UgALOXrWJNRVVPtk5ERERERGS3pyBRRGR3NuQwOOK/IRAGYHhxiBevOIg3f3QYGT5Pz7ZtR2UVwsjjnOO3b4OqBQxZ9lfOHtLOG74fkffAAVC/Kl39wQ9WceJd77GsKtJDDRYREREREdm9WKYPr1Df3NxMdnY2TU1NhMPhnm6OiIh0tTUfwkMngLG3eboqcxQnx35FYTjAoormdPmCnx1NKNDLN5YRERERERHpATuSr2lEooiI9B0DD4AzHgbXtkPBktallLYu7hQiAjw6c213tE5ERERERGS3piBRRET6ltEnw/kvwKTvwaE/3ur08/6bOcr1caey215Zym9fW9pdLRQREREREdktKUgUEZG+Z+ABcOIdsP8l6SL75LvTxz/2PAYYTtmnjPH9sgG4560VrKtv6+6WioiIiIiI7DYUJIqISN8VzIWzH4dv3Itr4nlw6QwAhroq+a+Rddx04mievOQAhhZmAvDi/IqebK2IiIiIiEifpiBRRET6tpHHwYRznOPi0TDhPACuaLid/Fm/w7fgH3zvwEEA3PvWCj5aWUcf3mdMRERERESkx2jXZhER2b1Eqp2dneuWp4tiU6/mhEVH8HlNS7rsmmkjuPLIYViW1ROtFBERERER6RW0a7OIiOy5QsVw4Wsw/tvpIv+MP/LSSYajRxeny/7w+mc8ot2cRUREREREvjIFiSIisvvJzIdT74OfNcG+FwAQeOUa7j2phIcu2I/vTB0IwO//vYyaSLQnWyoiIiIiItJnKEgUEZHd27RbINwP6lfi+cfpHDY0h5tPHM2okhCNbQnO+ctMItFET7dSRERERESk11OQKCIiu7dgLlz4CmQWwsYl8MIVeBpX8adzxlMSDrC8poUbn1lALJnq6ZaKiIiIiIj0atpsRURE9gwLnoKnv9fxPiOfxQffwwkv2BgD+Zk+Jg3K5eJDhrLvwNyea6eIiIiIiEg30mYrIiIi/2nc6fDtf8Kgg533bXWMfu9ynjiknuKQj7rWOK8tquaCB2exqra1Z9u6g2zbYIwhnrRZWtWMbffZfyMUEREREZFeTCMSRURkzxNtgnunQvMGAOzy/Vg65HwenlXB201lNHoKuOLwYRw2sohw0ENOho/soLdHmmqM4V8LKsnye5g4MJdwYFM7KuZBSzULM6bw7b/OJLUpPGyNpzhgaD53f3sieZm+HmmziIiIiIj0HTuSrylIFBGRPVPDGvjoPpj7N0h0jEBM4eK11CT+njqKWfYoUrjxui1O2aecGyYaCpJVMHAqBLIBWFffxutLqsnP8jOqJMSwwixcLmvn29VcAaFSsJx7vLWshgsenA3AFGsJP894guGuCtyJFgCe8JzMDS1nAZ0/c0xZmH98f/8eC0BFRERERKRvUJAoIiLyVUWq4L3fw6r3INkODavTp2rJ4U+pk1iYGsBRrjlc6HkVgJgni41FB7Iq72Ce+LSeOYnBVJIPQF6mj2FFWRSHA/zi5DHk7siowPd+D2/8wjnOKobcQfyX77+ZvqiKQquRZ3y3ELbat7rsj67zmXbu9bQkIBgIcvvDT7GiLUi9p5BDhhdwzJgS1tS10RZPceFBg+iXm7HTX5eIiIiIiOxeFCSKiIjsrOrFMPsvsOBpiDVtdbrN+MmwYp3KmsniV4EfURBZyr/sKawxJQAcMqKQgiwfA/MyufLIYVjWl4xUbG+E349ywswtfGKGsxerCVgJAJa5hnB39HgCVpw8ItzofWybt0vg5rTYz1lghnQqH1kc4slLp3ZMke7FapqjZPg9ZPk9Pd0UEREREZHdloJEERGRryvR7owOXPOBc2y5aBx9Dv+0jqV+6ftMa3yCwbHl5Ju6Tpc1ZAzm3lEP85cP13cqP3vyAH5wyBAGFWQ6BfFWiLdBVqHz/t3fwZu/BKB+4g/Jyy+C6Tdt1awPD3+Sb7+S2PTOcK33WX7ofhqLbf/vfH7uUZxVeTYuXyat8VS6/N5zJnL8uNKOiqkkrH4X+k0Gf9YOfFG7wLJX4MkL4LQ/wehvAM6U8aP+8A5jy7J58pKpXx7CioiIiIjITlOQKCIi0l3WzYIHjgXTEdKRM4C1Vim3ei4js2gwT83pCBW/e8AgfnbSaPjrNKhZAj94B8Ll8Mex0FbHVfHLmJN9FO9dfzizfnMCU6IfdNy3fBKp773OYb97i3X17Vx55HCO2quYcXmbPnvtDFj4NOz9Lfjnd9KjG5Ph/liFI6logZ+u25d37PF43RbfnjyA0cVBpg4rYcDcW+HDuyC7P5z0v064ZyeYOfy/aMXHAUMLCHjdXfMd/ix7i2NnFOj976zgtleWAvCvKw9iTFn2tq4UEREREZGvSUGiiIhId6peDL5MqJgLT10IxnbK84dDRh4NUZs/tRzC/Q37kkczP/M9wsmu9wGIjjsHz6AD8bx4GWvtQg6P30EKN+fuP4AVs17hMd+vnXsd/zsYcSzk9GdNXSvLq1uYNrr4i9u0bhYseAo+fQxizZ1OVfgGs7w9RK4VYYy1mg0UUuyO4Le3Xn+x0WTyamo/3gmdQNGoA6hqjnLC3mUcMapo10w5TrTDr0s63v+kEnwZXPy3j/n34moAJg/O40/n7rtj602KiIiIiMhXoiBRRESkp2xc5uwEPePuzuWeIA/u/zJl71zPMe7Z27z0j8nT+GPy9C1KDDcUz+HSEw+A4UftXHvaG2HhU2C5nMDz4wc6j57cQo3JYZUpYYpr6TbP35U8hT8mv0kW7SR82XzvoMFcdPAQslvXQLgMfDuxicvy6fDoFs8cyCF10p1MfDJAUzSZLi7I8vPrU8cyojjE7NX19M/NYOrQ/B3/PBERERER6URBooiISE9b+5GzE3TeYHjp2q02bol7w8yNlbO/a0m67Nf9/8z13z2DP72zgt/9+zMAfvPNcZy134Bd166NnznrPkYbweWBEcfx2YwXaJ//PPcnT+S19lEMDSWpimeQiLWyn/tz7hy1iNwVz3W6TZ0J8bE9Ep/fz+HJDzDBXKzyfZ1Rk6ESaKvH9maSGnMaXrer48LP33C+mwN+CIEwPHc5zHtkq2bOtEdhXF72yoP7247kvsbJnc5bFrx4xUGMLdeUZxERERGRr0NBooiISG8y9+/wwhUd78smYr7/Jre8sAjvrHu5yfsoq00x2dctIDfLjzGGHz+9gJW1LTx4weRu27XYtg1N7QlyMrxEYkme/2QDA/IzOXREIbz6E/jonh2+52Gx31M6eCynTignP8PNAc8dQDDRAIFsGHEczH8cgMdG3U19W5L+9R9wQsvTuLHT9zDeDO4d/Qh3zY2TTCbIMFGayWRwgbMbdiSa5KOVdVw9bQQjikO77PsQEREREdkTKEgUERHpTWwbPvk7rH4f1s2Ek/4IQ48AYG1tK889+QBlQ8Zw+jFH9Gw7v4wxzrRtl8cZcbhxGRs//DsfLf6cF+L7EcXHd9zTOco9p9Nlb6XG85E9miRumsngt94/b3Xrem8p+0Z+i8EZubivtYwfeZ5k5MAy8jfO2rTGo4XJGwJN6zCeAKfHf8bc9pJO9xlVEuKlHx6EZ8sRkCIiIiIi8qUUJIqIiEi3aI4mWF7dQkGWj/ZEilc+Xceny1ZwonsGp2+8d5vXTGcKK/qdxsjWOeS5W/n1honMMnux78BcjhtbwsxV9RRk+fnVKWNx1y6Dpy6AmsWd7hEvm8wfCn/BR5U2n6xtTJcfM6aYP5y1Dxm+7hnFKSIiIiLS1ylIFBERkZ5lDLx/B9R+7rxtqYGVb2GZFN+NX8fb9oRO1bODXub8dNoXjyaMVMOKN2DtDGczG4CMfBh9CgzYn49r3fzojTbWpnIYm2szsV8WLe5cCsJBxpZn43FZtMVT5GR4ycnwAhb9c4MUhvxYlgVAWzxJSzRJwOcmHPB20Rcju6VUAiy3s3hnWx1kFmDbhoRt4/e4iSZSuF1W5/VCRURERHoJBYkiIiLS+zRXULV+NdOby4klUhgDs1bXM31xNVceOZxrjxrx1e6zdia8eCVs3Hp3aRsLF84fbepMiIjJoIUglSafWhNmsRlIP2sjObTitZIsYhhzsqfRaLJYXdcGgM9tcfre+Rw/LMCgMJicQVRVV2BvmMfGjKF8Fs0hP9NHaXaA95bX4nW7GN8/m/55GUzon5MOJtNiLbBhDvSfAt5AunhRRRMBr5uhhVk7931K77DkRXjhSnB7wR+GuuXEj/wl31myH7NW1VOWE6SqKcrkwXk8etGUrfuHiIiISA9TkCgiIiJ9RiSaIMvv2bGAJRmHBU9C1QJY877zvn4F2MmdasNauxCXZQgQJ0Q7fiuRPtdkMsgghtdKAdBufCwyg/hb8ii8pCi26imxGiix6snJCpIs2Iu8tlVUxQNUuoo5vumfZBOh2Z3DjIwjmJT4mHV2AT+MnMd6U8jho0ooywmwoaGd648dxaiSkMKmnpCMgcsLLheseAsWPQsHXgX5Q53TKZs3l1SzT6CSooGjnVB42Svw2NnA1n+cfjx5GKVWPTckvk8V+QD89/F7YVlw8vgyisKBra4RERER6QkKEkVERGTPk4xBe4Mz5dlOwer3nM1hkjFo3gCNa6F2OQRzIGcgqXgrqaWv4Kv/bNu3w0XKuNOhYouVRYZpw7XFjtJfV5PJ4OnUIaw1RRRajVSafN7OOJbzJuZy3CCLZGsjbpNgwIBBWIkoxFsg0QZlE5xNb/ZkxjjBsduZhr5u1TLW1zaTNBCqmYNJxshsXkl2y+e4/JmspYTaVBbReIzM1vUsdQ1jcLaLwfHPCNtNlDR8TMrlx+OycCci6Y9Z4R3Op76JrGmyOdY1k71ca2lxhYkcfQfFb1+HK9rArNA0ZmQewfHDsxjy4fW4U9H09a2hIVwUvIMZa9vSZWXZAf55yVT65WZ03/clIiIi8gUUJIqIiIh8Va21zo7UHj94M8CXCRl54Mtygqqq+U69sonO+ne1y+HTx5wNYHxZEC6DUCnV5LFi7XoymlfQ5g4RDnjIj62joGkRM0deR0HNhxS2fEa9lUN+y2fk0bTTTW4hyCzPJFK4aLW91NpZhH0Wew8owJuZjeUNYmcPwBXMIcvvIhpP0uTOxVs8ikH5mfi9blLJJHbDGnyBTAhkgzcIlkVbPElbPIXLsrBScdyR9eD2Ynn8kFVMU3uCfy+qpj2RoiWWZP8h+eRl+PB6LMpzgoS6cn3J+pUw9+8w+/8gFYdkO8abQdI2eFPtXfe5X2KtXcgR8d+TxIPP7eJbWXP5XvtD5PmShJL1ALQe/FNuWlzOqooakrjJsVooHz+N287ar0faLCIiIrIlBYkiIiIivZkxzqjJhU/Dgn864aUngFn2MlbMGQ1Xb0JErBBx2yLfaqKNAG3GT67VQqG1cyGkbSwMsMEUkGHFKLCa0+fieGi1QkRtCxc2CTyEaSVstaevXW8K2EgOAPPsYfwleTxV5KdHabrdbr4xvozv7pOFN5hJrKWJjGQjATdsbDe0WCGaPfk0NTdhN1dC7kCKmxcy1FOD5XLTWl9FZigbdzxCTcVaNpowFRTQ5CvG74ZLV16RXgPzP6WMRcLyEiDOas9gmtx5VHv7sd5dTqC9hmJvlPJAO163mzARMptXUukfQo2nlNGNb9PizuFB6xTWJXMoys7kpfpyyuMr+EPoMQq8MerCe1GW3EDtsFOpnP0CUxKzAPh14ts8aE6iOBxgQ6PzXfk8Lt6/4XCKlvwdXv6vbbY3ZrwkggXU5O/HksEXsNGEKS3IJS83l8EFmRRk+Xfq11hERERkRylIFBEREemLEu3OCMmsYvD4APi8JsLrS2pI2Yag102/bC8j69/CjlThxhCwW3FHG1heG6Uh0kJmqhmXnaAsVYHLJEkaC5dl0Y8qfHReQzJu3LgweKydn64dx5O+b7vxOQGk1faF9VPGwm19vT9+Xp/4PjPtvWg2GWRaUdzYfGfaflx4+FgsO+GMLt0R9qbnd3XsqhxP2jS2xbe5lmEsHqPp378lP7aWygN/RSArm3DAy8V//5i3l23kO1MH8otvjHV+PR84BqoXQyDsjHiNNmPHmr8wEP3EHsZSM5Cm/a9n3MhhZPk99M/LIMvvwefRrs8iIiKy6ylIFBEREZHOos3YbQ20pyBR8zkub4BE8d7UtNp4U2001m8kFqljUF6A8txMTDKK3d6MGXgAxuXFbloPTRuwWirxmQTMeQjWzfzSj0zhopEQGIPfSpJB+1YBWpuVwWJrGAaIuTIh0UqLFcKfW0qpO0JOsob8yNL01OWX976LN1PjWVzRzOJKZ0TlKfuU8cdvTeiKb22HxJM2H62sY/LgPAJed8cJY2CLDXQam5p47vW3qF2/knMjf6UgWYWHVKd7zbRHcWPiIqLGRw05JPFwwYGDuOWkMd31OCIiIrKHUJAoIiIiIl3LGGhaB5YLPEHAOJvBxNsgZ4Dz3pvZaZQf0WZnsxiX1xlxWbcCikanR186tzVb71q96j14+EQIl8NV88HtIZpIccwf32VtfRtPX3oAEwfkdstj73LGdGwcU7cc3rsDFj7VqUrKWMy092K+GcrUUf0ZEmwjI7IKly+AFe4HI44lmVHAyiZIuvykmquJxqLU500gw+8hw+fGNrBwQxPGgNdtEQ562W9QHsmUIcPvZk1dG5YFbbEUZTkBPlhRx4qaFgqyfAwtzGJseTbGQFlOAI+7F46MjLdCw2pIJZz+F8jp6HuphLMOajAX/FnOmqC9kDGGtniKpvYETe0JGtsS2MYwaVAufo+7c+UtdxnfJLLmUzasXExuyUCK8/OgYRUbc8bzzroEeY2LKMs0LM+YQL/cIBMG5GKMoTmaJDvYheuaiohIn6AgUURERER2L+vnOJvg5A1OF22MxKhqijKuX+8MhnbaJ4/AO7dDe6MTvNqJnbrNelNAxGSwypRQY3IIEmeFKaXWZNNMJhGTQYYV5WT3h6Rws8QewGIzkAqTT9x4qSR/q3tm+NyM75dDXpaPWCJFlt9DToaPUMBDImUoCvnJ8RmyknXE8RLHT9KTQSDZRGHjPHJbVmBl9yMY8JNMJqhvt2mK2gxJLMPj8eFOtuJrr8EK5uD2+vG0bcQySUz9KlK+bOxgPl47ihUIU5s1iqzauYQal+FrWd+pncZyEXdn0WZl4E22kGVaALBxUxsaRXugkE8SA5kTH0C9yWLAmAPZq38+o0tDDC7Iwu2ytnr2r8u2DRuqqgh7kmTHKqFpPUSbqK2rZcGKNSxq9HJP80EEiZNrRciiHR9J/HlljCjKwrIsvFaSCc3vcnjtIyRdPlYFxxHLG0lB3RwGtM7fbhs+t8t4w57AmuzJtKXczG8KsO+E/Thr8gDGlGUT9LqcYNvVC8NiERHpMgoSRURERER2B7YNtctIzvkb89bUUlHbSHs8xaepQXhIMtm1lKFWJTlWCxnECFhxPKRws/PrXm7W6C2i3ltCZrSKVCpFC0EiJkiLCdKGn/7WRkK00UYAFzYeUiTwUG7VErI6dtG2jYXra66L+VXUmyywXOTRvP3K/6HS5LHEHkAUHymXjxpXMYGsMINLixiQXIPbJLD7TSHpzaQ+OJCadhdVNTXsnZtgUPtCyCwm3tpIXdxDdfY4Mhb8ncxkI69lnMjbkTIG9evPmg3r+UvrVRRbjbv+4YGEcfOZ6U+R1UCAeKdfgy8z3x5Mlckj6Eqyn2sZKXeA6IBDyQ+6IVxG7diLWJXIZlRJqPOu7HYKXO5t37TiE5j5ZxhxDGQVOaMnV7xJZXUVa4qnsdgzmlDAw7x1jXyytpGB+Rn88pSx2mRIRHqMMYbPa1poak+QtA22bUgZQ8o2GAPF4QAjS0Jd8g9NvYGCRBERERGR3VhbPEltJI5lgdtl0Z5IMSAvA+/macdNG6B6kXO8YY4zddrlhtrlEG2EaDMm2gSxCHbJ3rhKxmHVLoOqBZiWakjFsczOh5EpXJ3CTBuLOncRaz2DcCfbSdkpjOUm6DFk08oSawgtJgMDVLmKccUjuO04dYRJpAzx0AACxAkmG2lNuihIVjPCU02ltz/v2eNYlCihNpVJNGHjJ07/QIwD+nkZkQP9w26qskZTG4Xsyg/JaF5BNJ5gnGs1Q1Kr8EbW4Uu17vSz7oxmE2SJGUizyaSZIMbl5STfJ/gTjU6FQDb4w6RwYSLVALjsOADtvjzW5Uzm46LTKYvMx9OwgjpvKQvzj+Xq0w7BtmHmqjp8VoKhiRX0GzQMK7MIZv8F6lfSFmnAteYDUm4/wZZ16V3Xv0jMeNhIDgYXNd4y/FaSMn+c3JblWL4syB0EhSMwQHMcYt5cCpY/gSse2eb9EsbNFYkf8po9uVP50MJM/vH9/SnI8uOy2HqJAxHZYy2vjrC0atu/p+yIeNJmUUUzsWTHusS2cTa2W1vfRnVz7EuvLw77+ejGI3fL358UJIqIiIiIyM6LNkHNEmhc64wo84chFtnipxmCeZDT31mf0OV2Rp2l4uAPQdlEZ4OZZAzaG5z1Cb1b74C9K8WSKRZVNGPbhn3653z1tRzjrbD6A2ipJhVvpa6uFru5mobGelKRjSy3yyhLrWdQYgU15DOCNQBE3Dm0Jw3LGYBlbJqtEGO9FQxOrqQqMBSPx0NRy5KtPu6uol8yy70PPn8QgHUNbfzPqeOY1C8TIlXOWqBuzzYeMALG3rVrPG5cBsunY3yZrGmIsSyWx/LKRjxr3qXZBDnV/QHDXRu+9sfEjIfX7YkUW41Mcn1GCheLrBGUeZpZN/AU7lldzoctpbTh9JHBBZmcOqGcQ0cUMrw4C4/LpV3Ld0DKNrQnUlQ1tdMSS5HpcxP0uQkFvF+6JqYxhvrWOK8srGJdQxtnTurPkILM3TI06cts27CxJeb8mvo9NLQl+LymBbfLoiDLR1lOsOMflfqoaCJFPOX8I8fauja+ed+HxJJff6T99vjcLkpzArhdFm7Lwu2ycFkWlgVr6trYp38Oj1w0pcvb0RMUJIqIiIiIiHSFZAywwOMjmbJxu6zOQcvmKb+pJKx6G4rHOSNCG50AkoEH9ESrd0hVU5TalhjxWJTy9qUUhfysWl9BtKmGVU2G5xfVsSRZho8kp7vfZZi1gVn2KMrdDZzneo05ZiTfjV1Hjh9c/hBVze0k8XD2pDL+x3Uv1vx/bvWZNhar7BKWm36sM4VETAbV5GJjsdQMIDcrk9y8PIIFg3G5XZRlB4gnbVrjKfbpn8OwoiyCXicwC3jdBL1uvG6rd4dg9SudzaRaNzrrobZuBE+Atkg9TS1R6jMHMy/vWBq9JbTGkjS1J8jP8oMxrK5rY3FlM+2bNugJeF3YxhmtHE18ceAyvCiLDJ+bWNImlrSJJ21iyRSxpE00kSKR6hwPDCnMZL+BeViWs3ym3+tiwoAcikMBoskU6xvayc/0M648m4DXRWHIn/7ObdtgbRpdGk/atCdStMdTBL1usjP2rE1+6lvjLKuKUN8aT39PLstiYH4GWX5njdlY0vm1zPR5CHjdbIzE+NeCSupbYwzMzwSgriXO47PXUtkUBZzga3Pgtllepo/RpWFSm6bmGmOoa40zcUAuR40uJjvoZXRZmHBg+78GbfEkKze2MqYsvFP/La1vaOOFTyuwbcMpE8rpl5vxpfWNMdz15ufc/ebnWz3XgLwMynK+3j9IWViMKM4iL7PzMgpFYT/Di7IYXhT6wr6Zsg2NbXHnv8HdkIJEERERERER6RKRaIKlVRH8HhdZfg8GJwDol5tBIBkh7gmxtqGdQfkZuF0WLy+ooj2R4psTy7GMgWUvQ9V8SEahZqlzHKn8Sp9dY3KoNdlE8VJnwtSZMC0EnWnguAgSpcrk00IA2/Jgub3EbBdBjyHPlyLizsZtWQSIk3AHaDQhvB43gz21+FJtxPGREcwAlwt/splAsplQopaceDWW24vbJPAnmvGnWogbNxsoIu4KEEsajMtNyIpS4mkhZFoxbi9N3kKSxkXcFaS8fSmBZAQfSVwmhdfe/jqWJ8V+xQIzZKd+nTJ8bnIzfLTFk7TGU8S/4oiuopCfcNDLmrrWrYLF7QkFPHhcFinb0BpP4doUQCbtjvu4XRb79M+hMMtPdtCL3+vC43LhcVt4XJt+3C7cLguv28LtcmGMYUNjO9XNUSLRJNFEiqTtrF+XSBlSto2FRW6ml3DAi8dtEU+aTcGqM7otvkV4Gk/axFM2ZdlBhhVn0dgWZ2MkhsuynOn1LovynACl2UGMAds4ozw3NLYTiSZxWzC4IIuynAAuyyKesp2gN9PHvHWNVDS243G7sG3D5xtbaGz74k2zXJYzvfbrGJCXgcFQ0xz7SiP3Mn1uhhVlkdy0/l9LLElNJEqmz0NhyE9jW4JQwENlU5SWWJLJg/M4aXwZmT5nXdTUpu9+84i91XWtfFYdweN2Mbo0zNq6Nupa43y0so6WWDL9nBMG5DIwP4PB+ZkMLw4RiSY4aXwZAa+bWDLFW0truOSRuVu1tzwnyLOXHUBRuGtHtu/JFCSKiIiIiIhI39Gy0QkU61Y4ozejTZhINal4G66ahZhUEisZxWWSPd3SXWq2PYKVdhnt+Kg3YXxWgggZFIf8jLDW8Wz5dbj9GWT4PIQDHja2xEmmbGwDx48rIT/LTyjgIZpI4XG5yPC5yfC5yfR78HtcnUaR1bbEmLumAbfLwu9x4/O48Htc+L0ufG4XAa+b/Cwffo8TFkWiCV74tILaSByXBS6XxcZIjMWVzdS3xvG4LPrlZlDV3M7SykinsPCL7IrQrK8alJ9BYchPJJqkuT1BPGVT2xLvVOc/v5/9h+QxojjEhoZ23C6L1niSUSVhrjlqBG7LorYlRk6GN70RUjJl897yWhra4unlHeJJm5ygl5cXVvJZdYTq5hgbI1++FuCuNLo0TFbAw6xV9ds8P7Y8zOCCLF5bWJUehXj25P78/OSx6Tq9fnTxbkBBooiIiIiIiOxeEu1QtdBZozPRBm11znTgWAuYFBiDcfuwG9djx9tJpeKYZALLTpLATcLy4mmvxbY8pNwB3PEI3kQzJOO0+XKJBktx2TGS8RiWSRH3hoh7s4n68mkNlhONx7DcfqxgNu7MPHKIEE41YOKtBLwejJ2klQxWtQeJkIVpqyNsIvjcFgWty6nOGE519j6sb07iM1FW1sdY5x3MgUPzycv04fe6aWiNc/y4EoYVhXr6294hxhhiSZs1dW1YFrgsiyy/B9s405szvB6CPme6+craVhZuaKK5PUFTe4J40iaxaYRbMmVI2jZJ25BM2elRh7aBsuwApdkBwkEvAa8bj8vCu2nkosdlkdq0xmMkmsQ2Bq/bCVYD3k2hqdtZa9MJUN24XRZr6lpZubGVvEwfxeEAtjHOtP6kzec1LelRlS7LwudxUZodICfDWdZgUUUzkWiClHECwJygl8qmKAUhPwcOLQAgZQxDCjLpn5exzfUpm6MJ2mIpvG5nFGdBlp+UMUQTKbybwt1dLWUbZq6sozXufC44088H5WfQFnemq2cHvc5I1liKkSVZPD13A8uqIiQ2BX2b1xCMJlM0tycZW55Nv9wgiZTNvHWNDMrPZGRJiKKQn0NHFOJxu1i16dd9bX0bs1fX8/ayjV/Yxr98ZxJHjS7e5c8uX0xBooiIiIiIiIiI9FrvL6/lyTnryMv08cnaRuatawTg01uO/tKNgWTX25F8bRvbgYmIiIiIiIiIiHSdg4YXcNBwZ/Tmwg1NnHrvB+w/JF8hYi+nIFFERERERERERHrM2PJs3vzRYeRm+nq6KbIdChJFRERERERERKRH9c/L6OkmyFfg6ukGiIiIiIiIiIiISO+nIFFERERERERERES2S0GiiIiIiIiIiIiIbJeCRBEREREREREREdkuBYkiIiIiIiIiIiKyXQoSRUREREREREREZLsUJIqIiIiIiIiIiMh2KUgUERERERERERGR7VKQKCIiIiIiIiIiItulIFFERERERERERES2S0GiiIiIiIiIiIiIbJeCRBEREREREREREdkuBYkiIiIiIiIiIiKyXQoSRUREREREREREZLsUJIqIiIiIiIiIiMh2KUgUERERERERERGR7VKQKCIiIiIiIiIiItulIFFERERERERERES2S0GiiIiIiIiIiIiIbJeCRBEREREREREREdkuBYkiIiIiIiIiIiKyXZ6ebsDXYYwBoLm5uYdbIiIiIiIiIiIi0vdsztU252xfpk8HiZFIBID+/fv3cEtERERERERERET6rkgkQnZ29pfWscxXiRt7Kdu2qaioIBQKYVlWTzenSzQ3N9O/f3/WrVtHOBzu6eaI7DD1Yenr1Ielr1Mflr5OfVh2B+rH0tepD+/ejDFEIhHKyspwub58FcQ+PSLR5XLRr1+/nm5GtwiHw/qPVfo09WHp69SHpa9TH5a+Tn1Ydgfqx9LXqQ/vvrY3EnEzbbYiIiIiIiIiIiIi26UgUURERERERERERLZLQWIv5/f7ueWWW/D7/T3dFJGdoj4sfZ36sPR16sPS16kPy+5A/Vj6OvVh2axPb7YiIiIiIiIiIiIi3UMjEkVERERERERERGS7FCSKiIiIiIiIiIjIdilIFBERERERERERke1SkCgiIiIiIiIiIiLbpSCxF7vnnnsYNGgQgUCAKVOmMGvWrJ5ukggAt956K/vttx+hUIiioiJOOeUUli1b1qlONBrl8ssvJz8/n6ysLL75zW9SXV3dqc7atWs54YQTyMjIoKioiOuuu45kMtmdjyICwG233YZlWVx99dXpMvVh6e02bNjAueeeS35+PsFgkHHjxvHxxx+nzxtjuPnmmyktLSUYDDJt2jSWL1/e6R719fWcc845hMNhcnJy+N73vkdLS0t3P4rsgVKpFDfddBODBw8mGAwydOhQfvnLX7LlPpDqw9LbvPvuu5x00kmUlZVhWRbPPfdcp/O7qs/Onz+fgw8+mEAgQP/+/bn99tu7+tFkD/FlfTiRSHDDDTcwbtw4MjMzKSsr4zvf+Q4VFRWd7qE+LAoSe6knnniCa6+9lltuuYW5c+cyfvx4jjnmGGpqanq6aSK88847XH755Xz00UdMnz6dRCLB0UcfTWtra7rONddcw4svvsiTTz7JO++8Q0VFBaeddlr6fCqV4oQTTiAej/Phhx/y8MMP89BDD3HzzTf3xCPJHmz27Nn86U9/Yu+99+5Urj4svVlDQwMHHnggXq+XV155hcWLF/P73/+e3NzcdJ3bb7+dO++8k/vvv5+ZM2eSmZnJMcccQzQaTdc555xzWLRoEdOnT+ell17i3Xff5eKLL+6JR5I9zG9+8xvuu+8+7r77bpYsWcJvfvMbbr/9du666650HfVh6W1aW1sZP34899xzzzbP74o+29zczNFHH83AgQOZM2cOv/3tb/nZz37Gn//85y5/Ptn9fVkfbmtrY+7cudx0003MnTuXZ555hmXLlnHyySd3qqc+LBjplSZPnmwuv/zy9PtUKmXKysrMrbfe2oOtEtm2mpoaA5h33nnHGGNMY2Oj8Xq95sknn0zXWbJkiQHMjBkzjDHGvPzyy8blcpmqqqp0nfvuu8+Ew2ETi8W69wFkjxWJRMzw4cPN9OnTzaGHHmquuuoqY4z6sPR+N9xwgznooIO+8Lxt26akpMT89re/TZc1NjYav99vHnvsMWOMMYsXLzaAmT17drrOK6+8YizLMhs2bOi6xosYY0444QRz4YUXdio77bTTzDnnnGOMUR+W3g8wzz77bPr9ruqz9957r8nNze30Z4kbbrjBjBw5soufSPY0/9mHt2XWrFkGMGvWrDHGqA+LQyMSe6F4PM6cOXOYNm1auszlcjFt2jRmzJjRgy0T2bampiYA8vLyAJgzZw6JRKJTHx41ahQDBgxI9+EZM2Ywbtw4iouL03WOOeYYmpubWbRoUTe2XvZkl19+OSeccEKnvgrqw9L7vfDCC0yaNIkzzjiDoqIiJkyYwF/+8pf0+VWrVlFVVdWpD2dnZzNlypROfTgnJ4dJkyal60ybNg2Xy8XMmTO772Fkj3TAAQfwxhtv8NlnnwHw6aef8v7773PccccB6sPS9+yqPjtjxgwOOeQQfD5fus4xxxzDsmXLaGho6KanEXE0NTVhWRY5OTmA+rA4PD3dANlabW0tqVSq019OAYqLi1m6dGkPtUpk22zb5uqrr+bAAw9k7NixAFRVVeHz+dL/w9msuLiYqqqqdJ1t9fHN50S62uOPP87cuXOZPXv2VufUh6W3W7lyJffddx/XXnstP/nJT5g9ezZXXnklPp+P888/P90Ht9VHt+zDRUVFnc57PB7y8vLUh6XL/fjHP6a5uZlRo0bhdrtJpVL8+te/5pxzzgFQH5Y+Z1f12aqqKgYPHrzVPTaf23IJC5GuFI1GueGGGzj77LMJh8OA+rA4FCSKyNdy+eWXs3DhQt5///2eborIV7Zu3Tquuuoqpk+fTiAQ6OnmiOww27aZNGkS//M//wPAhAkTWLhwIffffz/nn39+D7dOZPv++c9/8uijj/KPf/yDMWPGMG/ePK6++mrKysrUh0VEelgikeDMM8/EGMN9993X082RXkZTm3uhgoIC3G73VruDVldXU1JS0kOtEtnaFVdcwUsvvcRbb71Fv3790uUlJSXE43EaGxs71d+yD5eUlGyzj28+J9KV5syZQ01NDRMnTsTj8eDxeHjnnXe488478Xg8FBcXqw9Lr1ZaWsro0aM7le21116sXbsW6OiDX/ZniZKSkq02cUsmk9TX16sPS5e77rrr+PGPf8y3vvUtxo0bx3nnncc111zDrbfeCqgPS9+zq/qs/nwhPW1ziLhmzRqmT5+eHo0I6sPiUJDYC/l8Pvbdd1/eeOONdJlt27zxxhtMnTq1B1sm4jDGcMUVV/Dss8/y5ptvbjV0fd9998Xr9Xbqw8uWLWPt2rXpPjx16lQWLFjQ6X9Em/9H9Z9/ORbZ1Y488kgWLFjAvHnz0j+TJk3inHPOSR+rD0tvduCBB7Js2bJOZZ999hkDBw4EYPDgwZSUlHTqw83NzcycObNTH25sbGTOnDnpOm+++Sa2bTNlypRueArZk7W1teFydf6riNvtxrZtQH1Y+p5d1WenTp3Ku+++SyKRSNeZPn06I0eO1JRQ6XKbQ8Tly5fz+uuvk5+f3+m8+rAA2rW5t3r88ceN3+83Dz30kFm8eLG5+OKLTU5OTqfdQUV6yqWXXmqys7PN22+/bSorK9M/bW1t6TqXXHKJGTBggHnzzTfNxx9/bKZOnWqmTp2aPp9MJs3YsWPN0UcfbebNm2deffVVU1hYaG688caeeCSRTrs2G6M+LL3brFmzjMfjMb/+9a/N8uXLzaOPPmoyMjLMI488kq5z2223mZycHPP888+b+fPnm2984xtm8ODBpr29PV3n2GOPNRMmTDAzZ84077//vhk+fLg5++yze+KRZA9z/vnnm/LycvPSSy+ZVatWmWeeecYUFBSY66+/Pl1HfVh6m0gkYj755BPzySefGMDccccd5pNPPknvaLsr+mxjY6MpLi425513nlm4cKF5/PHHTUZGhvnTn/7U7c8ru58v68PxeNycfPLJpl+/fmbevHmd/p635Q7M6sOiILEXu+uuu8yAAQOMz+czkydPNh999FFPN0nEGGMMsM2fBx98MF2nvb3dXHbZZSY3N9dkZGSYU0891VRWVna6z+rVq81xxx1ngsGgKSgoMD/60Y9MIpHo5qcRcfxnkKg+LL3diy++aMaOHWv8fr8ZNWqU+fOf/9zpvG3b5qabbjLFxcXG7/ebI4880ixbtqxTnbq6OnP22WebrKwsEw6HzQUXXGAikUh3PobsoZqbm81VV11lBgwYYAKBgBkyZIj57//+705/WVUflt7mrbfe2uafgc8//3xjzK7rs59++qk56KCDjN/vN+Xl5ea2227rrkeU3dyX9eFVq1Z94d/z3nrrrfQ91IfFMsaY7hv/KCIiIiIiIiIiIn2R1kgUERERERERERGR7VKQKCIiIiIiIiIiItulIFFERERERERERES2S0GiiIiIiIiIiIiIbJeCRBEREREREREREdkuBYkiIiIiIiIiIiKyXQoSRUREREREREREZLsUJIqIiIiIiIiIiMh2KUgUERERERERERGR7VKQKCIiIiJf6rvf/S6WZWFZFl6vl+LiYo466igeeOABbNvu6eaJiIiISDdRkCgiIiIi23XsscdSWVnJ6tWreeWVVzj88MO56qqrOPHEE0kmkz3dPBERERHpBgoSRURERGS7/H4/JSUllJeXM3HiRH7yk5/w/PPP88orr/DQQw8BcMcddzBu3DgyMzPp378/l112GS0tLQC0trYSDod56qmnOt33ueeeIzMzk0gkQjwe54orrqC0tJRAIMDAgQO59dZbu/tRRUREROQLKEgUERERkZ1yxBFHMH78eJ555hkAXC4Xd955J4sWLeLhhx/mzTff5PrrrwcgMzOTb33rWzz44IOd7vHggw9y+umnEwqFuPPOO3nhhRf45z//ybJly3j00UcZNGhQdz+WiIiIiHwBT083QERERET6rlGjRjF//nwArr766nT5oEGD+NWvfsUll1zCvffeC8BFF13EAQccQGVlJaWlpdTU1PDyyy/z+uuvA7B27VqGDx/OQQcdhGVZDBw4sNufR0RERES+mEYkioiIiMhOM8ZgWRYAr7/+OkceeSTl5eWEQiHOO+886urqaGtrA2Dy5MmMGTOGhx9+GIBHHnmEgQMHcsghhwDOpi7z5s1j5MiRXHnllfz73//umYcSERERkW1SkCgiIiIiO23JkiUMHjyY1atXc+KJJ7L33nvz9NNPM2fOHO655x4A4vF4uv5FF12UXlPxwQcf5IILLkgHkRMnTmTVqlX88pe/pL29nTPPPJPTTz+9259JRERERLZNQaKIiIiI7JQ333yTBQsW8M1vfpM5c+Zg2za///3v2X///RkxYgQVFRVbXXPuueeyZs0a7rzzThYvXsz555/f6Xw4HOass87iL3/5C0888QRPP/009fX13fVIIiIiIvIltEaiiIiIiGxXLBajqqqKVCpFdXU1r776Krfeeisnnngi3/nOd1i4cCGJRIK77rqLk046iQ8++ID7779/q/vk5uZy2mmncd1113H00UfTr1+/9Lk77riD0tJSJkyYgMvl4sknn6SkpIScnJxufFIRERER+SIakSgiIiIi2/Xqq69SWlrKoEGDOPbYY3nrrbe48847ef7553G73YwfP5477riD3/zmN4wdO5ZHH32UW2+9dZv3+t73vkc8HufCCy/sVB4Khbj99tuZNGkS++23H6tXr+bll1/G5dIfWUVERER6A8sYY3q6ESIiIiKy5/j73//ONddcQ0VFBT6fr6ebIyIiIiJfkaY2i4iIiEi3aGtro7Kykttuu40f/OAHChFFRERE+hjNExERERGRbnH77bczatQoSkpKuPHGG3u6OSIiIiKygzS1WURERERERERERLZLIxJFRERERERERERkuxQkioiIiIiIiIiIyHYpSBQREREREREREZHtUpAoIiIiIiIiIiIi26UgUURERERERERERLZLQaKIiIiIiIiIiIhsl4JEERERERERERER2S4FiSIiIiIiIiIiIrJd/w/WkTJtqbRVywAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vamos tentar reduzir novamente o numero de hidden layers para ver se mantemos o desempenho ou se perdemos para achar o melhor nmero , teste 3\n",
        "batch_size = 7\n",
        "window_size = 7\n",
        "hidden_layer = 64\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGVn6FBq7ZgD",
        "outputId": "35037561-4345-4b63-c021-0d61007c5899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_511:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_575:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_639:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_703:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_767:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_831:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_895:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 20) == 0:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6cIHISv7ll7",
        "outputId": "256ce00d-1397-4a01-d9d0-94ad116a453e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200  Current loss: 0.7285171747207642\n",
            "Epoch 20/200  Current loss: 0.05411476641893387\n",
            "Epoch 40/200  Current loss: 0.022409193217754364\n",
            "Epoch 60/200  Current loss: 0.012141343206167221\n",
            "Epoch 80/200  Current loss: 0.00822270754724741\n",
            "Epoch 100/200  Current loss: 0.007968599908053875\n",
            "Epoch 120/200  Current loss: 0.007092914078384638\n",
            "Epoch 140/200  Current loss: 0.006668785121291876\n",
            "Epoch 160/200  Current loss: 0.006255833897739649\n",
            "Epoch 180/200  Current loss: 0.0075666289776563644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No conseguimos manter o desempenho reduzindo novamente o nmero de hidden layers, portanto vamos manter o nmero em 128 por enquanto\n"
      ],
      "metadata": {
        "id": "SKZFRbeD9n6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#agora com o nmero de hidden layers 'definido' vamos tentar mudar os outros parametros, comecando pelo batch size, onde vamos tentar usar o tamanho de 16 -- teste 4\n",
        "batch_size = 16\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLFD-8IT9y7Y",
        "outputId": "31a95db0-c9cc-418e-c859-0938e546ae84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_959:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1023:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1087:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1151:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1215:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1279:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1343:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1407:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1471:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1535:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1599:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1663:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1727:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1791:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1855:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1919:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 20) == 0 or i==200:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaLDgb-W-QWP",
        "outputId": "b415a5c2-aff2-40a0-acf5-889dff55b2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200  Current loss: 0.8260537981987\n",
            "Epoch 20/200  Current loss: 0.04319222643971443\n",
            "Epoch 40/200  Current loss: 0.02964189276099205\n",
            "Epoch 60/200  Current loss: 0.016091015189886093\n",
            "Epoch 80/200  Current loss: 0.00890293624252081\n",
            "Epoch 100/200  Current loss: 0.015562673099339008\n",
            "Epoch 120/200  Current loss: 0.007484846748411655\n",
            "Epoch 140/200  Current loss: 0.007151931989938021\n",
            "Epoch 160/200  Current loss: 0.007605182006955147\n",
            "Epoch 180/200  Current loss: 0.009730782359838486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aps tentar aumentar o batch size, os resultados de perda foram ruins, no conseguindo chegar a uma loss minma e variando muito, por isso tentaremos diminuir o tamanho do batch size."
      ],
      "metadata": {
        "id": "lSIwwzvJ_-AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#agora com o nmero de hidden layers 'definido' vamos tentar mudar os outros parametros, comecando pelo batch size, onde vamos tentar usar o tamanho de 5 -- teste 5\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JB5WY_jAI2O",
        "outputId": "95950019-402c-4d6d-eef7-fc940afab214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_1983:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2047:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2111:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2175:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2239:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 20) == 0 or i==199:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW27pfYGAUPW",
        "outputId": "e0945f70-fbd0-4791-e4de-8eefcb53513f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200  Current loss: 0.29435527324676514\n",
            "Epoch 20/200  Current loss: 0.04540400579571724\n",
            "Epoch 40/200  Current loss: 0.01558215543627739\n",
            "Epoch 60/200  Current loss: 0.009760619141161442\n",
            "Epoch 80/200  Current loss: 0.008118699304759502\n",
            "Epoch 100/200  Current loss: 0.0066260420717298985\n",
            "Epoch 120/200  Current loss: 0.006298711057752371\n",
            "Epoch 140/200  Current loss: 0.006306991912424564\n",
            "Epoch 160/200  Current loss: 0.006017967592924833\n",
            "Epoch 180/200  Current loss: 0.005164982285350561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conseguimos melhorar o desempenho alcanando um novo melhor resultado, a partir de agora manteremos por enquanto o batch size em 5. Vale notar que a partir de agora vamos printar a epoca 199 que no estava sendo printada. Por isso, vou repetir o ltimo teste para ter resultados verdadeiros.\n"
      ],
      "metadata": {
        "id": "FW8vkE5CBjlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#agora com o nmero de hidden layers 'definido' vamos tentar mudar os outros parametros, comecando pelo batch size, onde vamos tentar usar o tamanho de 5 -- teste 6\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qU4AaetCCkR",
        "outputId": "07dbedac-1fd0-4506-abc0-536249e800c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_2303:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2367:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2431:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2495:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2559:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 20) == 0 or i==199:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e07vJSjECFtw",
        "outputId": "d39bba8a-4d7b-4483-d852-3c68d73ce252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200  Current loss: 0.28863516449928284\n",
            "Epoch 20/200  Current loss: 0.03301073983311653\n",
            "Epoch 40/200  Current loss: 0.01443031057715416\n",
            "Epoch 60/200  Current loss: 0.010835405439138412\n",
            "Epoch 80/200  Current loss: 0.00910954363644123\n",
            "Epoch 100/200  Current loss: 0.007439804263412952\n",
            "Epoch 120/200  Current loss: 0.006682157516479492\n",
            "Epoch 140/200  Current loss: 0.00613526301458478\n",
            "Epoch 160/200  Current loss: 0.0056292470544576645\n",
            "Epoch 180/200  Current loss: 0.005797896068543196\n",
            "Epoch 199/200  Current loss: 0.005728010553866625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pronto, agora iremos tentar alterar a widowsize, comeando diminuindo para 3 dias para conseguir prever pequenos ajustes nos preos"
      ],
      "metadata": {
        "id": "HhECWnRgDlYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#agora com o nmero de hidden layers 'definido' vamos tentar mudar os outros parametros, mudando widow size para 3 -- teste 7\n",
        "batch_size = 5\n",
        "window_size = 3\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN7Ct2YXDsqJ",
        "outputId": "8e41bc41-8428-4a6b-ca70-b4c65c9e739c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_2587:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2615:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2643:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2671:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2699:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data(data, window_size): #mudando o widow size para 3\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    i = 0\n",
        "    while (i + window_size) <= len(data) - 1:\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size])\n",
        "\n",
        "        i += 1\n",
        "    assert len(X) ==  len(y)\n",
        "    return X, y\n",
        "#windowing the data with window_data function\n",
        "X, y = window_data(scaled_data, 3)\n",
        "\n",
        "\n",
        "#we now split the data into training and test set\n",
        "import numpy as np\n",
        "X_train  = np.array(X[:1018])\n",
        "y_train = np.array(y[:1018])\n",
        "\n",
        "X_test = np.array(X[1018:])\n",
        "y_test = np.array(y[1018:])\n",
        "\n",
        "print(\"X_train size: {}\".format(X_train.shape))\n",
        "print(\"y_train size: {}\".format(y_train.shape))\n",
        "print(\"X_test size: {}\".format(X_test.shape))\n",
        "print(\"y_test size: {}\".format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO-0sAUNEVH5",
        "outputId": "018c718b-ee83-4565-964c-38bf39ba6585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (1018, 3, 1)\n",
            "y_train size: (1018, 1)\n",
            "X_test size: (252, 3, 1)\n",
            "y_test size: (252, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 20) == 0 or i==199:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S_HVD0DDv8h",
        "outputId": "5687f19f-e6f3-4372-a6fb-c0021c3c33e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200  Current loss: 0.34375882148742676\n",
            "Epoch 20/200  Current loss: 0.02954321913421154\n",
            "Epoch 40/200  Current loss: 0.023292524740099907\n",
            "Epoch 60/200  Current loss: 0.015191330574452877\n",
            "Epoch 80/200  Current loss: 0.011132189072668552\n",
            "Epoch 100/200  Current loss: 0.009063535369932652\n",
            "Epoch 120/200  Current loss: 0.008203229866921902\n",
            "Epoch 140/200  Current loss: 0.007874662056565285\n",
            "Epoch 160/200  Current loss: 0.0075427088886499405\n",
            "Epoch 180/200  Current loss: 0.007334374822676182\n",
            "Epoch 199/200  Current loss: 0.0071278964169323444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No obtivemos resultado bom diminuindo a widowsize, agora tentaremos aumenta-l para 30 dias"
      ],
      "metadata": {
        "id": "pQe4Pcu4FXfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mudando widow size para 30 -- teste 8\n",
        "batch_size = 5\n",
        "window_size = 30\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3UGzsqUFhnR",
        "outputId": "4fc91fdc-ca3e-46cc-a0fb-01bafa890cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_2970:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_3241:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_3512:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_3783:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_4054:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data(data, window_size): #mudando o widow size para 30\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    i = 0\n",
        "    while (i + window_size) <= len(data) - 1:\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size])\n",
        "\n",
        "        i += 1\n",
        "    assert len(X) ==  len(y)\n",
        "    return X, y\n",
        "#windowing the data with window_data function\n",
        "X, y = window_data(scaled_data, 30)\n",
        "\n",
        "\n",
        "#we now split the data into training and test set\n",
        "import numpy as np\n",
        "X_train  = np.array(X[:1018])\n",
        "y_train = np.array(y[:1018])\n",
        "\n",
        "X_test = np.array(X[1018:])\n",
        "y_test = np.array(y[1018:])\n",
        "\n",
        "print(\"X_train size: {}\".format(X_train.shape))\n",
        "print(\"y_train size: {}\".format(y_train.shape))\n",
        "print(\"X_test size: {}\".format(X_test.shape))\n",
        "print(\"y_test size: {}\".format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIdEzUjDFmVp",
        "outputId": "85db23b2-04d3-48b2-fecc-4b683435859e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (1018, 30, 1)\n",
            "y_train size: (1018, 1)\n",
            "X_test size: (225, 30, 1)\n",
            "y_test size: (225, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 20) == 0 or i==199:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SC_dEwnFo3p",
        "outputId": "f448b820-1c04-436d-8059-0b33d7bff488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200  Current loss: 0.416760116815567\n",
            "Epoch 20/200  Current loss: 0.20618188381195068\n",
            "Epoch 40/200  Current loss: 0.01672408916056156\n",
            "Epoch 60/200  Current loss: 0.03689922019839287\n",
            "Epoch 80/200  Current loss: 0.015921564772725105\n",
            "Epoch 100/200  Current loss: 0.009797337464988232\n",
            "Epoch 120/200  Current loss: 0.01157499197870493\n",
            "Epoch 140/200  Current loss: 0.008211509324610233\n",
            "Epoch 160/200  Current loss: 0.008687487803399563\n",
            "Epoch 180/200  Current loss: 0.007675998844206333\n",
            "Epoch 199/200  Current loss: 0.007532231509685516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado no foi satisfatrio. Apresentando grande varao entre as pocas e gerando um custo de processamento maior por levar em conta 30 dias, agora vamos testar com 14, caso o resultado tambm no seja satisfatrio, voltaremos a 7"
      ],
      "metadata": {
        "id": "xjwM9opiJRXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando widow size para 14 -- teste 9\n",
        "batch_size = 5\n",
        "window_size = 14\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEwWHsHrJl1Y",
        "outputId": "f5f40578-f31c-4596-a59c-8a1591280cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_4181:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_4308:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_4435:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_4562:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_4689:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data(data, window_size): #mudando o widow size para 14\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    i = 0\n",
        "    while (i + window_size) <= len(data) - 1:\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size])\n",
        "\n",
        "        i += 1\n",
        "    assert len(X) ==  len(y)\n",
        "    return X, y\n",
        "#windowing the data with window_data function\n",
        "X, y = window_data(scaled_data, 14)\n",
        "\n",
        "\n",
        "#we now split the data into training and test set\n",
        "import numpy as np\n",
        "X_train  = np.array(X[:1018])\n",
        "y_train = np.array(y[:1018])\n",
        "\n",
        "X_test = np.array(X[1018:])\n",
        "y_test = np.array(y[1018:])\n",
        "\n",
        "print(\"X_train size: {}\".format(X_train.shape))\n",
        "print(\"y_train size: {}\".format(y_train.shape))\n",
        "print(\"X_test size: {}\".format(X_test.shape))\n",
        "print(\"y_test size: {}\".format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auhINUBJJw6p",
        "outputId": "f94de340-1d7e-48ef-968a-d5aebe3e2943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (1018, 14, 1)\n",
            "y_train size: (1018, 1)\n",
            "X_test size: (241, 14, 1)\n",
            "y_test size: (241, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 20) == 0 or i==199:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPK2Dcw3KAG4",
        "outputId": "836c723d-8b2c-438d-fb0f-765088a2afe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200  Current loss: 0.44188275933265686\n",
            "Epoch 20/200  Current loss: 0.38765084743499756\n",
            "Epoch 40/200  Current loss: 0.7747215032577515\n",
            "Epoch 60/200  Current loss: 0.013700900599360466\n",
            "Epoch 80/200  Current loss: 0.010259026661515236\n",
            "Epoch 100/200  Current loss: 0.008715693838894367\n",
            "Epoch 120/200  Current loss: 0.007492117118090391\n",
            "Epoch 140/200  Current loss: 0.007684154435992241\n",
            "Epoch 160/200  Current loss: 0.00716098677366972\n",
            "Epoch 180/200  Current loss: 0.006164308171719313\n",
            "Epoch 199/200  Current loss: 0.006595658138394356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado tambm no foi dos melhores, iremos realizar um ltimo teste na widow size, agora com valor de 5 para ver se obtemos alguma melhora, se no, seguiremos para outros parametros"
      ],
      "metadata": {
        "id": "0UXhziUnOBUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando widow size para 5 -- teste 10\n",
        "batch_size = 5\n",
        "window_size = 5\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSSq-u8dOKeT",
        "outputId": "748d3ed1-b727-457e-e43b-2f3c7b8eb0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_4735:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_4781:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_4827:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_4873:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_4919:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data(data, window_size): #mudando o widow size para 5\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    i = 0\n",
        "    while (i + window_size) <= len(data) - 1:\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size])\n",
        "\n",
        "        i += 1\n",
        "    assert len(X) ==  len(y)\n",
        "    return X, y\n",
        "#windowing the data with window_data function\n",
        "X, y = window_data(scaled_data, 5)\n",
        "\n",
        "\n",
        "#we now split the data into training and test set\n",
        "import numpy as np\n",
        "X_train  = np.array(X[:1018])\n",
        "y_train = np.array(y[:1018])\n",
        "\n",
        "X_test = np.array(X[1018:])\n",
        "y_test = np.array(y[1018:])\n",
        "\n",
        "print(\"X_train size: {}\".format(X_train.shape))\n",
        "print(\"y_train size: {}\".format(y_train.shape))\n",
        "print(\"X_test size: {}\".format(X_test.shape))\n",
        "print(\"y_test size: {}\".format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zSYiDN_OPEi",
        "outputId": "a255ebf2-5f35-4f92-b178-baace1d712f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (1018, 5, 1)\n",
            "y_train size: (1018, 1)\n",
            "X_test size: (250, 5, 1)\n",
            "y_test size: (250, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 20) == 0 or i==199:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFeifcAKOTQy",
        "outputId": "f1608b22-9a26-4b76-cefa-ac1874e4a7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/200  Current loss: 0.24285578727722168\n",
            "Epoch 20/200  Current loss: 0.04620243236422539\n",
            "Epoch 40/200  Current loss: 0.02285032346844673\n",
            "Epoch 60/200  Current loss: 0.012482931837439537\n",
            "Epoch 80/200  Current loss: 0.009845415130257607\n",
            "Epoch 100/200  Current loss: 0.008673902601003647\n",
            "Epoch 120/200  Current loss: 0.00795407872647047\n",
            "Epoch 140/200  Current loss: 0.007552572060376406\n",
            "Epoch 160/200  Current loss: 0.007214440498501062\n",
            "Epoch 180/200  Current loss: 0.006904201116412878\n",
            "Epoch 199/200  Current loss: 0.006760466378182173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado ainda foi inferior  widow size de 7, portanto vamos tomar ela como 7 mesmo. Vale notar que estamos presos em um current loss entre 0.005 e 0.006, vamos tentar mudar o learning rate e nmero de pocas agora\n"
      ],
      "metadata": {
        "id": "tKHYOVKnPQ6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando learning rate para 0.0005 e 300 epocas -- teste 11\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.0005\n",
        "epochs = 300\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFrhMdisPqKl",
        "outputId": "95155776-64ee-44b0-b2ef-43fa08975472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_5213:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_5277:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_5341:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_5405:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_5469:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data(data, window_size):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    i = 0\n",
        "    while (i + window_size) <= len(data) - 1:\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size])\n",
        "\n",
        "        i += 1\n",
        "    assert len(X) ==  len(y)\n",
        "    return X, y\n",
        "#windowing the data with window_data function\n",
        "X, y = window_data(scaled_data, 7)\n",
        "\n",
        "\n",
        "#we now split the data into training and test set\n",
        "import numpy as np\n",
        "X_train  = np.array(X[:1018])\n",
        "y_train = np.array(y[:1018])\n",
        "\n",
        "X_test = np.array(X[1018:])\n",
        "y_test = np.array(y[1018:])\n",
        "\n",
        "print(\"X_train size: {}\".format(X_train.shape))\n",
        "print(\"y_train size: {}\".format(y_train.shape))\n",
        "print(\"X_test size: {}\".format(X_test.shape))\n",
        "print(\"y_test size: {}\".format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwiYczYxPu2x",
        "outputId": "339290d2-89df-47cf-e105-4ae8fe20b47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (1018, 7, 1)\n",
            "y_train size: (1018, 1)\n",
            "X_test size: (248, 7, 1)\n",
            "y_test size: (248, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 30) == 0 or i==299:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWNJK2TjQgNs",
        "outputId": "63cf3e21-23e2-4650-cb59-ec6a6006d46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/300  Current loss: 0.575018048286438\n",
            "Epoch 30/300  Current loss: 0.03449414297938347\n",
            "Epoch 60/300  Current loss: 0.016268255189061165\n",
            "Epoch 90/300  Current loss: 0.010464824736118317\n",
            "Epoch 120/300  Current loss: 0.007275812793523073\n",
            "Epoch 150/300  Current loss: 0.006670705042779446\n",
            "Epoch 180/300  Current loss: 0.006188875529915094\n",
            "Epoch 210/300  Current loss: 0.006314788479357958\n",
            "Epoch 240/300  Current loss: 0.0051803989335894585\n",
            "Epoch 270/300  Current loss: 0.0053329565562307835\n",
            "Epoch 299/300  Current loss: 0.004499213770031929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conseguimos um bom resultado, apesar de aumentar o custo computacional, conseguimos chegar em 0.004, vamos tentar abaixar o learning rate e aumentar as epocas mais uma vez para ver se conseguimos melhorar ainda mais"
      ],
      "metadata": {
        "id": "ahrSxLPLSnMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando learning rate para 0.0001 e 400 epocas -- teste 12\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.0001\n",
        "epochs = 400\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFbNpPZtS21Z",
        "outputId": "62bf601d-4795-4cad-e1cd-1d8eb0938191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_5533:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_5597:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_5661:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_5725:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_5789:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 40) == 0 or i==399:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYc6qLG2S7Hx",
        "outputId": "24fc3e73-5a6d-4cb1-baaf-40633e38bf01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/400  Current loss: 1.0669338703155518\n",
            "Epoch 40/400  Current loss: 0.034290362149477005\n",
            "Epoch 80/400  Current loss: 0.02073126845061779\n",
            "Epoch 120/400  Current loss: 0.01394751388579607\n",
            "Epoch 160/400  Current loss: 0.010303928516805172\n",
            "Epoch 200/400  Current loss: 0.008055229671299458\n",
            "Epoch 240/400  Current loss: 0.007267606444656849\n",
            "Epoch 280/400  Current loss: 0.006805751007050276\n",
            "Epoch 320/400  Current loss: 0.0062682670541107655\n",
            "Epoch 360/400  Current loss: 0.005984218325465918\n",
            "Epoch 399/400  Current loss: 0.005733234342187643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a taxa de aprendizado de 0.0001 nao se provou boa, agora vamos tentar usar a de 0.0005"
      ],
      "metadata": {
        "id": "4I0FzbkhVkyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando learning rate para 0.0005 e 400 epocas -- teste 13\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.0005\n",
        "epochs = 400\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-b6NoAbqnZH",
        "outputId": "4adab945-b272-4a42-a6e8-30f0d028ea41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_63:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_127:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_191:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_255:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_319:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 40) == 0 or i==399:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXq0geBQquNX",
        "outputId": "9ab1480d-bcdd-4fbd-ab96-99a282d01998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/400  Current loss: 0.5720178484916687\n",
            "Epoch 40/400  Current loss: 0.03304370492696762\n",
            "Epoch 80/400  Current loss: 0.011326165869832039\n",
            "Epoch 120/400  Current loss: 0.007650713436305523\n",
            "Epoch 160/400  Current loss: 0.006719676777720451\n",
            "Epoch 200/400  Current loss: 0.005778108723461628\n",
            "Epoch 240/400  Current loss: 0.0053559476509690285\n",
            "Epoch 280/400  Current loss: 0.005098922643810511\n",
            "Epoch 320/400  Current loss: 0.004371023736894131\n",
            "Epoch 360/400  Current loss: 0.0037951425183564425\n",
            "Epoch 399/400  Current loss: 0.0040424894541502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conseguimos um resultado bom na poca 360 e depois regredimos, vamos tentar o mesmo exemplo mas agora com 500 pocas, caso no prove utilidade, tentaremos colocar pocas entre 300-400\n"
      ],
      "metadata": {
        "id": "4OO2kKjgxR_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando learning rate para 0.0005 e 500 epocas -- teste 14\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.0005\n",
        "epochs = 500\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0EQw7Jzxirq",
        "outputId": "e39593c5-eef1-44ad-85c8-37f19ba048b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_383:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_447:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_511:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_575:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_639:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 50) == 0 or i==499:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHXORAg6xn4C",
        "outputId": "e034084f-9669-4a23-f01f-694fad5f49cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/500  Current loss: 0.5122868418693542\n",
            "Epoch 50/500  Current loss: 0.016774121671915054\n",
            "Epoch 100/500  Current loss: 0.007560082711279392\n",
            "Epoch 150/500  Current loss: 0.0062993718311190605\n",
            "Epoch 200/500  Current loss: 0.00566638121381402\n",
            "Epoch 250/500  Current loss: 0.004904218018054962\n",
            "Epoch 300/500  Current loss: 0.006049328949302435\n",
            "Epoch 350/500  Current loss: 0.0052979509346187115\n",
            "Epoch 400/500  Current loss: 0.004385064821690321\n",
            "Epoch 450/500  Current loss: 0.00308659253641963\n",
            "Epoch 499/500  Current loss: 0.003917569760233164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois de varias variaes da loss nas pocas, na ltima bateria conseguimos atingir um valor recorde de 0.003, vamos tentar diminur o nmero de pocas e aumentar suavemente a learning rate, tentando buscar essa loss alcanada sem todas essas variaes que aconteceram\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "btwzaaju3nGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando learning rate para 0.001 e 300 epocas -- teste 15 -- teste meio aleatrio, para tentar entender melhor como a learning rate e as epocas esto se comportando\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.001\n",
        "epochs = 300\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLvdLlTQtM11",
        "outputId": "b34183ff-c3f6-4f1b-a843-5278e8c4f727"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_63:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_127:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_191:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_255:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_319:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 50) == 0 or i==299:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqR9bNr2tZl3",
        "outputId": "89eb0977-178a-43bb-ea37-9200beafcd47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/300  Current loss: 0.2886889576911926\n",
            "Epoch 50/300  Current loss: 0.011186820454895496\n",
            "Epoch 100/300  Current loss: 0.0066604274325072765\n",
            "Epoch 150/300  Current loss: 0.005322591867297888\n",
            "Epoch 200/300  Current loss: 0.006463708356022835\n",
            "Epoch 250/300  Current loss: 0.0058747255243361\n",
            "Epoch 299/300  Current loss: 0.004366373643279076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como esperado o resultado no foi bom, chegando ao final dos testes com a learning rate, tentaremos agora usar a de 0.0005 com 300 epcas, ja que ela foi a que conseguiu o melhor resultado e o nico problema foi uma titubincia nas epcas finais"
      ],
      "metadata": {
        "id": "co9-0L_jx9q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando learning rate para 0.0005 e 300 epocas -- teste 16\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.0005\n",
        "epochs = 300\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1p8tmr0yP3I",
        "outputId": "24d53315-d53e-4989-8f60-fb88f328c74b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_703:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_767:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_831:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_895:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_959:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 50) == 0 or i==299:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvhBXL6XzS3E",
        "outputId": "b6d5b487-e704-411a-d865-1858c6367ab8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/300  Current loss: 0.5519399642944336\n",
            "Epoch 50/300  Current loss: 0.018847305327653885\n",
            "Epoch 100/300  Current loss: 0.008729160763323307\n",
            "Epoch 150/300  Current loss: 0.006603132467716932\n",
            "Epoch 200/300  Current loss: 0.0059548974968492985\n",
            "Epoch 250/300  Current loss: 0.0051090833730995655\n",
            "Epoch 299/300  Current loss: 0.004254874773323536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como observado anteriormente, a taxa de learning de 0.0005 demora mais a aprender, assim dificultando que em 300 pocas apresente resultado timo, como o nosso melhor resultado saiu na poca 450/500 em uns testes atras, vamos tentar agora com 450 pocas. Tambm iremos arriscar uma mudana sutil na taxa, sendo agora 0.0004"
      ],
      "metadata": {
        "id": "tfTR2f5X3xFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando learning rate para 0.0004 e 450 epocas -- teste 17\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.0004\n",
        "epochs = 450\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c58j7LMY4G_C",
        "outputId": "1b1541e7-3f32-4af3-e174-209e658b8e7e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_1023:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1087:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1151:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1215:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1279:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 50) == 0 or i==449:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDBDzUQ24RFx",
        "outputId": "c4039a9c-125c-4ac0-9282-f7e6f2be2b54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/450  Current loss: 0.5755784511566162\n",
            "Epoch 50/450  Current loss: 0.023520642891526222\n",
            "Epoch 100/450  Current loss: 0.008287721313536167\n",
            "Epoch 150/450  Current loss: 0.0066921706311404705\n",
            "Epoch 200/450  Current loss: 0.0054135858081281185\n",
            "Epoch 250/450  Current loss: 0.005166566930711269\n",
            "Epoch 300/450  Current loss: 0.007015734910964966\n",
            "Epoch 350/450  Current loss: 0.005491523537784815\n",
            "Epoch 400/450  Current loss: 0.003928482532501221\n",
            "Epoch 449/450  Current loss: 0.004131177440285683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando learning rate para 0.0004 e 450 epocas -- teste 18 -- a taxa 0.0004 apresentou uma melhoria boa, vamos tentar aumentar as epcas\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.0004\n",
        "epochs = 500\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT1HNDz2QsOM",
        "outputId": "de3c5f8d-5a1b-423c-bcf4-373cc31e21c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_63:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_127:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_191:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_255:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_319:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 50) == 0 or i==499:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrMU30kCQ0Y_",
        "outputId": "0a4b2b45-8cb7-4f5d-a924-b5b283e87cdf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/500  Current loss: 0.653827965259552\n",
            "Epoch 50/500  Current loss: 0.020835066214203835\n",
            "Epoch 100/500  Current loss: 0.009289778769016266\n",
            "Epoch 150/500  Current loss: 0.006752738729119301\n",
            "Epoch 200/500  Current loss: 0.005416069179773331\n",
            "Epoch 250/500  Current loss: 0.009895590133965015\n",
            "Epoch 300/500  Current loss: 0.005158011335879564\n",
            "Epoch 350/500  Current loss: 0.0062384153716266155\n",
            "Epoch 400/500  Current loss: 0.003877679817378521\n",
            "Epoch 450/500  Current loss: 0.0036585743073374033\n",
            "Epoch 499/500  Current loss: 0.003913811407983303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para finalizar os testes de learning rate, tentaremos 0.0005 com 450 epocas\n"
      ],
      "metadata": {
        "id": "kM3g3GPKUfGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando learning rate para 0.0005 e 450 epocas -- teste 19 -- a taxa 0.0004 apresentou uma melhoria boa, vamos tentar aumentar as epcas\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.0005\n",
        "epochs = 450\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RidYYyTeUlPq",
        "outputId": "d5dc196c-5b9a-4744-a966-dba5edadad23"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_703:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_767:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_831:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_895:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_959:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 50) == 0 or i==449:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONctfGM_Up6c",
        "outputId": "06d07fe0-464b-4f00-f928-3d28237e8993"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/450  Current loss: 0.5008678436279297\n",
            "Epoch 50/450  Current loss: 0.014897557906806469\n",
            "Epoch 100/450  Current loss: 0.008341250009834766\n",
            "Epoch 150/450  Current loss: 0.006426945794373751\n",
            "Epoch 200/450  Current loss: 0.006201307289302349\n",
            "Epoch 250/450  Current loss: 0.005719465669244528\n",
            "Epoch 300/450  Current loss: 0.004994014743715525\n",
            "Epoch 350/450  Current loss: 0.005072608590126038\n",
            "Epoch 400/450  Current loss: 0.00455183582380414\n",
            "Epoch 449/450  Current loss: 0.004369713831692934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado no foi satisfatrio. Manteremos 0.0005 e 500 epocas"
      ],
      "metadata": {
        "id": "YM4EB3zrXci4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mudando learning rate para 0.0005 e 500 epocas -- teste 20 --- teste final com learning rate e epocas\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 4\n",
        "learning_rate = 0.0005\n",
        "epochs = 500\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3-tkqODXwwH",
        "outputId": "7488a5fa-ba95-48a6-f464-b82f22807f34"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_1663:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1727:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1791:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1855:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_1919:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 50) == 0 or i==499:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btntzZHrX24u",
        "outputId": "94276cfe-368f-491b-dde2-78aad025d5ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/500  Current loss: 0.5300008654594421\n",
            "Epoch 50/500  Current loss: 0.023650888353586197\n",
            "Epoch 100/500  Current loss: 0.008700547739863396\n",
            "Epoch 150/500  Current loss: 0.006697542034089565\n",
            "Epoch 200/500  Current loss: 0.0057250033132731915\n",
            "Epoch 250/500  Current loss: 0.005867592059075832\n",
            "Epoch 300/500  Current loss: 0.0051478492096066475\n",
            "Epoch 350/500  Current loss: 0.00461102370172739\n",
            "Epoch 400/500  Current loss: 0.004700975026935339\n",
            "Epoch 450/500  Current loss: 0.002713216235861182\n",
            "Epoch 499/500  Current loss: 0.003313068998977542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos finalizar nesses parametros de learning rate e epocas, pois a rede neural est alterando entre pocas, mas nessa configurao foi o melhor resultado que conseguimos, 0.0027. Agora vamos tentar diminuir o clip-margin para evitar exploso de gradientes e depois testar um aumento nas hidden layers para ver se nessa nova configurao faz efeito"
      ],
      "metadata": {
        "id": "TOs57UynkORb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clip margin 3 -- teste 21\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 3\n",
        "learning_rate = 0.0005\n",
        "epochs = 500\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl8k7JJQkmWR",
        "outputId": "62211cf0-efe9-4918-c48d-6a329159c0c0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_1983:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2047:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2111:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2175:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2239:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 50) == 0 or i==499:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOiq1NjNkyfI",
        "outputId": "a6381ff2-54ed-43dc-b528-632721420cfd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/500  Current loss: 0.5177028775215149\n",
            "Epoch 50/500  Current loss: 0.019237151369452477\n",
            "Epoch 100/500  Current loss: 0.008441193029284477\n",
            "Epoch 150/500  Current loss: 0.006633830722421408\n",
            "Epoch 200/500  Current loss: 0.005637857597321272\n",
            "Epoch 250/500  Current loss: 0.006880251225084066\n",
            "Epoch 300/500  Current loss: 0.004861029330641031\n",
            "Epoch 350/500  Current loss: 0.005625509191304445\n",
            "Epoch 400/500  Current loss: 0.004085917491465807\n",
            "Epoch 450/500  Current loss: 0.0029052819591015577\n",
            "Epoch 499/500  Current loss: 0.0034249224700033665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos tentar diminuir mais uma vez, ja que surtiu um leve efeito positivo\n"
      ],
      "metadata": {
        "id": "aMjaF5WLn3zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clip margin 2 -- teste 22\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 2\n",
        "learning_rate = 0.0005\n",
        "epochs = 500\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwFpdWJPn-tV",
        "outputId": "20a8b19b-796f-43b5-97db-ee5772604345"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_2303:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2367:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2431:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2495:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2559:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 50) == 0 or i==499:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrFvSGHRoBk_",
        "outputId": "852e7984-f9b3-470b-e3c3-05e8fefa6101"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/500  Current loss: 0.5716844201087952\n",
            "Epoch 50/500  Current loss: 0.019065022468566895\n",
            "Epoch 100/500  Current loss: 0.008056200109422207\n",
            "Epoch 150/500  Current loss: 0.0064092958346009254\n",
            "Epoch 200/500  Current loss: 0.005408258177340031\n",
            "Epoch 250/500  Current loss: 0.00467587448656559\n",
            "Epoch 300/500  Current loss: 0.0048828404396772385\n",
            "Epoch 350/500  Current loss: 0.0032404109369963408\n",
            "Epoch 400/500  Current loss: 0.002769848797470331\n",
            "Epoch 450/500  Current loss: 0.003035231726244092\n",
            "Epoch 499/500  Current loss: 0.0025970011483877897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chegamos no melhor resultado at agora, as ltimas pocas foram boas e o resultado foi o melhor ja registrado, agora testaremos c 256 hidden layers para finalizar todos testes c parametros"
      ],
      "metadata": {
        "id": "unP5VZqlq_bS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 256 hidden layers -- teste 23\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 256\n",
        "clip_margin = 2\n",
        "learning_rate = 0.0005\n",
        "epochs = 500\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hfUzpNkrQiN",
        "outputId": "9a35d647-727f-4926-db74-b864f01ad427"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_2623:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2687:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2751:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2815:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_2879:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 50) == 0 or i==499:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb1vOU6FrX8Q",
        "outputId": "70933ae7-62af-4421-c968-96a570b44289"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/500  Current loss: 0.2184419184923172\n",
            "Epoch 50/500  Current loss: 0.0224978718906641\n",
            "Epoch 100/500  Current loss: 0.009275045245885849\n",
            "Epoch 150/500  Current loss: 0.00697749899700284\n",
            "Epoch 200/500  Current loss: 0.006132485345005989\n",
            "Epoch 250/500  Current loss: 0.005750588607043028\n",
            "Epoch 300/500  Current loss: 0.00506069278344512\n",
            "Epoch 350/500  Current loss: 0.005286963656544685\n",
            "Epoch 400/500  Current loss: 0.0046483599580824375\n",
            "Epoch 450/500  Current loss: 0.005020936951041222\n",
            "Epoch 499/500  Current loss: 0.0034687414299696684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado no se mostrou vlido, pois, dobrando o nmero de camadas escondidas mantemos o mesmo e at pior resultado, com isso encerramos nossos testes nos hiperparametros"
      ],
      "metadata": {
        "id": "xjaLQaoT3a02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# teste louco com 1000 epocas e 0.0001 de lr, p ver como a rede responde, se h overfiting etc -- teste 24\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 128\n",
        "clip_margin = 2\n",
        "learning_rate = 0.0001\n",
        "epochs = 1000\n",
        "\n",
        "#o import do tensor flow estava dando errado entao tive que mudar para o compat.v1\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#we define the placeholders\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, window_size, 1])\n",
        "targets = tf.placeholder(tf.float32, [batch_size, 1])\n",
        "\n",
        "\n",
        "#Weights for the input gate\n",
        "weights_input_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_input_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_input = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#gera os dados candidatos\n",
        "\n",
        "#weights for the forgot gate\n",
        "weights_forget_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_forget_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_forget = tf.Variable(tf.zeros([hidden_layer]))\n",
        "#o forgot gate define se tal dado vai ser esquecido ou passado adiante\n",
        "\n",
        "#weights for the output gate\n",
        "weights_output_gate = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_output_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_output = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#weights for the memory cell\n",
        "weights_memory_cell = tf.Variable(tf.truncated_normal([1, hidden_layer], stddev=0.05))\n",
        "weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([hidden_layer, hidden_layer], stddev=0.05))\n",
        "bias_memory_cell = tf.Variable(tf.zeros([hidden_layer]))\n",
        "\n",
        "#Output layer weigts\n",
        "weights_output = tf.Variable(tf.truncated_normal([hidden_layer, 1], stddev=0.05))\n",
        "bias_output_layer = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "\n",
        "#function to compute the gate states\n",
        "def LSTM_cell(input, output, state):\n",
        "\n",
        "    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)\n",
        "\n",
        "    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)\n",
        "\n",
        "    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)\n",
        "\n",
        "    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)\n",
        "\n",
        "    state = state * forget_gate + input_gate * memory_cell\n",
        "\n",
        "    output = output_gate * tf.tanh(state)\n",
        "    return state, output\n",
        "\n",
        "\n",
        " #we now define loop for the network\n",
        "outputs = []\n",
        "for i in range(batch_size): #Iterates through every window in the batch\n",
        "\n",
        "    #for each batch I am creating batch_state as all zeros and output for that window which is all zeros at the beginning as well.\n",
        "    batch_state = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "    batch_output = np.zeros([1, hidden_layer], dtype=np.float32)\n",
        "\n",
        "    #for each point in the window we are feeding that into LSTM to get next output\n",
        "    for ii in range(window_size):\n",
        "        batch_state, batch_output = LSTM_cell(tf.reshape(inputs[i][ii], (-1, 1)), batch_state, batch_output)\n",
        "\n",
        "    #last output is conisdered and used to get a prediction\n",
        "    outputs.append(tf.matmul(batch_output, weights_output) + bias_output_layer)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VomfPbh93-Hl",
        "outputId": "7c324163-1343-41be-b531-d1ff63863731"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'add_2943:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_3007:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_3071:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_3135:0' shape=(1, 1) dtype=float32>,\n",
              " <tf.Tensor 'add_3199:0' shape=(1, 1) dtype=float32>]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i], (-1, 1)), outputs[i]))\n",
        "\n",
        "loss = tf.reduce_mean(losses)\n",
        "\n",
        "#we define optimizer with gradient clipping\n",
        "gradients = tf.gradients(loss, tf.trainable_variables())\n",
        "clipped, _ = tf.clip_by_global_norm(gradients, clip_margin)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trained_optimizer = optimizer.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
        "\n",
        "#we now train the network\n",
        "session = tf.Session()\n",
        "session.run(tf.global_variables_initializer())\n",
        "for i in range(epochs):\n",
        "    traind_scores = []\n",
        "    ii = 0\n",
        "    epoch_loss = []\n",
        "    while(ii + batch_size) <= len(X_train):\n",
        "        X_batch = X_train[ii:ii+batch_size]\n",
        "        y_batch = y_train[ii:ii+batch_size]\n",
        "\n",
        "        o, c, _ = session.run([outputs, loss, trained_optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
        "\n",
        "        epoch_loss.append(c)\n",
        "        traind_scores.append(o)\n",
        "        ii += batch_size\n",
        "    if (i % 100) == 0 or i==999:\n",
        "        print('Epoch {}/{}'.format(i, epochs), ' Current loss: {}'.format(np.mean(epoch_loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgi9MJQj4Nj3",
        "outputId": "25e917d3-ad56-4541-a474-b4d98a866628"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/1000  Current loss: 1.0956110954284668\n",
            "Epoch 100/1000  Current loss: 0.017652297392487526\n",
            "Epoch 200/1000  Current loss: 0.008276904001832008\n",
            "Epoch 300/1000  Current loss: 0.0063081346452236176\n",
            "Epoch 400/1000  Current loss: 0.005596332252025604\n",
            "Epoch 500/1000  Current loss: 0.005393880885094404\n",
            "Epoch 600/1000  Current loss: 0.004842748399823904\n",
            "Epoch 700/1000  Current loss: 0.004357151687145233\n",
            "Epoch 800/1000  Current loss: 0.0040436056442558765\n",
            "Epoch 900/1000  Current loss: 0.004090918228030205\n",
            "Epoch 999/1000  Current loss: 0.0038147871382534504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concluses finais:\n",
        "Aps diversos testes com os hiperparametros chegamos a esse resultado:\n",
        "batch_size = 5\n",
        "window_size = 7\n",
        "hidden_layer = 256\n",
        "clip_margin = 2\n",
        "learning_rate = 0.0005\n",
        "epochs = 500\n",
        "Com esses parametros chegamos  uma loss de 0.0025, sendo nosso melhor valor alcanado. Tambm notamos que a partir de certo ponto, os valores comeavam a oscilar durante o treinamento entre as epcas, no conseguimos eliminar isso mas reduzimos ao mximo prezando por uma razo entre desempenho e no repetio de valores no quantificamento das epcas. Com esse estudo conseguimos entender melhor como os hiperparametros funcionam para esse problema especfico, e entendemos que existem infinitas possibilidades a serem exploradas afim de chegar num resultado cada vez melhor."
      ],
      "metadata": {
        "id": "izd_pfYXDs7Y"
      }
    }
  ]
}